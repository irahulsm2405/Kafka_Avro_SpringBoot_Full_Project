[2025-08-10 11:33:07,286] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2025-08-10 11:33:07,522] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2025-08-10 11:33:07,699] INFO [ControllerServer id=3] Starting controller (kafka.server.ControllerServer)
[2025-08-10 11:33:07,719] INFO authorizerStart completed for endpoint CONTROLLER. Endpoint is now READY. (org.apache.kafka.server.network.EndpointReadyFutures)
[2025-08-10 11:33:08,088] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2025-08-10 11:33:08,170] INFO [SocketServer listenerType=CONTROLLER, nodeId=3] Created data-plane acceptor and processors for endpoint : ListenerName(CONTROLLER) (kafka.network.SocketServer)
[2025-08-10 11:33:08,173] INFO [SharedServer id=3] Starting SharedServer (kafka.server.SharedServer)
[2025-08-10 11:33:08,248] INFO [LogLoader partition=__cluster_metadata-0, dir=C:\tmp\server-3\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for __cluster_metadata-0. (kafka.log.LogLoader)
[2025-08-10 11:33:08,251] INFO [LogLoader partition=__cluster_metadata-0, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:08,251] INFO [LogLoader partition=__cluster_metadata-0, dir=C:\tmp\server-3\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:08,253] INFO Deleted producer state snapshot C:\tmp\server-3\kraft-combined-logs\__cluster_metadata-0\00000000000000032392.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2025-08-10 11:33:08,253] INFO [LogLoader partition=__cluster_metadata-0, dir=C:\tmp\server-3\kraft-combined-logs] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:08,523] INFO [ProducerStateManager partition=__cluster_metadata-0]Wrote producer snapshot at offset 37207 with 0 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-08-10 11:33:08,537] INFO [LogLoader partition=__cluster_metadata-0, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 37207 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:08,537] INFO [LogLoader partition=__cluster_metadata-0, dir=C:\tmp\server-3\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 37207 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:08,537] INFO [ProducerStateManager partition=__cluster_metadata-0]Loading producer state from snapshot file 'SnapshotFile(offset=37207, file=C:\tmp\server-3\kraft-combined-logs\__cluster_metadata-0\00000000000000037207.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-08-10 11:33:08,546] INFO [LogLoader partition=__cluster_metadata-0, dir=C:\tmp\server-3\kraft-combined-logs] Producer state recovery took 9ms for snapshot load and 0ms for segment recovery from offset 37207 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:08,593] INFO Initialized snapshots with IDs SortedSet(OffsetAndEpoch(offset=7136, epoch=1), OffsetAndEpoch(offset=14220, epoch=1), OffsetAndEpoch(offset=21301, epoch=1), OffsetAndEpoch(offset=28391, epoch=1), OffsetAndEpoch(offset=31328, epoch=1)) from C:\tmp\server-3\kraft-combined-logs\__cluster_metadata-0 (kafka.raft.KafkaMetadataLog$)
[2025-08-10 11:33:08,612] INFO [raft-expiration-reaper]: Starting (kafka.raft.TimingWheelExpirationService$ExpiredOperationReaper)
[2025-08-10 11:33:08,810] INFO [RaftManager id=3] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=11, leaderId=1, voters=[1, 2, 3], highWatermark=Optional.empty, fetchingSnapshot=Optional.empty) from null (org.apache.kafka.raft.QuorumState)
[2025-08-10 11:33:08,814] INFO [kafka-3-raft-outbound-request-thread]: Starting (kafka.raft.RaftSendThread)
[2025-08-10 11:33:08,814] INFO [kafka-3-raft-io-thread]: Starting (kafka.raft.KafkaRaftManager$RaftIoThread)
[2025-08-10 11:33:08,841] INFO [RaftManager id=3] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:08,843] WARN [RaftManager id=3] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:08,851] INFO [MetadataLoader id=3] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:08,853] INFO [ControllerServer id=3] Waiting for controller quorum voters future (kafka.server.ControllerServer)
[2025-08-10 11:33:08,853] INFO [RaftManager id=3] Registered the listener org.apache.kafka.image.loader.MetadataLoader@488522543 (org.apache.kafka.raft.KafkaRaftClient)
[2025-08-10 11:33:08,853] INFO [ControllerServer id=3] Finished waiting for controller quorum voters future (kafka.server.ControllerServer)
[2025-08-10 11:33:08,888] INFO [RaftManager id=3] Registered the listener org.apache.kafka.controller.QuorumController$QuorumMetaLogListener@167819944 (org.apache.kafka.raft.KafkaRaftClient)
[2025-08-10 11:33:08,895] INFO [controller-3-ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-08-10 11:33:08,896] INFO [controller-3-ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-08-10 11:33:08,897] INFO [controller-3-ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-08-10 11:33:08,900] INFO [controller-3-ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-08-10 11:33:08,915] INFO [ExpirationReaper-3-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-08-10 11:33:08,925] INFO [ControllerServer id=3] Waiting for the controller metadata publishers to be installed (kafka.server.ControllerServer)
[2025-08-10 11:33:08,925] INFO [ControllerServer id=3] Finished waiting for the controller metadata publishers to be installed (kafka.server.ControllerServer)
[2025-08-10 11:33:08,925] INFO [MetadataLoader id=3] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:08,925] INFO [SocketServer listenerType=CONTROLLER, nodeId=3] Enabling request processing. (kafka.network.SocketServer)
[2025-08-10 11:33:08,928] INFO Awaiting socket connections on 0.0.0.0:9097. (kafka.network.DataPlaneAcceptor)
[2025-08-10 11:33:08,931] INFO [RaftManager id=3] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:08,931] WARN [RaftManager id=3] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:08,931] INFO [ControllerServer id=3] Waiting for all of the authorizer futures to be completed (kafka.server.ControllerServer)
[2025-08-10 11:33:08,931] INFO [ControllerServer id=3] Finished waiting for all of the authorizer futures to be completed (kafka.server.ControllerServer)
[2025-08-10 11:33:08,931] INFO [ControllerServer id=3] Waiting for all of the SocketServer Acceptors to be started (kafka.server.ControllerServer)
[2025-08-10 11:33:08,932] INFO [ControllerServer id=3] Finished waiting for all of the SocketServer Acceptors to be started (kafka.server.ControllerServer)
[2025-08-10 11:33:08,933] INFO [BrokerServer id=3] Transition from SHUTDOWN to STARTING (kafka.server.BrokerServer)
[2025-08-10 11:33:08,934] INFO [BrokerServer id=3] Starting broker (kafka.server.BrokerServer)
[2025-08-10 11:33:08,943] INFO [broker-3-ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-08-10 11:33:08,943] INFO [broker-3-ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-08-10 11:33:08,943] INFO [broker-3-ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-08-10 11:33:08,943] INFO [broker-3-ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-08-10 11:33:08,966] INFO [BrokerServer id=3] Waiting for controller quorum voters future (kafka.server.BrokerServer)
[2025-08-10 11:33:08,966] INFO [BrokerServer id=3] Finished waiting for controller quorum voters future (kafka.server.BrokerServer)
[2025-08-10 11:33:08,978] INFO [broker-3-to-controller-forwarding-channel-manager]: Starting (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:08,980] INFO [broker-3-to-controller-forwarding-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:09,005] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2025-08-10 11:33:09,020] INFO [SocketServer listenerType=BROKER, nodeId=3] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2025-08-10 11:33:09,029] INFO [broker-3-to-controller-alter-partition-channel-manager]: Starting (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:09,030] INFO [broker-3-to-controller-alter-partition-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:09,039] INFO [MetadataLoader id=3] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:09,054] INFO [ExpirationReaper-3-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-08-10 11:33:09,055] INFO [ExpirationReaper-3-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-08-10 11:33:09,056] INFO [ExpirationReaper-3-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-08-10 11:33:09,058] INFO [ExpirationReaper-3-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-08-10 11:33:09,059] INFO [ExpirationReaper-3-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-08-10 11:33:09,081] INFO [ExpirationReaper-3-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-08-10 11:33:09,081] INFO [ExpirationReaper-3-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-08-10 11:33:09,089] INFO [RaftManager id=3] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:09,089] WARN [RaftManager id=3] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:09,125] INFO [broker-3-to-controller-heartbeat-channel-manager]: Starting (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:09,125] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:09,127] INFO [BrokerLifecycleManager id=3] Incarnation MLZx7l4lS4uWSfzYdUH6fQ of broker 3 in cluster lt3SeY4gSgmN81qtuDBrnQ is now STARTING. (kafka.server.BrokerLifecycleManager)
[2025-08-10 11:33:09,129] INFO [BrokerToControllerChannelManager id=3 name=heartbeat] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:09,129] WARN [BrokerToControllerChannelManager id=3 name=heartbeat] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:09,130] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:09,146] INFO [ExpirationReaper-3-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-08-10 11:33:09,150] INFO [MetadataLoader id=3] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:09,162] INFO [BrokerServer id=3] Waiting for the broker metadata publishers to be installed (kafka.server.BrokerServer)
[2025-08-10 11:33:09,163] INFO [MetadataLoader id=3] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:09,163] INFO [BrokerServer id=3] Finished waiting for the broker metadata publishers to be installed (kafka.server.BrokerServer)
[2025-08-10 11:33:09,163] INFO [BrokerServer id=3] Waiting for the controller to acknowledge that we are caught up (kafka.server.BrokerServer)
[2025-08-10 11:33:09,181] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:09,182] INFO [BrokerToControllerChannelManager id=3 name=heartbeat] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:09,182] WARN [BrokerToControllerChannelManager id=3 name=heartbeat] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:09,182] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:09,244] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:09,246] INFO [BrokerToControllerChannelManager id=3 name=heartbeat] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:09,246] WARN [BrokerToControllerChannelManager id=3 name=heartbeat] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:09,247] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:09,276] INFO [MetadataLoader id=3] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:09,307] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:09,308] INFO [BrokerToControllerChannelManager id=3 name=heartbeat] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:09,309] WARN [BrokerToControllerChannelManager id=3 name=heartbeat] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:09,309] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:09,338] INFO [RaftManager id=3] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:09,338] WARN [RaftManager id=3] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:09,368] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:09,369] INFO [BrokerToControllerChannelManager id=3 name=heartbeat] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:09,370] WARN [BrokerToControllerChannelManager id=3 name=heartbeat] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:09,370] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:09,384] INFO [MetadataLoader id=3] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:09,430] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:09,431] INFO [BrokerToControllerChannelManager id=3 name=heartbeat] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:09,431] WARN [BrokerToControllerChannelManager id=3 name=heartbeat] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:09,432] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:09,432] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2025-08-10 11:33:09,493] INFO [MetadataLoader id=3] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:09,493] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:09,494] INFO [BrokerToControllerChannelManager id=3 name=heartbeat] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:09,494] WARN [BrokerToControllerChannelManager id=3 name=heartbeat] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:09,494] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:09,556] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:09,557] INFO [BrokerToControllerChannelManager id=3 name=heartbeat] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:09,557] WARN [BrokerToControllerChannelManager id=3 name=heartbeat] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:09,558] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:09,603] INFO [MetadataLoader id=3] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:09,618] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:09,619] INFO [BrokerToControllerChannelManager id=3 name=heartbeat] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:09,619] WARN [BrokerToControllerChannelManager id=3 name=heartbeat] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:09,620] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:09,657] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2025-08-10 11:33:09,680] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:09,681] INFO [BrokerToControllerChannelManager id=3 name=heartbeat] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:09,682] WARN [BrokerToControllerChannelManager id=3 name=heartbeat] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:09,682] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:09,712] INFO [MetadataLoader id=3] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:09,743] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:09,744] INFO [BrokerToControllerChannelManager id=3 name=heartbeat] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:09,745] WARN [BrokerToControllerChannelManager id=3 name=heartbeat] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:09,745] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:09,759] INFO [RaftManager id=3] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:09,759] WARN [RaftManager id=3] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:09,805] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:09,806] INFO [BrokerToControllerChannelManager id=3 name=heartbeat] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:09,806] WARN [BrokerToControllerChannelManager id=3 name=heartbeat] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:09,806] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:09,821] INFO [MetadataLoader id=3] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:09,825] INFO [ControllerServer id=2] Starting controller (kafka.server.ControllerServer)
[2025-08-10 11:33:09,847] INFO authorizerStart completed for endpoint CONTROLLER. Endpoint is now READY. (org.apache.kafka.server.network.EndpointReadyFutures)
[2025-08-10 11:33:09,868] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:09,869] INFO [BrokerToControllerChannelManager id=3 name=heartbeat] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:09,869] WARN [BrokerToControllerChannelManager id=3 name=heartbeat] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:09,869] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:09,930] INFO [MetadataLoader id=3] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:09,930] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:09,931] INFO [BrokerToControllerChannelManager id=3 name=heartbeat] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:09,931] WARN [BrokerToControllerChannelManager id=3 name=heartbeat] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:09,931] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:09,993] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:09,994] INFO [BrokerToControllerChannelManager id=3 name=heartbeat] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:09,994] WARN [BrokerToControllerChannelManager id=3 name=heartbeat] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:09,994] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:10,040] INFO [MetadataLoader id=3] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:10,055] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:10,056] INFO [BrokerToControllerChannelManager id=3 name=heartbeat] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:10,056] WARN [BrokerToControllerChannelManager id=3 name=heartbeat] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:10,057] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:10,117] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:10,119] INFO [BrokerToControllerChannelManager id=3 name=heartbeat] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:10,119] WARN [BrokerToControllerChannelManager id=3 name=heartbeat] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:10,120] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:10,148] INFO [MetadataLoader id=3] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:10,165] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2025-08-10 11:33:10,180] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:10,181] INFO [BrokerToControllerChannelManager id=3 name=heartbeat] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:10,182] WARN [BrokerToControllerChannelManager id=3 name=heartbeat] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:10,182] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:10,214] INFO [RaftManager id=3] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:10,214] WARN [RaftManager id=3] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:10,242] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:10,243] INFO [BrokerToControllerChannelManager id=3 name=heartbeat] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:10,243] WARN [BrokerToControllerChannelManager id=3 name=heartbeat] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:10,243] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:10,249] INFO [SocketServer listenerType=CONTROLLER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(CONTROLLER) (kafka.network.SocketServer)
[2025-08-10 11:33:10,251] INFO [SharedServer id=2] Starting SharedServer (kafka.server.SharedServer)
[2025-08-10 11:33:10,258] INFO [MetadataLoader id=3] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:10,304] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:10,305] INFO [BrokerToControllerChannelManager id=3 name=heartbeat] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:10,305] WARN [BrokerToControllerChannelManager id=3 name=heartbeat] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:10,306] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:10,324] INFO [LogLoader partition=__cluster_metadata-0, dir=C:\tmp\server-2\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for __cluster_metadata-0. (kafka.log.LogLoader)
[2025-08-10 11:33:10,326] INFO [LogLoader partition=__cluster_metadata-0, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:10,328] INFO [LogLoader partition=__cluster_metadata-0, dir=C:\tmp\server-2\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:10,328] INFO Deleted producer state snapshot C:\tmp\server-2\kraft-combined-logs\__cluster_metadata-0\00000000000000032392.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2025-08-10 11:33:10,329] INFO [LogLoader partition=__cluster_metadata-0, dir=C:\tmp\server-2\kraft-combined-logs] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:10,366] INFO [MetadataLoader id=3] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:10,366] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:10,367] INFO [BrokerToControllerChannelManager id=3 name=heartbeat] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:10,367] WARN [BrokerToControllerChannelManager id=3 name=heartbeat] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:10,367] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:10,430] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:10,431] INFO [BrokerToControllerChannelManager id=3 name=heartbeat] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:10,432] WARN [BrokerToControllerChannelManager id=3 name=heartbeat] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:10,432] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:10,476] INFO [MetadataLoader id=3] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:10,492] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:10,493] INFO [BrokerToControllerChannelManager id=3 name=heartbeat] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:10,494] WARN [BrokerToControllerChannelManager id=3 name=heartbeat] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:10,494] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:10,556] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:10,557] INFO [BrokerToControllerChannelManager id=3 name=heartbeat] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:10,557] WARN [BrokerToControllerChannelManager id=3 name=heartbeat] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:10,558] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:10,587] INFO [MetadataLoader id=3] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:10,619] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:10,620] INFO [BrokerToControllerChannelManager id=3 name=heartbeat] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:10,621] WARN [BrokerToControllerChannelManager id=3 name=heartbeat] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:10,621] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:10,647] INFO [ProducerStateManager partition=__cluster_metadata-0]Wrote producer snapshot at offset 37207 with 0 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-08-10 11:33:10,664] INFO [LogLoader partition=__cluster_metadata-0, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 37207 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:10,664] INFO [LogLoader partition=__cluster_metadata-0, dir=C:\tmp\server-2\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 37207 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:10,664] INFO [ProducerStateManager partition=__cluster_metadata-0]Loading producer state from snapshot file 'SnapshotFile(offset=37207, file=C:\tmp\server-2\kraft-combined-logs\__cluster_metadata-0\00000000000000037207.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-08-10 11:33:10,667] INFO [LogLoader partition=__cluster_metadata-0, dir=C:\tmp\server-2\kraft-combined-logs] Producer state recovery took 3ms for snapshot load and 0ms for segment recovery from offset 37207 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:10,679] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:10,680] INFO [BrokerToControllerChannelManager id=3 name=heartbeat] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:10,680] WARN [BrokerToControllerChannelManager id=3 name=heartbeat] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:10,682] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:10,694] INFO [MetadataLoader id=3] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:10,706] INFO Initialized snapshots with IDs SortedSet(OffsetAndEpoch(offset=7135, epoch=1), OffsetAndEpoch(offset=14219, epoch=1), OffsetAndEpoch(offset=21300, epoch=1), OffsetAndEpoch(offset=28390, epoch=1), OffsetAndEpoch(offset=31328, epoch=1)) from C:\tmp\server-2\kraft-combined-logs\__cluster_metadata-0 (kafka.raft.KafkaMetadataLog$)
[2025-08-10 11:33:10,720] INFO [raft-expiration-reaper]: Starting (kafka.raft.TimingWheelExpirationService$ExpiredOperationReaper)
[2025-08-10 11:33:10,726] INFO [RaftManager id=3] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:10,726] WARN [RaftManager id=3] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:10,740] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:10,743] INFO [BrokerToControllerChannelManager id=3 name=heartbeat] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:10,743] WARN [BrokerToControllerChannelManager id=3 name=heartbeat] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:10,743] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:10,803] INFO [MetadataLoader id=3] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:10,803] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:10,803] INFO [RaftManager id=3] Become candidate due to fetch timeout (org.apache.kafka.raft.KafkaRaftClient)
[2025-08-10 11:33:10,804] INFO [BrokerToControllerChannelManager id=3 name=heartbeat] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:10,804] WARN [BrokerToControllerChannelManager id=3 name=heartbeat] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:10,805] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:10,808] INFO [RaftManager id=3] Completed transition to CandidateState(localId=3, epoch=12, retries=1, voteStates={1=UNRECORDED, 2=UNRECORDED, 3=GRANTED}, highWatermark=Optional.empty, electionTimeoutMs=1738) from FollowerState(fetchTimeoutMs=2000, epoch=11, leaderId=1, voters=[1, 2, 3], highWatermark=Optional.empty, fetchingSnapshot=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2025-08-10 11:33:10,829] INFO [RaftManager id=3] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:10,829] WARN [RaftManager id=3] Connection to node 2 (localhost/127.0.0.1:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:10,872] INFO [RaftManager id=2] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=11, leaderId=1, voters=[1, 2, 3], highWatermark=Optional.empty, fetchingSnapshot=Optional.empty) from null (org.apache.kafka.raft.QuorumState)
[2025-08-10 11:33:10,875] INFO [kafka-2-raft-outbound-request-thread]: Starting (kafka.raft.RaftSendThread)
[2025-08-10 11:33:10,875] INFO [kafka-2-raft-io-thread]: Starting (kafka.raft.KafkaRaftManager$RaftIoThread)
[2025-08-10 11:33:10,899] INFO [RaftManager id=3] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:10,899] WARN [RaftManager id=3] Connection to node 2 (localhost/127.0.0.1:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:10,903] INFO [RaftManager id=2] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:10,905] INFO [MetadataLoader id=2] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:10,905] WARN [RaftManager id=2] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:10,907] INFO [RaftManager id=2] Registered the listener org.apache.kafka.image.loader.MetadataLoader@1000755448 (org.apache.kafka.raft.KafkaRaftClient)
[2025-08-10 11:33:10,907] INFO [ControllerServer id=2] Waiting for controller quorum voters future (kafka.server.ControllerServer)
[2025-08-10 11:33:10,907] INFO [ControllerServer id=2] Finished waiting for controller quorum voters future (kafka.server.ControllerServer)
[2025-08-10 11:33:10,912] INFO [MetadataLoader id=3] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:10,944] INFO [RaftManager id=2] Registered the listener org.apache.kafka.controller.QuorumController$QuorumMetaLogListener@197301863 (org.apache.kafka.raft.KafkaRaftClient)
[2025-08-10 11:33:10,951] INFO [controller-2-ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-08-10 11:33:10,951] INFO [controller-2-ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-08-10 11:33:10,952] INFO [controller-2-ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-08-10 11:33:10,955] INFO [controller-2-ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-08-10 11:33:10,971] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-08-10 11:33:10,986] INFO [ControllerServer id=2] Waiting for the controller metadata publishers to be installed (kafka.server.ControllerServer)
[2025-08-10 11:33:10,987] INFO [MetadataLoader id=2] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:10,987] INFO [ControllerServer id=2] Finished waiting for the controller metadata publishers to be installed (kafka.server.ControllerServer)
[2025-08-10 11:33:10,988] INFO [SocketServer listenerType=CONTROLLER, nodeId=2] Enabling request processing. (kafka.network.SocketServer)
[2025-08-10 11:33:10,991] INFO Awaiting socket connections on 0.0.0.0:9095. (kafka.network.DataPlaneAcceptor)
[2025-08-10 11:33:10,993] INFO [RaftManager id=2] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:10,993] WARN [RaftManager id=2] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:10,997] INFO [ControllerServer id=2] Waiting for all of the authorizer futures to be completed (kafka.server.ControllerServer)
[2025-08-10 11:33:10,997] INFO [ControllerServer id=2] Finished waiting for all of the authorizer futures to be completed (kafka.server.ControllerServer)
[2025-08-10 11:33:10,998] INFO [ControllerServer id=2] Waiting for all of the SocketServer Acceptors to be started (kafka.server.ControllerServer)
[2025-08-10 11:33:10,998] INFO [ControllerServer id=2] Finished waiting for all of the SocketServer Acceptors to be started (kafka.server.ControllerServer)
[2025-08-10 11:33:10,999] INFO [BrokerServer id=2] Transition from SHUTDOWN to STARTING (kafka.server.BrokerServer)
[2025-08-10 11:33:11,001] INFO [BrokerServer id=2] Starting broker (kafka.server.BrokerServer)
[2025-08-10 11:33:11,012] INFO [broker-2-ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-08-10 11:33:11,013] INFO [broker-2-ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-08-10 11:33:11,013] INFO [broker-2-ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-08-10 11:33:11,013] INFO [broker-2-ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-08-10 11:33:11,023] INFO [MetadataLoader id=3] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:11,049] INFO [BrokerServer id=2] Waiting for controller quorum voters future (kafka.server.BrokerServer)
[2025-08-10 11:33:11,049] INFO [BrokerServer id=2] Finished waiting for controller quorum voters future (kafka.server.BrokerServer)
[2025-08-10 11:33:11,063] INFO [broker-2-to-controller-forwarding-channel-manager]: Starting (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:11,065] INFO [broker-2-to-controller-forwarding-channel-manager]: Recorded new controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:11,081] INFO [RaftManager id=2] Completed transition to Unattached(epoch=12, voters=[1, 2, 3], electionTimeoutMs=1342) from FollowerState(fetchTimeoutMs=2000, epoch=11, leaderId=1, voters=[1, 2, 3], highWatermark=Optional.empty, fetchingSnapshot=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2025-08-10 11:33:11,091] INFO [RaftManager id=2] Completed transition to Voted(epoch=12, votedId=3, voters=[1, 2, 3], electionTimeoutMs=1886) from Unattached(epoch=12, voters=[1, 2, 3], electionTimeoutMs=1342) (org.apache.kafka.raft.QuorumState)
[2025-08-10 11:33:11,092] INFO [RaftManager id=2] Vote request VoteRequestData(clusterId='lt3SeY4gSgmN81qtuDBrnQ', topics=[TopicData(topicName='__cluster_metadata', partitions=[PartitionData(partitionIndex=0, candidateEpoch=12, candidateId=3, lastOffsetEpoch=11, lastOffset=37207)])]) with epoch 12 is granted (org.apache.kafka.raft.KafkaRaftClient)
[2025-08-10 11:33:11,100] INFO [MetadataLoader id=2] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:11,107] INFO [RaftManager id=3] Completed transition to Leader(localId=3, epoch=12, epochStartOffset=37207, highWatermark=Optional.empty, voterStates={1=ReplicaState(nodeId=1, endOffset=Optional.empty, lastFetchTimestamp=-1, lastCaughtUpTimestamp=-1, hasAcknowledgedLeader=false), 2=ReplicaState(nodeId=2, endOffset=Optional.empty, lastFetchTimestamp=-1, lastCaughtUpTimestamp=-1, hasAcknowledgedLeader=false), 3=ReplicaState(nodeId=3, endOffset=Optional.empty, lastFetchTimestamp=-1, lastCaughtUpTimestamp=-1, hasAcknowledgedLeader=true)}) from CandidateState(localId=3, epoch=12, retries=1, voteStates={1=UNRECORDED, 2=GRANTED, 3=GRANTED}, highWatermark=Optional.empty, electionTimeoutMs=1738) (org.apache.kafka.raft.QuorumState)
[2025-08-10 11:33:11,110] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2025-08-10 11:33:11,114] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2025-08-10 11:33:11,131] INFO [MetadataLoader id=3] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:11,135] INFO [SocketServer listenerType=BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2025-08-10 11:33:11,144] INFO [broker-2-to-controller-alter-partition-channel-manager]: Starting (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:11,158] INFO [LocalLog partition=__cluster_metadata-0, dir=C:\tmp\server-3\kraft-combined-logs] Rolled new log segment at offset 37207 in 9 ms. (kafka.log.LocalLog)
[2025-08-10 11:33:11,179] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-08-10 11:33:11,181] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-08-10 11:33:11,182] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-08-10 11:33:11,184] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-08-10 11:33:11,186] INFO [ExpirationReaper-2-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-08-10 11:33:11,193] INFO [RaftManager id=2] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=12, leaderId=3, voters=[1, 2, 3], highWatermark=Optional.empty, fetchingSnapshot=Optional.empty) from Voted(epoch=12, votedId=3, voters=[1, 2, 3], electionTimeoutMs=1886) (org.apache.kafka.raft.QuorumState)
[2025-08-10 11:33:11,193] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:11,209] INFO [MetadataLoader id=2] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:11,215] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-08-10 11:33:11,216] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-08-10 11:33:11,241] INFO [MetadataLoader id=3] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:11,245] INFO [BrokerToControllerChannelManager id=3 name=heartbeat] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:11,247] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:11,255] INFO [RaftManager id=3] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:11,255] WARN [RaftManager id=3] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:11,257] INFO [broker-2-to-controller-alter-partition-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:11,278] INFO [broker-2-to-controller-heartbeat-channel-manager]: Starting (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:11,278] INFO [broker-2-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:11,281] INFO [BrokerLifecycleManager id=2] Incarnation ds8crqPBTj6ak0Dd8BtaiA of broker 2 in cluster lt3SeY4gSgmN81qtuDBrnQ is now STARTING. (kafka.server.BrokerLifecycleManager)
[2025-08-10 11:33:11,285] INFO [LocalLog partition=__cluster_metadata-0, dir=C:\tmp\server-2\kraft-combined-logs] Rolled new log segment at offset 37207 in 8 ms. (kafka.log.LocalLog)
[2025-08-10 11:33:11,291] INFO [BrokerToControllerChannelManager id=2 name=heartbeat] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:11,302] INFO [broker-2-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:11,302] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:11,310] INFO [BrokerToControllerChannelManager id=3 name=heartbeat] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:11,312] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:11,313] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-08-10 11:33:11,318] INFO [MetadataLoader id=2] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:11,320] INFO [RaftManager id=3] High watermark set to LogOffsetMetadata(offset=37208, metadata=Optional[(segmentBaseOffset=37207,relativePositionInSegment=106)]) for the first time for epoch 12 based on indexOfHw 1 and voters [ReplicaState(nodeId=2, endOffset=Optional[LogOffsetMetadata(offset=37208, metadata=Optional[(segmentBaseOffset=37207,relativePositionInSegment=106)])], lastFetchTimestamp=1754805791319, lastCaughtUpTimestamp=1754805791319, hasAcknowledgedLeader=true), ReplicaState(nodeId=3, endOffset=Optional[LogOffsetMetadata(offset=37208, metadata=Optional[(segmentBaseOffset=37207,relativePositionInSegment=106)])], lastFetchTimestamp=-1, lastCaughtUpTimestamp=-1, hasAcknowledgedLeader=true), ReplicaState(nodeId=1, endOffset=Optional.empty, lastFetchTimestamp=-1, lastCaughtUpTimestamp=-1, hasAcknowledgedLeader=false)] (org.apache.kafka.raft.LeaderState)
[2025-08-10 11:33:11,331] INFO [BrokerServer id=2] Waiting for the broker metadata publishers to be installed (kafka.server.BrokerServer)
[2025-08-10 11:33:11,331] INFO [MetadataLoader id=2] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:11,333] INFO [BrokerServer id=2] Finished waiting for the broker metadata publishers to be installed (kafka.server.BrokerServer)
[2025-08-10 11:33:11,333] INFO [BrokerServer id=2] Waiting for the controller to acknowledge that we are caught up (kafka.server.BrokerServer)
[2025-08-10 11:33:11,343] INFO [MetadataLoader id=3] initializeNewPublishers: The loader is still catching up because we have loaded up to offset -1, but the high water mark is 37208 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:11,343] INFO [MetadataLoader id=3] handleLoadSnapshot(00000000000000031328-0000000001): incrementing HandleLoadSnapshotCount to 1. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:11,350] INFO [broker-2-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:11,363] INFO [MetadataLoader id=3] handleLoadSnapshot(00000000000000031328-0000000001): generated a metadata delta between offset -1 and this snapshot in 20184 us. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:11,365] INFO [MetadataLoader id=3] maybePublishMetadata(SNAPSHOT): The loader is still catching up because we have loaded up to offset 31327, but the high water mark is 37208 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:11,365] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:11,437] INFO [BrokerToControllerChannelManager id=3 name=heartbeat] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:11,437] INFO [BrokerToControllerChannelManager id=2 name=heartbeat] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:11,438] INFO [broker-2-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:11,438] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:11,442] INFO [MetadataLoader id=2] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:11,462] INFO [MetadataLoader id=3] maybePublishMetadata(LOG_DELTA): The loader is still catching up because we have loaded up to offset 37206, but the high water mark is 37208 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:11,463] INFO [MetadataLoader id=3] initializeNewPublishers: The loader is still catching up because we have loaded up to offset 37206, but the high water mark is 37208 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:11,464] INFO [MetadataLoader id=3] maybePublishMetadata(LOG_DELTA): The loader finished catching up to the current high water mark of 37208 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:11,489] INFO [broker-2-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:11,489] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:11,501] INFO [BrokerLifecycleManager id=3] Unable to register broker 3 because the controller returned error DUPLICATE_BROKER_REGISTRATION (kafka.server.BrokerLifecycleManager)
[2025-08-10 11:33:11,502] INFO [BrokerLifecycleManager id=2] Unable to register broker 2 because the controller returned error DUPLICATE_BROKER_REGISTRATION (kafka.server.BrokerLifecycleManager)
[2025-08-10 11:33:11,548] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2025-08-10 11:33:11,551] INFO [MetadataLoader id=2] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:11,569] INFO [MetadataLoader id=3] InitializeNewPublishers: initializing SnapshotGenerator with a snapshot at offset 37207 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:11,570] INFO [MetadataLoader id=3] InitializeNewPublishers: initializing FeaturesPublisher with a snapshot at offset 37207 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:11,570] INFO [MetadataLoader id=3] InitializeNewPublishers: initializing DynamicConfigPublisher controller id=3 with a snapshot at offset 37207 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:11,572] INFO [MetadataLoader id=3] InitializeNewPublishers: initializing DynamicClientQuotaPublisher controller id=3 with a snapshot at offset 37207 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:11,573] INFO [MetadataLoader id=3] InitializeNewPublishers: initializing ScramPublisher controller id=3 with a snapshot at offset 37207 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:11,576] INFO [MetadataLoader id=3] InitializeNewPublishers: initializing DelegationTokenPublisher controller id=3 with a snapshot at offset 37207 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:11,578] INFO [MetadataLoader id=3] InitializeNewPublishers: initializing ControllerMetadataMetricsPublisher with a snapshot at offset 37207 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:11,580] INFO [MetadataLoader id=3] InitializeNewPublishers: initializing AclPublisher controller id=3 with a snapshot at offset 37207 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:11,580] INFO [MetadataLoader id=3] InitializeNewPublishers: initializing BrokerMetadataPublisher with a snapshot at offset 37207 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:11,582] INFO [BrokerMetadataPublisher id=3] Publishing initial metadata at offset OffsetAndEpoch(offset=37207, epoch=12) with metadata.version 3.6-IV2. (kafka.server.metadata.BrokerMetadataPublisher)
[2025-08-10 11:33:11,585] INFO Loading logs from log dirs ArraySeq(C:\tmp\server-3\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:11,615] INFO [BrokerLifecycleManager id=3] Unable to register broker 3 because the controller returned error DUPLICATE_BROKER_REGISTRATION (kafka.server.BrokerLifecycleManager)
[2025-08-10 11:33:11,616] INFO [BrokerLifecycleManager id=2] Unable to register broker 2 because the controller returned error DUPLICATE_BROKER_REGISTRATION (kafka.server.BrokerLifecycleManager)
[2025-08-10 11:33:11,621] INFO Recovering 19 logs from C:\tmp\server-3\kraft-combined-logs since no clean shutdown file was found (kafka.log.LogManager)
[2025-08-10 11:33:11,659] INFO [LogLoader partition=new-employee-created-event-0, dir=C:\tmp\server-3\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for new-employee-created-event-0. (kafka.log.LogLoader)
[2025-08-10 11:33:11,660] INFO [MetadataLoader id=2] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:11,660] INFO [LogLoader partition=new-employee-created-event-0, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,661] INFO [LogLoader partition=new-employee-created-event-0, dir=C:\tmp\server-3\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,661] INFO Deleted producer state snapshot C:\tmp\server-3\kraft-combined-logs\new-employee-created-event-0\00000000000000000004.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2025-08-10 11:33:11,662] INFO [LogLoader partition=new-employee-created-event-0, dir=C:\tmp\server-3\kraft-combined-logs] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,674] INFO [ProducerStateManager partition=new-employee-created-event-0]Wrote producer snapshot at offset 4 with 4 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-08-10 11:33:11,681] INFO [LogLoader partition=new-employee-created-event-0, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 4 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,681] INFO [LogLoader partition=new-employee-created-event-0, dir=C:\tmp\server-3\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 4 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,681] INFO [ProducerStateManager partition=new-employee-created-event-0]Loading producer state from snapshot file 'SnapshotFile(offset=4, file=C:\tmp\server-3\kraft-combined-logs\new-employee-created-event-0\00000000000000000004.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-08-10 11:33:11,689] INFO [LogLoader partition=new-employee-created-event-0, dir=C:\tmp\server-3\kraft-combined-logs] Producer state recovery took 8ms for snapshot load and 0ms for segment recovery from offset 4 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,703] INFO Completed load of Log(dir=C:\tmp\server-3\kraft-combined-logs\new-employee-created-event-0, topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, topic=new-employee-created-event, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=4) with 1 segments, local-log-start-offset 0 and log-end-offset 4 in 74ms (1/19 completed in C:\tmp\server-3\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:11,727] INFO [LogLoader partition=new-employee-created-event-1, dir=C:\tmp\server-3\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for new-employee-created-event-1. (kafka.log.LogLoader)
[2025-08-10 11:33:11,729] INFO [LogLoader partition=new-employee-created-event-1, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,729] INFO [LogLoader partition=new-employee-created-event-1, dir=C:\tmp\server-3\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,729] INFO Deleted producer state snapshot C:\tmp\server-3\kraft-combined-logs\new-employee-created-event-1\00000000000000000006.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2025-08-10 11:33:11,729] INFO [LogLoader partition=new-employee-created-event-1, dir=C:\tmp\server-3\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,733] INFO [ProducerStateManager partition=new-employee-created-event-1]Wrote producer snapshot at offset 6 with 3 producer ids in 1 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-08-10 11:33:11,740] INFO [LogLoader partition=new-employee-created-event-1, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,741] INFO [LogLoader partition=new-employee-created-event-1, dir=C:\tmp\server-3\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 6 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,741] INFO [ProducerStateManager partition=new-employee-created-event-1]Loading producer state from snapshot file 'SnapshotFile(offset=6, file=C:\tmp\server-3\kraft-combined-logs\new-employee-created-event-1\00000000000000000006.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-08-10 11:33:11,748] INFO [LogLoader partition=new-employee-created-event-1, dir=C:\tmp\server-3\kraft-combined-logs] Producer state recovery took 7ms for snapshot load and 0ms for segment recovery from offset 6 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,751] INFO Completed load of Log(dir=C:\tmp\server-3\kraft-combined-logs\new-employee-created-event-1, topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, topic=new-employee-created-event, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=6) with 1 segments, local-log-start-offset 0 and log-end-offset 6 in 47ms (2/19 completed in C:\tmp\server-3\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:11,754] INFO [ControllerServer id=1] Starting controller (kafka.server.ControllerServer)
[2025-08-10 11:33:11,766] INFO [LogLoader partition=new-employee-created-event-2, dir=C:\tmp\server-3\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for new-employee-created-event-2. (kafka.log.LogLoader)
[2025-08-10 11:33:11,766] INFO [LogLoader partition=new-employee-created-event-2, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,766] INFO [LogLoader partition=new-employee-created-event-2, dir=C:\tmp\server-3\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,767] INFO Deleted producer state snapshot C:\tmp\server-3\kraft-combined-logs\new-employee-created-event-2\00000000000000000003.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2025-08-10 11:33:11,767] INFO [LogLoader partition=new-employee-created-event-2, dir=C:\tmp\server-3\kraft-combined-logs] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,768] INFO [MetadataLoader id=2] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:11,769] INFO [RaftManager id=3] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:11,769] WARN [RaftManager id=3] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:11,774] INFO [ProducerStateManager partition=new-employee-created-event-2]Wrote producer snapshot at offset 3 with 2 producer ids in 1 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-08-10 11:33:11,775] INFO authorizerStart completed for endpoint CONTROLLER. Endpoint is now READY. (org.apache.kafka.server.network.EndpointReadyFutures)
[2025-08-10 11:33:11,777] INFO [LogLoader partition=new-employee-created-event-2, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,777] INFO [LogLoader partition=new-employee-created-event-2, dir=C:\tmp\server-3\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 3 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,777] INFO [ProducerStateManager partition=new-employee-created-event-2]Loading producer state from snapshot file 'SnapshotFile(offset=3, file=C:\tmp\server-3\kraft-combined-logs\new-employee-created-event-2\00000000000000000003.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-08-10 11:33:11,785] INFO [LogLoader partition=new-employee-created-event-2, dir=C:\tmp\server-3\kraft-combined-logs] Producer state recovery took 8ms for snapshot load and 0ms for segment recovery from offset 3 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,788] INFO Completed load of Log(dir=C:\tmp\server-3\kraft-combined-logs\new-employee-created-event-2, topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, topic=new-employee-created-event, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=3) with 1 segments, local-log-start-offset 0 and log-end-offset 3 in 38ms (3/19 completed in C:\tmp\server-3\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:11,803] INFO [LogLoader partition=__consumer_offsets-0, dir=C:\tmp\server-3\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-0. (kafka.log.LogLoader)
[2025-08-10 11:33:11,803] INFO [LogLoader partition=__consumer_offsets-0, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,804] INFO [LogLoader partition=__consumer_offsets-0, dir=C:\tmp\server-3\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,804] INFO [LogLoader partition=__consumer_offsets-0, dir=C:\tmp\server-3\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,810] INFO [LogLoader partition=__consumer_offsets-0, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,810] INFO [LogLoader partition=__consumer_offsets-0, dir=C:\tmp\server-3\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,810] INFO [LogLoader partition=__consumer_offsets-0, dir=C:\tmp\server-3\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,817] INFO [BrokerLifecycleManager id=3] Unable to register broker 3 because the controller returned error DUPLICATE_BROKER_REGISTRATION (kafka.server.BrokerLifecycleManager)
[2025-08-10 11:33:11,817] INFO [BrokerLifecycleManager id=2] Unable to register broker 2 because the controller returned error DUPLICATE_BROKER_REGISTRATION (kafka.server.BrokerLifecycleManager)
[2025-08-10 11:33:11,820] INFO Completed load of Log(dir=C:\tmp\server-3\kraft-combined-logs\__consumer_offsets-0, topicId=6g4QFzBuRcCnDf0xnmyCwA, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 32ms (4/19 completed in C:\tmp\server-3\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:11,828] INFO [LogLoader partition=__consumer_offsets-10, dir=C:\tmp\server-3\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-10. (kafka.log.LogLoader)
[2025-08-10 11:33:11,828] INFO [LogLoader partition=__consumer_offsets-10, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,829] INFO [LogLoader partition=__consumer_offsets-10, dir=C:\tmp\server-3\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,829] INFO [LogLoader partition=__consumer_offsets-10, dir=C:\tmp\server-3\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,837] INFO [LogLoader partition=__consumer_offsets-10, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,837] INFO [LogLoader partition=__consumer_offsets-10, dir=C:\tmp\server-3\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,837] INFO [LogLoader partition=__consumer_offsets-10, dir=C:\tmp\server-3\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,839] INFO Completed load of Log(dir=C:\tmp\server-3\kraft-combined-logs\__consumer_offsets-10, topicId=6g4QFzBuRcCnDf0xnmyCwA, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 18ms (5/19 completed in C:\tmp\server-3\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:11,848] INFO [RaftManager id=2] High watermark set to Optional[LogOffsetMetadata(offset=37208, metadata=Optional.empty)] for the first time for epoch 12 (org.apache.kafka.raft.FollowerState)
[2025-08-10 11:33:11,850] INFO [LogLoader partition=__consumer_offsets-12, dir=C:\tmp\server-3\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-12. (kafka.log.LogLoader)
[2025-08-10 11:33:11,851] INFO [LogLoader partition=__consumer_offsets-12, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,851] INFO [LogLoader partition=__consumer_offsets-12, dir=C:\tmp\server-3\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,851] INFO [LogLoader partition=__consumer_offsets-12, dir=C:\tmp\server-3\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,860] INFO [LogLoader partition=__consumer_offsets-12, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,860] INFO [LogLoader partition=__consumer_offsets-12, dir=C:\tmp\server-3\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,860] INFO [LogLoader partition=__consumer_offsets-12, dir=C:\tmp\server-3\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,863] INFO Completed load of Log(dir=C:\tmp\server-3\kraft-combined-logs\__consumer_offsets-12, topicId=6g4QFzBuRcCnDf0xnmyCwA, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 24ms (6/19 completed in C:\tmp\server-3\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:11,868] INFO [MetadataLoader id=2] handleLoadSnapshot(00000000000000031328-0000000001): incrementing HandleLoadSnapshotCount to 1. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:11,873] INFO [LogLoader partition=__consumer_offsets-16, dir=C:\tmp\server-3\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-16. (kafka.log.LogLoader)
[2025-08-10 11:33:11,874] INFO [LogLoader partition=__consumer_offsets-16, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,874] INFO [LogLoader partition=__consumer_offsets-16, dir=C:\tmp\server-3\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,874] INFO [LogLoader partition=__consumer_offsets-16, dir=C:\tmp\server-3\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,886] INFO [LogLoader partition=__consumer_offsets-16, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,886] INFO [LogLoader partition=__consumer_offsets-16, dir=C:\tmp\server-3\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,886] INFO [LogLoader partition=__consumer_offsets-16, dir=C:\tmp\server-3\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,889] INFO Completed load of Log(dir=C:\tmp\server-3\kraft-combined-logs\__consumer_offsets-16, topicId=6g4QFzBuRcCnDf0xnmyCwA, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 26ms (7/19 completed in C:\tmp\server-3\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:11,890] INFO [MetadataLoader id=2] handleLoadSnapshot(00000000000000031328-0000000001): generated a metadata delta between offset -1 and this snapshot in 22072 us. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:11,892] INFO [MetadataLoader id=2] maybePublishMetadata(SNAPSHOT): The loader is still catching up because we have loaded up to offset 31327, but the high water mark is 37208 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:11,893] INFO [MetadataLoader id=2] initializeNewPublishers: The loader is still catching up because we have loaded up to offset 31327, but the high water mark is 37208 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:11,900] INFO [LogLoader partition=__consumer_offsets-19, dir=C:\tmp\server-3\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-19. (kafka.log.LogLoader)
[2025-08-10 11:33:11,901] INFO [LogLoader partition=__consumer_offsets-19, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,901] INFO [LogLoader partition=__consumer_offsets-19, dir=C:\tmp\server-3\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,903] INFO [LogLoader partition=__consumer_offsets-19, dir=C:\tmp\server-3\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,913] INFO [LogLoader partition=__consumer_offsets-19, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,913] INFO [LogLoader partition=__consumer_offsets-19, dir=C:\tmp\server-3\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,913] INFO [LogLoader partition=__consumer_offsets-19, dir=C:\tmp\server-3\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,916] INFO Completed load of Log(dir=C:\tmp\server-3\kraft-combined-logs\__consumer_offsets-19, topicId=6g4QFzBuRcCnDf0xnmyCwA, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 26ms (8/19 completed in C:\tmp\server-3\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:11,928] INFO [LogLoader partition=__consumer_offsets-22, dir=C:\tmp\server-3\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-22. (kafka.log.LogLoader)
[2025-08-10 11:33:11,929] INFO [LogLoader partition=__consumer_offsets-22, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,929] INFO [LogLoader partition=__consumer_offsets-22, dir=C:\tmp\server-3\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,929] INFO [LogLoader partition=__consumer_offsets-22, dir=C:\tmp\server-3\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,942] INFO [LogLoader partition=__consumer_offsets-22, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,942] INFO [LogLoader partition=__consumer_offsets-22, dir=C:\tmp\server-3\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,943] INFO [LogLoader partition=__consumer_offsets-22, dir=C:\tmp\server-3\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,948] INFO Completed load of Log(dir=C:\tmp\server-3\kraft-combined-logs\__consumer_offsets-22, topicId=6g4QFzBuRcCnDf0xnmyCwA, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 32ms (9/19 completed in C:\tmp\server-3\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:11,960] INFO [LogLoader partition=__consumer_offsets-24, dir=C:\tmp\server-3\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-24. (kafka.log.LogLoader)
[2025-08-10 11:33:11,962] INFO [LogLoader partition=__consumer_offsets-24, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,962] INFO [LogLoader partition=__consumer_offsets-24, dir=C:\tmp\server-3\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,962] INFO [LogLoader partition=__consumer_offsets-24, dir=C:\tmp\server-3\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,975] INFO [LogLoader partition=__consumer_offsets-24, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,976] INFO [LogLoader partition=__consumer_offsets-24, dir=C:\tmp\server-3\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,976] INFO [LogLoader partition=__consumer_offsets-24, dir=C:\tmp\server-3\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:11,980] INFO Completed load of Log(dir=C:\tmp\server-3\kraft-combined-logs\__consumer_offsets-24, topicId=6g4QFzBuRcCnDf0xnmyCwA, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 31ms (10/19 completed in C:\tmp\server-3\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:12,000] INFO [LogLoader partition=__consumer_offsets-27, dir=C:\tmp\server-3\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-27. (kafka.log.LogLoader)
[2025-08-10 11:33:12,001] INFO [LogLoader partition=__consumer_offsets-27, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,003] INFO [LogLoader partition=__consumer_offsets-27, dir=C:\tmp\server-3\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,003] INFO [LogLoader partition=__consumer_offsets-27, dir=C:\tmp\server-3\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,004] INFO [MetadataLoader id=2] maybePublishMetadata(LOG_DELTA): The loader is still catching up because we have loaded up to offset 37206, but the high water mark is 37208 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:12,005] INFO [MetadataLoader id=2] initializeNewPublishers: The loader is still catching up because we have loaded up to offset 37206, but the high water mark is 37208 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:12,006] INFO [MetadataLoader id=2] maybePublishMetadata(LOG_DELTA): The loader finished catching up to the current high water mark of 37208 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:12,013] INFO [LogLoader partition=__consumer_offsets-27, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,013] INFO [LogLoader partition=__consumer_offsets-27, dir=C:\tmp\server-3\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,013] INFO [LogLoader partition=__consumer_offsets-27, dir=C:\tmp\server-3\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,017] INFO Completed load of Log(dir=C:\tmp\server-3\kraft-combined-logs\__consumer_offsets-27, topicId=6g4QFzBuRcCnDf0xnmyCwA, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 30ms (11/19 completed in C:\tmp\server-3\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:12,028] INFO [LogLoader partition=__consumer_offsets-3, dir=C:\tmp\server-3\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-3. (kafka.log.LogLoader)
[2025-08-10 11:33:12,029] INFO [LogLoader partition=__consumer_offsets-3, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,029] INFO [LogLoader partition=__consumer_offsets-3, dir=C:\tmp\server-3\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,029] INFO [LogLoader partition=__consumer_offsets-3, dir=C:\tmp\server-3\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,040] INFO [LogLoader partition=__consumer_offsets-3, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,040] INFO [LogLoader partition=__consumer_offsets-3, dir=C:\tmp\server-3\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,041] INFO [LogLoader partition=__consumer_offsets-3, dir=C:\tmp\server-3\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,044] INFO Completed load of Log(dir=C:\tmp\server-3\kraft-combined-logs\__consumer_offsets-3, topicId=6g4QFzBuRcCnDf0xnmyCwA, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 26ms (12/19 completed in C:\tmp\server-3\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:12,053] INFO [LogLoader partition=__consumer_offsets-32, dir=C:\tmp\server-3\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-32. (kafka.log.LogLoader)
[2025-08-10 11:33:12,054] INFO [LogLoader partition=__consumer_offsets-32, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,054] INFO [LogLoader partition=__consumer_offsets-32, dir=C:\tmp\server-3\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,054] INFO [LogLoader partition=__consumer_offsets-32, dir=C:\tmp\server-3\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,062] INFO [LogLoader partition=__consumer_offsets-32, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,063] INFO [LogLoader partition=__consumer_offsets-32, dir=C:\tmp\server-3\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,063] INFO [LogLoader partition=__consumer_offsets-32, dir=C:\tmp\server-3\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,066] INFO Completed load of Log(dir=C:\tmp\server-3\kraft-combined-logs\__consumer_offsets-32, topicId=6g4QFzBuRcCnDf0xnmyCwA, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 22ms (13/19 completed in C:\tmp\server-3\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:12,075] INFO [LogLoader partition=__consumer_offsets-33, dir=C:\tmp\server-3\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-33. (kafka.log.LogLoader)
[2025-08-10 11:33:12,076] INFO [LogLoader partition=__consumer_offsets-33, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,076] INFO [LogLoader partition=__consumer_offsets-33, dir=C:\tmp\server-3\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,076] INFO [LogLoader partition=__consumer_offsets-33, dir=C:\tmp\server-3\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,086] INFO [LogLoader partition=__consumer_offsets-33, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,086] INFO [LogLoader partition=__consumer_offsets-33, dir=C:\tmp\server-3\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,086] INFO [LogLoader partition=__consumer_offsets-33, dir=C:\tmp\server-3\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,089] INFO Completed load of Log(dir=C:\tmp\server-3\kraft-combined-logs\__consumer_offsets-33, topicId=6g4QFzBuRcCnDf0xnmyCwA, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 21ms (14/19 completed in C:\tmp\server-3\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:12,098] INFO [LogLoader partition=__consumer_offsets-37, dir=C:\tmp\server-3\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-37. (kafka.log.LogLoader)
[2025-08-10 11:33:12,100] INFO [LogLoader partition=__consumer_offsets-37, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,100] INFO [LogLoader partition=__consumer_offsets-37, dir=C:\tmp\server-3\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,100] INFO [LogLoader partition=__consumer_offsets-37, dir=C:\tmp\server-3\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,111] INFO [LogLoader partition=__consumer_offsets-37, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,112] INFO [LogLoader partition=__consumer_offsets-37, dir=C:\tmp\server-3\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,112] INFO [LogLoader partition=__consumer_offsets-37, dir=C:\tmp\server-3\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,112] INFO [MetadataLoader id=2] InitializeNewPublishers: initializing SnapshotGenerator with a snapshot at offset 37207 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:12,113] INFO [MetadataLoader id=2] InitializeNewPublishers: initializing FeaturesPublisher with a snapshot at offset 37207 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:12,113] INFO [MetadataLoader id=2] InitializeNewPublishers: initializing DynamicConfigPublisher controller id=2 with a snapshot at offset 37207 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:12,115] INFO Completed load of Log(dir=C:\tmp\server-3\kraft-combined-logs\__consumer_offsets-37, topicId=6g4QFzBuRcCnDf0xnmyCwA, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 25ms (15/19 completed in C:\tmp\server-3\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:12,115] INFO [MetadataLoader id=2] InitializeNewPublishers: initializing DynamicClientQuotaPublisher controller id=2 with a snapshot at offset 37207 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:12,116] INFO [MetadataLoader id=2] InitializeNewPublishers: initializing ScramPublisher controller id=2 with a snapshot at offset 37207 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:12,119] INFO [MetadataLoader id=2] InitializeNewPublishers: initializing DelegationTokenPublisher controller id=2 with a snapshot at offset 37207 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:12,122] INFO [MetadataLoader id=2] InitializeNewPublishers: initializing ControllerMetadataMetricsPublisher with a snapshot at offset 37207 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:12,123] INFO [MetadataLoader id=2] InitializeNewPublishers: initializing AclPublisher controller id=2 with a snapshot at offset 37207 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:12,124] INFO [MetadataLoader id=2] InitializeNewPublishers: initializing BrokerMetadataPublisher with a snapshot at offset 37207 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:12,125] INFO [LogLoader partition=__consumer_offsets-39, dir=C:\tmp\server-3\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-39. (kafka.log.LogLoader)
[2025-08-10 11:33:12,125] INFO [BrokerMetadataPublisher id=2] Publishing initial metadata at offset OffsetAndEpoch(offset=37207, epoch=12) with metadata.version 3.6-IV2. (kafka.server.metadata.BrokerMetadataPublisher)
[2025-08-10 11:33:12,127] INFO [LogLoader partition=__consumer_offsets-39, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,127] INFO [LogLoader partition=__consumer_offsets-39, dir=C:\tmp\server-3\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,127] INFO [LogLoader partition=__consumer_offsets-39, dir=C:\tmp\server-3\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,131] INFO Loading logs from log dirs ArraySeq(C:\tmp\server-2\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:12,137] INFO [LogLoader partition=__consumer_offsets-39, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,137] INFO [LogLoader partition=__consumer_offsets-39, dir=C:\tmp\server-3\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,137] INFO [LogLoader partition=__consumer_offsets-39, dir=C:\tmp\server-3\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,141] INFO Completed load of Log(dir=C:\tmp\server-3\kraft-combined-logs\__consumer_offsets-39, topicId=6g4QFzBuRcCnDf0xnmyCwA, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 27ms (16/19 completed in C:\tmp\server-3\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:12,151] INFO [LogLoader partition=__consumer_offsets-44, dir=C:\tmp\server-3\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-44. (kafka.log.LogLoader)
[2025-08-10 11:33:12,152] INFO [LogLoader partition=__consumer_offsets-44, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,152] INFO [LogLoader partition=__consumer_offsets-44, dir=C:\tmp\server-3\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,152] INFO [LogLoader partition=__consumer_offsets-44, dir=C:\tmp\server-3\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,157] INFO Recovering 20 logs from C:\tmp\server-2\kraft-combined-logs since no clean shutdown file was found (kafka.log.LogManager)
[2025-08-10 11:33:12,162] INFO [LogLoader partition=__consumer_offsets-44, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,163] INFO [LogLoader partition=__consumer_offsets-44, dir=C:\tmp\server-3\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,163] INFO [LogLoader partition=__consumer_offsets-44, dir=C:\tmp\server-3\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,166] INFO Completed load of Log(dir=C:\tmp\server-3\kraft-combined-logs\__consumer_offsets-44, topicId=6g4QFzBuRcCnDf0xnmyCwA, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 24ms (17/19 completed in C:\tmp\server-3\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:12,177] INFO [LogLoader partition=__consumer_offsets-45, dir=C:\tmp\server-3\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-45. (kafka.log.LogLoader)
[2025-08-10 11:33:12,178] INFO [LogLoader partition=__consumer_offsets-45, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,179] INFO [LogLoader partition=__consumer_offsets-45, dir=C:\tmp\server-3\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,179] INFO [LogLoader partition=__consumer_offsets-45, dir=C:\tmp\server-3\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,186] INFO [LogLoader partition=new-employee-created-event-0, dir=C:\tmp\server-2\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for new-employee-created-event-0. (kafka.log.LogLoader)
[2025-08-10 11:33:12,187] INFO [LogLoader partition=new-employee-created-event-0, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,187] INFO [LogLoader partition=new-employee-created-event-0, dir=C:\tmp\server-2\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,188] INFO Deleted producer state snapshot C:\tmp\server-2\kraft-combined-logs\new-employee-created-event-0\00000000000000000004.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2025-08-10 11:33:12,189] INFO [LogLoader partition=new-employee-created-event-0, dir=C:\tmp\server-2\kraft-combined-logs] Producer state recovery took 2ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,189] INFO [LogLoader partition=__consumer_offsets-45, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,189] INFO [LogLoader partition=__consumer_offsets-45, dir=C:\tmp\server-3\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,189] INFO [LogLoader partition=__consumer_offsets-45, dir=C:\tmp\server-3\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,193] INFO Completed load of Log(dir=C:\tmp\server-3\kraft-combined-logs\__consumer_offsets-45, topicId=6g4QFzBuRcCnDf0xnmyCwA, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 27ms (18/19 completed in C:\tmp\server-3\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:12,200] INFO [ProducerStateManager partition=new-employee-created-event-0]Wrote producer snapshot at offset 4 with 4 producer ids in 1 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-08-10 11:33:12,201] INFO [LogLoader partition=__consumer_offsets-8, dir=C:\tmp\server-3\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-8. (kafka.log.LogLoader)
[2025-08-10 11:33:12,202] INFO [LogLoader partition=__consumer_offsets-8, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,203] INFO [LogLoader partition=__consumer_offsets-8, dir=C:\tmp\server-3\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,203] INFO [LogLoader partition=__consumer_offsets-8, dir=C:\tmp\server-3\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,210] INFO [LogLoader partition=new-employee-created-event-0, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 4 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,210] INFO [LogLoader partition=new-employee-created-event-0, dir=C:\tmp\server-2\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 4 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,210] INFO [ProducerStateManager partition=new-employee-created-event-0]Loading producer state from snapshot file 'SnapshotFile(offset=4, file=C:\tmp\server-2\kraft-combined-logs\new-employee-created-event-0\00000000000000000004.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-08-10 11:33:12,212] INFO [LogLoader partition=new-employee-created-event-0, dir=C:\tmp\server-2\kraft-combined-logs] Producer state recovery took 2ms for snapshot load and 0ms for segment recovery from offset 4 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,213] INFO [LogLoader partition=__consumer_offsets-8, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,213] INFO [LogLoader partition=__consumer_offsets-8, dir=C:\tmp\server-3\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,213] INFO [LogLoader partition=__consumer_offsets-8, dir=C:\tmp\server-3\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,217] INFO Completed load of Log(dir=C:\tmp\server-3\kraft-combined-logs\__consumer_offsets-8, topicId=6g4QFzBuRcCnDf0xnmyCwA, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 23ms (19/19 completed in C:\tmp\server-3\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:12,219] INFO Completed load of Log(dir=C:\tmp\server-2\kraft-combined-logs\new-employee-created-event-0, topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, topic=new-employee-created-event, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=4) with 1 segments, local-log-start-offset 0 and log-end-offset 4 in 52ms (1/20 completed in C:\tmp\server-2\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:12,220] INFO Loaded 19 logs in 633ms (unclean log dirs = ArrayBuffer(C:\tmp\server-3\kraft-combined-logs)) (kafka.log.LogManager)
[2025-08-10 11:33:12,222] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2025-08-10 11:33:12,222] INFO [RaftManager id=3] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:12,223] WARN [RaftManager id=3] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:12,223] INFO [BrokerLifecycleManager id=3] Unable to register broker 3 because the controller returned error DUPLICATE_BROKER_REGISTRATION (kafka.server.BrokerLifecycleManager)
[2025-08-10 11:33:12,224] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2025-08-10 11:33:12,234] INFO [LogLoader partition=new-employee-created-event-1, dir=C:\tmp\server-2\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for new-employee-created-event-1. (kafka.log.LogLoader)
[2025-08-10 11:33:12,236] INFO [LogLoader partition=new-employee-created-event-1, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,237] INFO [LogLoader partition=new-employee-created-event-1, dir=C:\tmp\server-2\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,238] INFO Deleted producer state snapshot C:\tmp\server-2\kraft-combined-logs\new-employee-created-event-1\00000000000000000006.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2025-08-10 11:33:12,239] INFO [LogLoader partition=new-employee-created-event-1, dir=C:\tmp\server-2\kraft-combined-logs] Producer state recovery took 2ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,239] INFO [BrokerLifecycleManager id=2] Unable to register broker 2 because the controller returned error DUPLICATE_BROKER_REGISTRATION (kafka.server.BrokerLifecycleManager)
[2025-08-10 11:33:12,251] INFO [ProducerStateManager partition=new-employee-created-event-1]Wrote producer snapshot at offset 6 with 3 producer ids in 5 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-08-10 11:33:12,260] INFO [LogLoader partition=new-employee-created-event-1, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,261] INFO [LogLoader partition=new-employee-created-event-1, dir=C:\tmp\server-2\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 6 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,261] INFO [ProducerStateManager partition=new-employee-created-event-1]Loading producer state from snapshot file 'SnapshotFile(offset=6, file=C:\tmp\server-2\kraft-combined-logs\new-employee-created-event-1\00000000000000000006.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-08-10 11:33:12,263] INFO [LogLoader partition=new-employee-created-event-1, dir=C:\tmp\server-2\kraft-combined-logs] Producer state recovery took 2ms for snapshot load and 0ms for segment recovery from offset 6 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,269] INFO Completed load of Log(dir=C:\tmp\server-2\kraft-combined-logs\new-employee-created-event-1, topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, topic=new-employee-created-event, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=6) with 1 segments, local-log-start-offset 0 and log-end-offset 6 in 48ms (2/20 completed in C:\tmp\server-2\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:12,278] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2025-08-10 11:33:12,286] INFO [LogLoader partition=new-employee-created-event-2, dir=C:\tmp\server-2\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for new-employee-created-event-2. (kafka.log.LogLoader)
[2025-08-10 11:33:12,287] INFO [LogLoader partition=new-employee-created-event-2, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,288] INFO [LogLoader partition=new-employee-created-event-2, dir=C:\tmp\server-2\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,289] INFO Deleted producer state snapshot C:\tmp\server-2\kraft-combined-logs\new-employee-created-event-2\00000000000000000003.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2025-08-10 11:33:12,289] INFO [LogLoader partition=new-employee-created-event-2, dir=C:\tmp\server-2\kraft-combined-logs] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,301] INFO [ProducerStateManager partition=new-employee-created-event-2]Wrote producer snapshot at offset 3 with 2 producer ids in 3 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-08-10 11:33:12,313] INFO [LogLoader partition=new-employee-created-event-2, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,314] INFO [LogLoader partition=new-employee-created-event-2, dir=C:\tmp\server-2\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 3 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,314] INFO [ProducerStateManager partition=new-employee-created-event-2]Loading producer state from snapshot file 'SnapshotFile(offset=3, file=C:\tmp\server-2\kraft-combined-logs\new-employee-created-event-2\00000000000000000003.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-08-10 11:33:12,317] INFO [LogLoader partition=new-employee-created-event-2, dir=C:\tmp\server-2\kraft-combined-logs] Producer state recovery took 3ms for snapshot load and 0ms for segment recovery from offset 3 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,321] INFO Completed load of Log(dir=C:\tmp\server-2\kraft-combined-logs\new-employee-created-event-2, topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, topic=new-employee-created-event, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=3) with 1 segments, local-log-start-offset 0 and log-end-offset 3 in 51ms (3/20 completed in C:\tmp\server-2\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:12,347] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2025-08-10 11:33:12,351] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-08-10 11:33:12,353] INFO [GroupCoordinator 3]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:12,351] INFO [AddPartitionsToTxnSenderThread-3]: Starting (kafka.server.AddPartitionsToTxnManager)
[2025-08-10 11:33:12,360] INFO [GroupCoordinator 3]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:12,362] INFO [TransactionCoordinator id=3] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-08-10 11:33:12,365] INFO [TxnMarkerSenderThread-3]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-08-10 11:33:12,365] INFO [TransactionCoordinator id=3] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-08-10 11:33:12,367] INFO [BrokerMetadataPublisher id=3] Updating metadata.version to 14 at offset OffsetAndEpoch(offset=37207, epoch=12). (kafka.server.metadata.BrokerMetadataPublisher)
[2025-08-10 11:33:12,378] INFO [LogLoader partition=__consumer_offsets-11, dir=C:\tmp\server-2\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-11. (kafka.log.LogLoader)
[2025-08-10 11:33:12,379] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(__consumer_offsets-16, __consumer_offsets-45, __consumer_offsets-12, __consumer_offsets-44, new-employee-created-event-1, __consumer_offsets-10, __consumer_offsets-24, __consumer_offsets-22, __consumer_offsets-19, __consumer_offsets-0, __consumer_offsets-32, __consumer_offsets-27, __consumer_offsets-39, __consumer_offsets-8, __consumer_offsets-37, __consumer_offsets-3, __consumer_offsets-33) (kafka.server.ReplicaFetcherManager)
[2025-08-10 11:33:12,379] INFO [LogLoader partition=__consumer_offsets-11, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,380] INFO [LogLoader partition=__consumer_offsets-11, dir=C:\tmp\server-2\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,381] INFO Deleted producer state snapshot C:\tmp\server-2\kraft-combined-logs\__consumer_offsets-11\00000000000000000022.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2025-08-10 11:33:12,382] INFO [LogLoader partition=__consumer_offsets-11, dir=C:\tmp\server-2\kraft-combined-logs] Producer state recovery took 2ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,394] INFO [ProducerStateManager partition=__consumer_offsets-11]Wrote producer snapshot at offset 22 with 0 producer ids in 3 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-08-10 11:33:12,407] INFO [LogLoader partition=__consumer_offsets-11, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 22 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,407] INFO [LogLoader partition=__consumer_offsets-11, dir=C:\tmp\server-2\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 22 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,407] INFO [ProducerStateManager partition=__consumer_offsets-11]Loading producer state from snapshot file 'SnapshotFile(offset=22, file=C:\tmp\server-2\kraft-combined-logs\__consumer_offsets-11\00000000000000000022.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-08-10 11:33:12,409] INFO [LogLoader partition=__consumer_offsets-11, dir=C:\tmp\server-2\kraft-combined-logs] Producer state recovery took 2ms for snapshot load and 0ms for segment recovery from offset 22 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,413] INFO Completed load of Log(dir=C:\tmp\server-2\kraft-combined-logs\__consumer_offsets-11, topicId=6g4QFzBuRcCnDf0xnmyCwA, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=22) with 1 segments, local-log-start-offset 0 and log-end-offset 22 in 92ms (4/20 completed in C:\tmp\server-2\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:12,422] INFO [LogLoader partition=__consumer_offsets-13, dir=C:\tmp\server-2\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-13. (kafka.log.LogLoader)
[2025-08-10 11:33:12,423] INFO [LogLoader partition=__consumer_offsets-13, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,423] INFO [LogLoader partition=__consumer_offsets-13, dir=C:\tmp\server-2\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,423] INFO [LogLoader partition=__consumer_offsets-13, dir=C:\tmp\server-2\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,424] INFO [SocketServer listenerType=CONTROLLER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(CONTROLLER) (kafka.network.SocketServer)
[2025-08-10 11:33:12,428] INFO [SharedServer id=1] Starting SharedServer (kafka.server.SharedServer)
[2025-08-10 11:33:12,428] INFO [Partition __consumer_offsets-16 broker=3] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:33:12,434] INFO [LogLoader partition=__consumer_offsets-13, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,434] INFO [LogLoader partition=__consumer_offsets-13, dir=C:\tmp\server-2\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,435] INFO [LogLoader partition=__consumer_offsets-13, dir=C:\tmp\server-2\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,439] INFO Completed load of Log(dir=C:\tmp\server-2\kraft-combined-logs\__consumer_offsets-13, topicId=6g4QFzBuRcCnDf0xnmyCwA, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 24ms (5/20 completed in C:\tmp\server-2\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:12,441] INFO [Partition __consumer_offsets-45 broker=3] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:33:12,447] INFO [Partition __consumer_offsets-12 broker=3] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:33:12,449] INFO [LogLoader partition=__consumer_offsets-15, dir=C:\tmp\server-2\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-15. (kafka.log.LogLoader)
[2025-08-10 11:33:12,451] INFO [LogLoader partition=__consumer_offsets-15, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,451] INFO [LogLoader partition=__consumer_offsets-15, dir=C:\tmp\server-2\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,451] INFO [LogLoader partition=__consumer_offsets-15, dir=C:\tmp\server-2\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,452] INFO [Partition __consumer_offsets-44 broker=3] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:33:12,459] INFO [Partition new-employee-created-event-1 broker=3] Log loaded for partition new-employee-created-event-1 with initial high watermark 6 (kafka.cluster.Partition)
[2025-08-10 11:33:12,461] INFO [LogLoader partition=__consumer_offsets-15, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,462] INFO [LogLoader partition=__consumer_offsets-15, dir=C:\tmp\server-2\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,462] INFO [LogLoader partition=__consumer_offsets-15, dir=C:\tmp\server-2\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,465] INFO Completed load of Log(dir=C:\tmp\server-2\kraft-combined-logs\__consumer_offsets-15, topicId=6g4QFzBuRcCnDf0xnmyCwA, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 26ms (6/20 completed in C:\tmp\server-2\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:12,466] INFO [Partition __consumer_offsets-10 broker=3] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:33:12,471] INFO [Partition __consumer_offsets-24 broker=3] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:33:12,474] INFO [LogLoader partition=__consumer_offsets-2, dir=C:\tmp\server-2\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-2. (kafka.log.LogLoader)
[2025-08-10 11:33:12,474] INFO [Partition __consumer_offsets-22 broker=3] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:33:12,474] INFO [LogLoader partition=__consumer_offsets-2, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,476] INFO [LogLoader partition=__consumer_offsets-2, dir=C:\tmp\server-2\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,476] INFO [LogLoader partition=__consumer_offsets-2, dir=C:\tmp\server-2\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,479] INFO [Partition __consumer_offsets-19 broker=3] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:33:12,485] INFO [LogLoader partition=__consumer_offsets-2, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,485] INFO [Partition __consumer_offsets-0 broker=3] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:33:12,485] INFO [LogLoader partition=__consumer_offsets-2, dir=C:\tmp\server-2\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,486] INFO [LogLoader partition=__consumer_offsets-2, dir=C:\tmp\server-2\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,489] INFO Completed load of Log(dir=C:\tmp\server-2\kraft-combined-logs\__consumer_offsets-2, topicId=6g4QFzBuRcCnDf0xnmyCwA, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 23ms (7/20 completed in C:\tmp\server-2\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:12,490] INFO [Partition __consumer_offsets-32 broker=3] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:33:12,494] INFO [Partition __consumer_offsets-27 broker=3] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:33:12,496] INFO [LogLoader partition=__consumer_offsets-20, dir=C:\tmp\server-2\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-20. (kafka.log.LogLoader)
[2025-08-10 11:33:12,498] INFO [LogLoader partition=__consumer_offsets-20, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,499] INFO [LogLoader partition=__consumer_offsets-20, dir=C:\tmp\server-2\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,499] INFO [LogLoader partition=__consumer_offsets-20, dir=C:\tmp\server-2\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,500] INFO [Partition __consumer_offsets-39 broker=3] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:33:12,505] INFO [Partition __consumer_offsets-8 broker=3] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:33:12,510] INFO [LogLoader partition=__consumer_offsets-20, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,510] INFO [LogLoader partition=__consumer_offsets-20, dir=C:\tmp\server-2\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,510] INFO [Partition __consumer_offsets-37 broker=3] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:33:12,511] INFO [LogLoader partition=__consumer_offsets-20, dir=C:\tmp\server-2\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,517] INFO Completed load of Log(dir=C:\tmp\server-2\kraft-combined-logs\__consumer_offsets-20, topicId=6g4QFzBuRcCnDf0xnmyCwA, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 27ms (8/20 completed in C:\tmp\server-2\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:12,518] INFO [Partition __consumer_offsets-3 broker=3] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:33:12,521] INFO [Partition __consumer_offsets-33 broker=3] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:33:12,527] INFO [LogLoader partition=__consumer_offsets-23, dir=C:\tmp\server-2\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-23. (kafka.log.LogLoader)
[2025-08-10 11:33:12,528] INFO [LogLoader partition=__consumer_offsets-23, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,528] INFO [LogLoader partition=__consumer_offsets-23, dir=C:\tmp\server-2\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,528] INFO [LogLoader partition=__consumer_offsets-23, dir=C:\tmp\server-2\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,530] INFO [Partition new-employee-created-event-2 broker=3] Log loaded for partition new-employee-created-event-2 with initial high watermark 3 (kafka.cluster.Partition)
[2025-08-10 11:33:12,534] INFO [Partition new-employee-created-event-0 broker=3] Log loaded for partition new-employee-created-event-0 with initial high watermark 4 (kafka.cluster.Partition)
[2025-08-10 11:33:12,535] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(new-employee-created-event-0, new-employee-created-event-2) (kafka.server.ReplicaFetcherManager)
[2025-08-10 11:33:12,540] INFO [LogLoader partition=__consumer_offsets-23, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,540] INFO [LogLoader partition=__consumer_offsets-23, dir=C:\tmp\server-2\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,540] INFO [LogLoader partition=__consumer_offsets-23, dir=C:\tmp\server-2\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,544] INFO Completed load of Log(dir=C:\tmp\server-2\kraft-combined-logs\__consumer_offsets-23, topicId=6g4QFzBuRcCnDf0xnmyCwA, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 26ms (9/20 completed in C:\tmp\server-2\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:12,547] INFO [LogLoader partition=__cluster_metadata-0, dir=C:\tmp\server-1\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for __cluster_metadata-0. (kafka.log.LogLoader)
[2025-08-10 11:33:12,550] INFO [LogLoader partition=__cluster_metadata-0, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,551] INFO [LogLoader partition=__cluster_metadata-0, dir=C:\tmp\server-1\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,553] INFO Deleted producer state snapshot C:\tmp\server-1\kraft-combined-logs\__cluster_metadata-0\00000000000000032392.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2025-08-10 11:33:12,554] INFO [LogLoader partition=__cluster_metadata-0, dir=C:\tmp\server-1\kraft-combined-logs] Producer state recovery took 2ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,566] INFO [ReplicaFetcherThread-0-2]: Starting (kafka.server.ReplicaFetcherThread)
[2025-08-10 11:33:12,569] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker 2 for partitions HashMap(new-employee-created-event-0 -> InitialFetchState(Some(x5jQ0eyLQ6GD6TVf1uZ4Lw),BrokerEndPoint(id=2, host=localhost:9094),8,4)) (kafka.server.ReplicaFetcherManager)
[2025-08-10 11:33:12,576] INFO [LogLoader partition=__consumer_offsets-26, dir=C:\tmp\server-2\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-26. (kafka.log.LogLoader)
[2025-08-10 11:33:12,576] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker 1 for partitions HashMap(new-employee-created-event-2 -> InitialFetchState(Some(x5jQ0eyLQ6GD6TVf1uZ4Lw),BrokerEndPoint(id=1, host=localhost:9092),7,3)) (kafka.server.ReplicaFetcherManager)
[2025-08-10 11:33:12,576] INFO [ReplicaFetcherThread-0-1]: Starting (kafka.server.ReplicaFetcherThread)
[2025-08-10 11:33:12,577] INFO [LogLoader partition=__consumer_offsets-26, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,579] INFO [LogLoader partition=__consumer_offsets-26, dir=C:\tmp\server-2\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,579] INFO Deleted producer state snapshot C:\tmp\server-2\kraft-combined-logs\__consumer_offsets-26\00000000000000000012.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2025-08-10 11:33:12,580] INFO [LogLoader partition=__consumer_offsets-26, dir=C:\tmp\server-2\kraft-combined-logs] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,583] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:12,583] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:12,583] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:12,583] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Connection to node 2 (localhost/127.0.0.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:12,583] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:12,583] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:12,584] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9094 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:12,584] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:12,589] INFO [ProducerStateManager partition=__consumer_offsets-26]Wrote producer snapshot at offset 12 with 0 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-08-10 11:33:12,592] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-2=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=3, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[7], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:12,592] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-0=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=4, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[8], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9094 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:12,600] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 16 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:12,602] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:12,602] INFO [LogLoader partition=__consumer_offsets-26, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 12 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,603] INFO [LogLoader partition=__consumer_offsets-26, dir=C:\tmp\server-2\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 12 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,603] INFO [ProducerStateManager partition=__consumer_offsets-26]Loading producer state from snapshot file 'SnapshotFile(offset=12, file=C:\tmp\server-2\kraft-combined-logs\__consumer_offsets-26\00000000000000000012.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-08-10 11:33:12,603] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 45 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:12,604] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:12,604] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 12 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:12,604] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:12,604] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 44 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:12,604] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:12,604] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 10 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:12,604] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:12,604] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 24 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:12,604] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:12,604] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 22 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:12,606] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:12,606] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 19 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:12,606] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:12,606] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 0 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:12,606] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:12,607] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 32 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:12,607] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:12,607] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 27 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:12,607] INFO [LogLoader partition=__consumer_offsets-26, dir=C:\tmp\server-2\kraft-combined-logs] Producer state recovery took 3ms for snapshot load and 1ms for segment recovery from offset 12 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,607] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:12,607] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 39 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:12,607] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:12,607] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 8 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:12,607] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:12,607] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 37 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:12,607] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:12,607] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 3 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:12,607] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:12,608] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 33 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:12,609] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:12,611] INFO Completed load of Log(dir=C:\tmp\server-2\kraft-combined-logs\__consumer_offsets-26, topicId=6g4QFzBuRcCnDf0xnmyCwA, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=12) with 1 segments, local-log-start-offset 0 and log-end-offset 12 in 67ms (10/20 completed in C:\tmp\server-2\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:12,615] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-16 in 10 milliseconds for epoch 4, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:12,616] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-45 in 12 milliseconds for epoch 4, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:12,616] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-12 in 12 milliseconds for epoch 4, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:12,617] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-44 in 13 milliseconds for epoch 4, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:12,617] INFO [DynamicConfigPublisher broker id=3] Updating topic new-employee-created-event with new configuration : min.insync.replicas -> 2 (kafka.server.metadata.DynamicConfigPublisher)
[2025-08-10 11:33:12,617] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-10 in 13 milliseconds for epoch 4, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:12,618] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-24 in 14 milliseconds for epoch 4, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:12,619] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-22 in 13 milliseconds for epoch 4, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:12,620] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-19 in 14 milliseconds for epoch 4, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:12,620] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-0 in 13 milliseconds for epoch 4, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:12,623] INFO [LogLoader partition=__consumer_offsets-29, dir=C:\tmp\server-2\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-29. (kafka.log.LogLoader)
[2025-08-10 11:33:12,624] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-32 in 17 milliseconds for epoch 4, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:12,625] INFO [LogLoader partition=__consumer_offsets-29, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,626] INFO [LogLoader partition=__consumer_offsets-29, dir=C:\tmp\server-2\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,626] INFO [LogLoader partition=__consumer_offsets-29, dir=C:\tmp\server-2\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,629] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-27 in 22 milliseconds for epoch 4, of which 21 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:12,631] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-39 in 24 milliseconds for epoch 4, of which 23 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:12,632] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-8 in 25 milliseconds for epoch 4, of which 24 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:12,633] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-37 in 26 milliseconds for epoch 4, of which 26 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:12,635] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-3 in 27 milliseconds for epoch 4, of which 26 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:12,636] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-33 in 26 milliseconds for epoch 4, of which 26 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:12,643] INFO [DynamicConfigPublisher broker id=3] Updating topic __consumer_offsets with new configuration : compression.type -> producer,cleanup.policy -> compact,segment.bytes -> 104857600 (kafka.server.metadata.DynamicConfigPublisher)
[2025-08-10 11:33:12,647] INFO [LogLoader partition=__consumer_offsets-29, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,647] INFO [LogLoader partition=__consumer_offsets-29, dir=C:\tmp\server-2\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,647] INFO [LogLoader partition=__consumer_offsets-29, dir=C:\tmp\server-2\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,653] INFO Completed load of Log(dir=C:\tmp\server-2\kraft-combined-logs\__consumer_offsets-29, topicId=6g4QFzBuRcCnDf0xnmyCwA, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 41ms (11/20 completed in C:\tmp\server-2\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:12,667] INFO [LogLoader partition=__consumer_offsets-31, dir=C:\tmp\server-2\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-31. (kafka.log.LogLoader)
[2025-08-10 11:33:12,669] INFO [LogLoader partition=__consumer_offsets-31, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,669] INFO [LogLoader partition=__consumer_offsets-31, dir=C:\tmp\server-2\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,669] INFO [LogLoader partition=__consumer_offsets-31, dir=C:\tmp\server-2\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,684] INFO [LogLoader partition=__consumer_offsets-31, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,684] INFO [LogLoader partition=__consumer_offsets-31, dir=C:\tmp\server-2\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,685] INFO [LogLoader partition=__consumer_offsets-31, dir=C:\tmp\server-2\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,691] INFO Completed load of Log(dir=C:\tmp\server-2\kraft-combined-logs\__consumer_offsets-31, topicId=6g4QFzBuRcCnDf0xnmyCwA, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 37ms (12/20 completed in C:\tmp\server-2\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:12,705] INFO [LogLoader partition=__consumer_offsets-34, dir=C:\tmp\server-2\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-34. (kafka.log.LogLoader)
[2025-08-10 11:33:12,706] INFO [LogLoader partition=__consumer_offsets-34, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,707] INFO [LogLoader partition=__consumer_offsets-34, dir=C:\tmp\server-2\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,707] INFO [LogLoader partition=__consumer_offsets-34, dir=C:\tmp\server-2\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,717] INFO [LogLoader partition=__consumer_offsets-34, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,718] INFO [LogLoader partition=__consumer_offsets-34, dir=C:\tmp\server-2\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,718] INFO [LogLoader partition=__consumer_offsets-34, dir=C:\tmp\server-2\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,722] INFO Completed load of Log(dir=C:\tmp\server-2\kraft-combined-logs\__consumer_offsets-34, topicId=6g4QFzBuRcCnDf0xnmyCwA, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 31ms (13/20 completed in C:\tmp\server-2\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:12,730] INFO [LogLoader partition=__consumer_offsets-36, dir=C:\tmp\server-2\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-36. (kafka.log.LogLoader)
[2025-08-10 11:33:12,731] INFO [LogLoader partition=__consumer_offsets-36, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,732] INFO [LogLoader partition=__consumer_offsets-36, dir=C:\tmp\server-2\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,732] INFO [LogLoader partition=__consumer_offsets-36, dir=C:\tmp\server-2\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,742] INFO [LogLoader partition=__consumer_offsets-36, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,742] INFO [LogLoader partition=__consumer_offsets-36, dir=C:\tmp\server-2\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,742] INFO [LogLoader partition=__consumer_offsets-36, dir=C:\tmp\server-2\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,746] INFO Completed load of Log(dir=C:\tmp\server-2\kraft-combined-logs\__consumer_offsets-36, topicId=6g4QFzBuRcCnDf0xnmyCwA, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 23ms (14/20 completed in C:\tmp\server-2\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:12,756] INFO [LogLoader partition=__consumer_offsets-40, dir=C:\tmp\server-2\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-40. (kafka.log.LogLoader)
[2025-08-10 11:33:12,757] INFO [LogLoader partition=__consumer_offsets-40, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,757] INFO [LogLoader partition=__consumer_offsets-40, dir=C:\tmp\server-2\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,757] INFO [LogLoader partition=__consumer_offsets-40, dir=C:\tmp\server-2\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,768] INFO [LogLoader partition=__consumer_offsets-40, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,768] INFO [LogLoader partition=__consumer_offsets-40, dir=C:\tmp\server-2\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,768] INFO [LogLoader partition=__consumer_offsets-40, dir=C:\tmp\server-2\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,771] INFO Completed load of Log(dir=C:\tmp\server-2\kraft-combined-logs\__consumer_offsets-40, topicId=6g4QFzBuRcCnDf0xnmyCwA, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 25ms (15/20 completed in C:\tmp\server-2\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:12,783] INFO [LogLoader partition=__consumer_offsets-43, dir=C:\tmp\server-2\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-43. (kafka.log.LogLoader)
[2025-08-10 11:33:12,783] INFO [RaftManager id=3] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:12,783] WARN [RaftManager id=3] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:12,784] INFO [LogLoader partition=__consumer_offsets-43, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,785] INFO [LogLoader partition=__consumer_offsets-43, dir=C:\tmp\server-2\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,785] INFO [LogLoader partition=__consumer_offsets-43, dir=C:\tmp\server-2\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,799] INFO [LogLoader partition=__consumer_offsets-43, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,799] INFO [LogLoader partition=__consumer_offsets-43, dir=C:\tmp\server-2\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,799] INFO [LogLoader partition=__consumer_offsets-43, dir=C:\tmp\server-2\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,802] INFO Completed load of Log(dir=C:\tmp\server-2\kraft-combined-logs\__consumer_offsets-43, topicId=6g4QFzBuRcCnDf0xnmyCwA, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 31ms (16/20 completed in C:\tmp\server-2\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:12,810] INFO [LogLoader partition=__consumer_offsets-47, dir=C:\tmp\server-2\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-47. (kafka.log.LogLoader)
[2025-08-10 11:33:12,812] INFO [LogLoader partition=__consumer_offsets-47, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,812] INFO [LogLoader partition=__consumer_offsets-47, dir=C:\tmp\server-2\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,812] INFO [LogLoader partition=__consumer_offsets-47, dir=C:\tmp\server-2\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,823] INFO [LogLoader partition=__consumer_offsets-47, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,823] INFO [LogLoader partition=__consumer_offsets-47, dir=C:\tmp\server-2\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,823] INFO [LogLoader partition=__consumer_offsets-47, dir=C:\tmp\server-2\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,828] INFO Completed load of Log(dir=C:\tmp\server-2\kraft-combined-logs\__consumer_offsets-47, topicId=6g4QFzBuRcCnDf0xnmyCwA, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 25ms (17/20 completed in C:\tmp\server-2\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:12,836] INFO [LogLoader partition=__consumer_offsets-49, dir=C:\tmp\server-2\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-49. (kafka.log.LogLoader)
[2025-08-10 11:33:12,837] INFO [LogLoader partition=__consumer_offsets-49, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,837] INFO [LogLoader partition=__consumer_offsets-49, dir=C:\tmp\server-2\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,837] INFO [LogLoader partition=__consumer_offsets-49, dir=C:\tmp\server-2\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,847] INFO [LogLoader partition=__consumer_offsets-49, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,847] INFO [LogLoader partition=__consumer_offsets-49, dir=C:\tmp\server-2\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,847] INFO [LogLoader partition=__consumer_offsets-49, dir=C:\tmp\server-2\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,849] INFO Completed load of Log(dir=C:\tmp\server-2\kraft-combined-logs\__consumer_offsets-49, topicId=6g4QFzBuRcCnDf0xnmyCwA, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 22ms (18/20 completed in C:\tmp\server-2\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:12,859] INFO [LogLoader partition=__consumer_offsets-5, dir=C:\tmp\server-2\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-5. (kafka.log.LogLoader)
[2025-08-10 11:33:12,860] INFO [LogLoader partition=__consumer_offsets-5, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,860] INFO [LogLoader partition=__consumer_offsets-5, dir=C:\tmp\server-2\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,861] INFO [LogLoader partition=__consumer_offsets-5, dir=C:\tmp\server-2\kraft-combined-logs] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,869] INFO [LogLoader partition=__consumer_offsets-5, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,870] INFO [LogLoader partition=__consumer_offsets-5, dir=C:\tmp\server-2\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,870] INFO [LogLoader partition=__consumer_offsets-5, dir=C:\tmp\server-2\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,873] INFO Completed load of Log(dir=C:\tmp\server-2\kraft-combined-logs\__consumer_offsets-5, topicId=6g4QFzBuRcCnDf0xnmyCwA, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 22ms (19/20 completed in C:\tmp\server-2\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:12,882] INFO [LogLoader partition=__consumer_offsets-6, dir=C:\tmp\server-2\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-6. (kafka.log.LogLoader)
[2025-08-10 11:33:12,883] INFO [LogLoader partition=__consumer_offsets-6, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,883] INFO [LogLoader partition=__consumer_offsets-6, dir=C:\tmp\server-2\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,884] INFO [LogLoader partition=__consumer_offsets-6, dir=C:\tmp\server-2\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,897] INFO [LogLoader partition=__consumer_offsets-6, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,897] INFO [LogLoader partition=__consumer_offsets-6, dir=C:\tmp\server-2\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,897] INFO [LogLoader partition=__consumer_offsets-6, dir=C:\tmp\server-2\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,900] INFO Completed load of Log(dir=C:\tmp\server-2\kraft-combined-logs\__consumer_offsets-6, topicId=6g4QFzBuRcCnDf0xnmyCwA, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 27ms (20/20 completed in C:\tmp\server-2\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:12,908] INFO Loaded 20 logs in 775ms (unclean log dirs = ArrayBuffer(C:\tmp\server-2\kraft-combined-logs)) (kafka.log.LogManager)
[2025-08-10 11:33:12,909] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2025-08-10 11:33:12,910] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2025-08-10 11:33:12,956] INFO [ProducerStateManager partition=__cluster_metadata-0]Wrote producer snapshot at offset 37207 with 0 producer ids in 5 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-08-10 11:33:12,994] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2025-08-10 11:33:12,994] INFO [LogLoader partition=__cluster_metadata-0, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 37207 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,995] INFO [LogLoader partition=__cluster_metadata-0, dir=C:\tmp\server-1\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 37207 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:12,995] INFO [ProducerStateManager partition=__cluster_metadata-0]Loading producer state from snapshot file 'SnapshotFile(offset=37207, file=C:\tmp\server-1\kraft-combined-logs\__cluster_metadata-0\00000000000000037207.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-08-10 11:33:12,996] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-08-10 11:33:12,997] INFO [AddPartitionsToTxnSenderThread-2]: Starting (kafka.server.AddPartitionsToTxnManager)
[2025-08-10 11:33:13,000] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:13,001] INFO [LogLoader partition=__cluster_metadata-0, dir=C:\tmp\server-1\kraft-combined-logs] Producer state recovery took 6ms for snapshot load and 0ms for segment recovery from offset 37207 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:13,003] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:13,004] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-08-10 11:33:13,006] INFO [TxnMarkerSenderThread-2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-08-10 11:33:13,006] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-08-10 11:33:13,008] INFO [BrokerMetadataPublisher id=2] Updating metadata.version to 14 at offset OffsetAndEpoch(offset=37207, epoch=12). (kafka.server.metadata.BrokerMetadataPublisher)
[2025-08-10 11:33:13,018] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(__consumer_offsets-15, __consumer_offsets-47, __consumer_offsets-13, new-employee-created-event-0, __consumer_offsets-11, __consumer_offsets-43, __consumer_offsets-23, __consumer_offsets-20, __consumer_offsets-49, __consumer_offsets-31, __consumer_offsets-29, __consumer_offsets-26, __consumer_offsets-40, __consumer_offsets-5, __consumer_offsets-6, __consumer_offsets-36, __consumer_offsets-2, __consumer_offsets-34) (kafka.server.ReplicaFetcherManager)
[2025-08-10 11:33:13,036] INFO [BrokerLifecycleManager id=3] Unable to register broker 3 because the controller returned error DUPLICATE_BROKER_REGISTRATION (kafka.server.BrokerLifecycleManager)
[2025-08-10 11:33:13,038] INFO [BrokerLifecycleManager id=2] Unable to register broker 2 because the controller returned error DUPLICATE_BROKER_REGISTRATION (kafka.server.BrokerLifecycleManager)
[2025-08-10 11:33:13,064] INFO Initialized snapshots with IDs SortedSet(OffsetAndEpoch(offset=7135, epoch=1), OffsetAndEpoch(offset=14219, epoch=1), OffsetAndEpoch(offset=21300, epoch=1), OffsetAndEpoch(offset=28390, epoch=1), OffsetAndEpoch(offset=31329, epoch=1)) from C:\tmp\server-1\kraft-combined-logs\__cluster_metadata-0 (kafka.raft.KafkaMetadataLog$)
[2025-08-10 11:33:13,066] INFO [Partition __consumer_offsets-15 broker=2] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:33:13,074] INFO [Partition __consumer_offsets-47 broker=2] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:33:13,078] INFO [Partition __consumer_offsets-13 broker=2] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:33:13,079] INFO [raft-expiration-reaper]: Starting (kafka.raft.TimingWheelExpirationService$ExpiredOperationReaper)
[2025-08-10 11:33:13,083] INFO [Partition new-employee-created-event-0 broker=2] Log loaded for partition new-employee-created-event-0 with initial high watermark 4 (kafka.cluster.Partition)
[2025-08-10 11:33:13,088] INFO [Partition __consumer_offsets-11 broker=2] Log loaded for partition __consumer_offsets-11 with initial high watermark 22 (kafka.cluster.Partition)
[2025-08-10 11:33:13,092] INFO [Partition __consumer_offsets-43 broker=2] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:33:13,097] INFO [Partition __consumer_offsets-23 broker=2] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:33:13,100] INFO [Partition __consumer_offsets-20 broker=2] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:33:13,104] INFO [Partition __consumer_offsets-49 broker=2] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:33:13,108] INFO [Partition __consumer_offsets-31 broker=2] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:33:13,111] INFO [Partition __consumer_offsets-29 broker=2] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:33:13,116] INFO [Partition __consumer_offsets-26 broker=2] Log loaded for partition __consumer_offsets-26 with initial high watermark 12 (kafka.cluster.Partition)
[2025-08-10 11:33:13,121] INFO [Partition __consumer_offsets-40 broker=2] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:33:13,125] INFO [Partition __consumer_offsets-5 broker=2] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:33:13,129] INFO [Partition __consumer_offsets-6 broker=2] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:33:13,133] INFO [Partition __consumer_offsets-36 broker=2] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:33:13,136] INFO [Partition __consumer_offsets-2 broker=2] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:33:13,141] INFO [Partition __consumer_offsets-34 broker=2] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:33:13,148] INFO [Partition new-employee-created-event-2 broker=2] Log loaded for partition new-employee-created-event-2 with initial high watermark 3 (kafka.cluster.Partition)
[2025-08-10 11:33:13,150] INFO [Partition new-employee-created-event-1 broker=2] Log loaded for partition new-employee-created-event-1 with initial high watermark 6 (kafka.cluster.Partition)
[2025-08-10 11:33:13,151] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(new-employee-created-event-2, new-employee-created-event-1) (kafka.server.ReplicaFetcherManager)
[2025-08-10 11:33:13,172] INFO [ReplicaFetcherThread-0-3]: Starting (kafka.server.ReplicaFetcherThread)
[2025-08-10 11:33:13,175] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 3 for partitions HashMap(new-employee-created-event-1 -> InitialFetchState(Some(x5jQ0eyLQ6GD6TVf1uZ4Lw),BrokerEndPoint(id=3, host=localhost:9096),5,6)) (kafka.server.ReplicaFetcherManager)
[2025-08-10 11:33:13,180] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 1 for partitions HashMap(new-employee-created-event-2 -> InitialFetchState(Some(x5jQ0eyLQ6GD6TVf1uZ4Lw),BrokerEndPoint(id=1, host=localhost:9092),7,3)) (kafka.server.ReplicaFetcherManager)
[2025-08-10 11:33:13,180] INFO [ReplicaFetcherThread-0-1]: Starting (kafka.server.ReplicaFetcherThread)
[2025-08-10 11:33:13,185] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:13,185] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:13,185] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:13,185] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Connection to node 3 (localhost/127.0.0.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:13,185] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:13,185] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:13,186] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 3: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9096 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:13,186] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:13,190] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-1=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=6, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[5], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9096 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:13,190] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-2=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=3, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[7], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:13,197] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 15 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:13,198] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:13,199] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 47 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:13,200] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:13,200] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 13 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:13,200] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:13,201] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 11 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:13,201] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:13,201] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 43 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:13,201] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:13,201] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 23 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:13,201] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:13,201] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 20 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:13,201] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:13,202] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 49 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:13,202] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:13,202] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 31 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:13,202] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:13,202] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 29 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:13,202] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:13,202] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 26 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:13,202] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:13,202] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 40 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:13,203] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:13,203] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 5 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:13,203] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:13,203] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 6 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:13,203] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:13,203] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 36 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:13,203] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:13,203] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 2 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:13,203] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:13,203] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 34 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:13,203] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:13,206] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-15 in 7 milliseconds for epoch 4, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:13,207] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-47 in 7 milliseconds for epoch 4, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:13,208] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-13 in 6 milliseconds for epoch 4, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:13,209] INFO [DynamicConfigPublisher broker id=2] Updating topic new-employee-created-event with new configuration : min.insync.replicas -> 2 (kafka.server.metadata.DynamicConfigPublisher)
[2025-08-10 11:33:13,217] INFO [DynamicConfigPublisher broker id=2] Updating topic __consumer_offsets with new configuration : compression.type -> producer,cleanup.policy -> compact,segment.bytes -> 104857600 (kafka.server.metadata.DynamicConfigPublisher)
[2025-08-10 11:33:13,231] INFO Loaded member MemberMetadata(memberId=consumer-new-employee-created-event-1-83335fbb-1145-4cba-b23e-d24c97c8924d, groupInstanceId=None, clientId=consumer-new-employee-created-event-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group new-employee-created-event with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2025-08-10 11:33:13,245] INFO Loaded member MemberMetadata(memberId=consumer-new-employee-created-event-2-873684dc-c1e5-46ee-9625-6842871ae3e4, groupInstanceId=None, clientId=consumer-new-employee-created-event-2, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group new-employee-created-event with generation 3. (kafka.coordinator.group.GroupMetadata$)
[2025-08-10 11:33:13,245] INFO Loaded member MemberMetadata(memberId=consumer-new-employee-created-event-1-94b45227-4390-4459-96f0-b6c48921a680, groupInstanceId=None, clientId=consumer-new-employee-created-event-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group new-employee-created-event with generation 5. (kafka.coordinator.group.GroupMetadata$)
[2025-08-10 11:33:13,246] INFO Loaded member MemberMetadata(memberId=consumer-new-employee-created-event-1-94b45227-4390-4459-96f0-b6c48921a680, groupInstanceId=None, clientId=consumer-new-employee-created-event-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group new-employee-created-event with generation 6. (kafka.coordinator.group.GroupMetadata$)
[2025-08-10 11:33:13,246] INFO Loaded member MemberMetadata(memberId=consumer-new-employee-created-event-1-87edfd1d-8d78-45f7-8336-09cb36b45a30, groupInstanceId=None, clientId=consumer-new-employee-created-event-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group new-employee-created-event with generation 6. (kafka.coordinator.group.GroupMetadata$)
[2025-08-10 11:33:13,247] INFO Loaded member MemberMetadata(memberId=consumer-new-employee-created-event-1-94b45227-4390-4459-96f0-b6c48921a680, groupInstanceId=None, clientId=consumer-new-employee-created-event-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group new-employee-created-event with generation 7. (kafka.coordinator.group.GroupMetadata$)
[2025-08-10 11:33:13,251] INFO [GroupCoordinator 2]: Loading group metadata for new-employee-created-event with generation 8 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:13,252] INFO [RaftManager id=1] Completed transition to ResignedState(localId=1, epoch=11, voters=[1, 2, 3], electionTimeoutMs=1068, unackedVoters=[2, 3], preferredSuccessors=[]) from null (org.apache.kafka.raft.QuorumState)
[2025-08-10 11:33:13,252] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-11 in 51 milliseconds for epoch 4, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:13,252] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-43 in 51 milliseconds for epoch 4, of which 51 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:13,253] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-23 in 52 milliseconds for epoch 4, of which 52 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:13,253] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-20 in 52 milliseconds for epoch 4, of which 52 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:13,253] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-49 in 51 milliseconds for epoch 4, of which 51 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:13,254] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-31 in 52 milliseconds for epoch 4, of which 51 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:13,254] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-29 in 52 milliseconds for epoch 4, of which 52 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:13,255] INFO [kafka-1-raft-io-thread]: Starting (kafka.raft.KafkaRaftManager$RaftIoThread)
[2025-08-10 11:33:13,255] INFO [kafka-1-raft-outbound-request-thread]: Starting (kafka.raft.RaftSendThread)
[2025-08-10 11:33:13,258] INFO Loaded member MemberMetadata(memberId=consumer-new-employee-created-event-2-2-2307fe4f-3c55-425e-bebb-1711511a567b, groupInstanceId=None, clientId=consumer-new-employee-created-event-2-2, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group new-employee-created-event-2 with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2025-08-10 11:33:13,259] INFO Loaded member MemberMetadata(memberId=consumer-new-employee-created-event-2-3-557a1ed6-93ef-4f87-8f31-b897df06a44f, groupInstanceId=None, clientId=consumer-new-employee-created-event-2-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group new-employee-created-event-2 with generation 3. (kafka.coordinator.group.GroupMetadata$)
[2025-08-10 11:33:13,259] INFO Loaded member MemberMetadata(memberId=consumer-new-employee-created-event-2-3-e432c907-03e5-48bc-aa35-b2be72397e83, groupInstanceId=None, clientId=consumer-new-employee-created-event-2-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group new-employee-created-event-2 with generation 5. (kafka.coordinator.group.GroupMetadata$)
[2025-08-10 11:33:13,260] INFO [GroupCoordinator 2]: Loading group metadata for new-employee-created-event-2 with generation 6 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:13,260] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-26 in 58 milliseconds for epoch 4, of which 52 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:13,261] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-40 in 58 milliseconds for epoch 4, of which 58 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:13,261] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-5 in 58 milliseconds for epoch 4, of which 58 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:13,261] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-6 in 58 milliseconds for epoch 4, of which 58 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:13,261] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-36 in 58 milliseconds for epoch 4, of which 58 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:13,262] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-2 in 59 milliseconds for epoch 4, of which 59 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:13,262] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-34 in 58 milliseconds for epoch 4, of which 58 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:13,286] INFO [MetadataLoader id=1] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:13,288] INFO [RaftManager id=1] Registered the listener org.apache.kafka.image.loader.MetadataLoader@1228981101 (org.apache.kafka.raft.KafkaRaftClient)
[2025-08-10 11:33:13,288] INFO [ControllerServer id=1] Waiting for controller quorum voters future (kafka.server.ControllerServer)
[2025-08-10 11:33:13,288] INFO [ControllerServer id=1] Finished waiting for controller quorum voters future (kafka.server.ControllerServer)
[2025-08-10 11:33:13,330] INFO [RaftManager id=1] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=12, leaderId=3, voters=[1, 2, 3], highWatermark=Optional.empty, fetchingSnapshot=Optional.empty) from ResignedState(localId=1, epoch=11, voters=[1, 2, 3], electionTimeoutMs=1068, unackedVoters=[2, 3], preferredSuccessors=[]) (org.apache.kafka.raft.QuorumState)
[2025-08-10 11:33:13,333] INFO [RaftManager id=1] Registered the listener org.apache.kafka.controller.QuorumController$QuorumMetaLogListener@110400211 (org.apache.kafka.raft.KafkaRaftClient)
[2025-08-10 11:33:13,341] INFO [controller-1-ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-08-10 11:33:13,342] INFO [controller-1-ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-08-10 11:33:13,345] INFO [controller-1-ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-08-10 11:33:13,348] INFO [controller-1-ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-08-10 11:33:13,367] INFO [LocalLog partition=__cluster_metadata-0, dir=C:\tmp\server-1\kraft-combined-logs] Rolled new log segment at offset 37207 in 11 ms. (kafka.log.LocalLog)
[2025-08-10 11:33:13,373] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-08-10 11:33:13,386] INFO [RaftManager id=1] High watermark set to Optional[LogOffsetMetadata(offset=37211, metadata=Optional.empty)] for the first time for epoch 12 (org.apache.kafka.raft.FollowerState)
[2025-08-10 11:33:13,389] INFO [MetadataLoader id=1] initializeNewPublishers: The loader is still catching up because we have loaded up to offset -1, but the high water mark is 37211 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:13,390] INFO [ControllerServer id=1] Waiting for the controller metadata publishers to be installed (kafka.server.ControllerServer)
[2025-08-10 11:33:13,390] INFO [MetadataLoader id=1] initializeNewPublishers: The loader is still catching up because we have loaded up to offset -1, but the high water mark is 37211 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:13,390] INFO [ControllerServer id=1] Finished waiting for the controller metadata publishers to be installed (kafka.server.ControllerServer)
[2025-08-10 11:33:13,391] INFO [SocketServer listenerType=CONTROLLER, nodeId=1] Enabling request processing. (kafka.network.SocketServer)
[2025-08-10 11:33:13,395] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.DataPlaneAcceptor)
[2025-08-10 11:33:13,403] INFO [ControllerServer id=1] Waiting for all of the authorizer futures to be completed (kafka.server.ControllerServer)
[2025-08-10 11:33:13,403] INFO [ControllerServer id=1] Finished waiting for all of the authorizer futures to be completed (kafka.server.ControllerServer)
[2025-08-10 11:33:13,403] INFO [ControllerServer id=1] Waiting for all of the SocketServer Acceptors to be started (kafka.server.ControllerServer)
[2025-08-10 11:33:13,403] INFO [ControllerServer id=1] Finished waiting for all of the SocketServer Acceptors to be started (kafka.server.ControllerServer)
[2025-08-10 11:33:13,405] INFO [BrokerServer id=1] Transition from SHUTDOWN to STARTING (kafka.server.BrokerServer)
[2025-08-10 11:33:13,406] INFO [BrokerServer id=1] Starting broker (kafka.server.BrokerServer)
[2025-08-10 11:33:13,412] INFO [MetadataLoader id=1] handleLoadSnapshot(00000000000000031329-0000000001): incrementing HandleLoadSnapshotCount to 1. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:13,418] INFO [broker-1-ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-08-10 11:33:13,418] INFO [broker-1-ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-08-10 11:33:13,418] INFO [broker-1-ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-08-10 11:33:13,418] INFO [broker-1-ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-08-10 11:33:13,436] INFO [MetadataLoader id=1] handleLoadSnapshot(00000000000000031329-0000000001): generated a metadata delta between offset -1 and this snapshot in 23238 us. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:13,438] INFO [MetadataLoader id=1] maybePublishMetadata(SNAPSHOT): The loader is still catching up because we have loaded up to offset 31328, but the high water mark is 37211 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:13,448] INFO [BrokerServer id=1] Waiting for controller quorum voters future (kafka.server.BrokerServer)
[2025-08-10 11:33:13,448] INFO [BrokerServer id=1] Finished waiting for controller quorum voters future (kafka.server.BrokerServer)
[2025-08-10 11:33:13,461] INFO [broker-1-to-controller-forwarding-channel-manager]: Starting (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:13,463] INFO [broker-1-to-controller-forwarding-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:13,498] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2025-08-10 11:33:13,512] INFO [SocketServer listenerType=BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2025-08-10 11:33:13,524] INFO [broker-1-to-controller-alter-partition-channel-manager]: Starting (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:13,524] INFO [broker-1-to-controller-alter-partition-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:13,537] INFO [MetadataLoader id=1] maybePublishMetadata(LOG_DELTA): The loader is still catching up because we have loaded up to offset 37206, but the high water mark is 37211 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:13,537] INFO [MetadataLoader id=1] initializeNewPublishers: The loader is still catching up because we have loaded up to offset 37206, but the high water mark is 37211 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:13,538] INFO [MetadataLoader id=1] maybePublishMetadata(LOG_DELTA): The loader finished catching up to the current high water mark of 37211 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:13,548] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-08-10 11:33:13,550] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-08-10 11:33:13,552] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-08-10 11:33:13,554] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-08-10 11:33:13,555] INFO [ExpirationReaper-1-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-08-10 11:33:13,583] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-08-10 11:33:13,583] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-08-10 11:33:13,599] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:13,599] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:13,599] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:13,599] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:13,600] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-2=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=3, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[7], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:13,614] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:13,615] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Connection to node 2 (localhost/127.0.0.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:13,615] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:13,615] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9094 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:13,616] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-0=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=4, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[8], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9094 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:13,628] INFO [broker-1-to-controller-heartbeat-channel-manager]: Starting (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:13,629] INFO [broker-1-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:13,632] INFO [BrokerLifecycleManager id=1] Incarnation d-dhMVNCQuqfFWm-Lth4BA of broker 1 in cluster lt3SeY4gSgmN81qtuDBrnQ is now STARTING. (kafka.server.BrokerLifecycleManager)
[2025-08-10 11:33:13,639] INFO [BrokerLifecycleManager id=1] Unable to register broker 1 because the controller returned error DUPLICATE_BROKER_REGISTRATION (kafka.server.BrokerLifecycleManager)
[2025-08-10 11:33:13,649] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing SnapshotGenerator with a snapshot at offset 37210 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:13,650] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing FeaturesPublisher with a snapshot at offset 37210 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:13,650] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing DynamicConfigPublisher controller id=1 with a snapshot at offset 37210 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:13,651] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing DynamicClientQuotaPublisher controller id=1 with a snapshot at offset 37210 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:13,653] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing ScramPublisher controller id=1 with a snapshot at offset 37210 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:13,654] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing DelegationTokenPublisher controller id=1 with a snapshot at offset 37210 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:13,655] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-08-10 11:33:13,657] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing ControllerMetadataMetricsPublisher with a snapshot at offset 37210 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:13,658] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing AclPublisher controller id=1 with a snapshot at offset 37210 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:13,671] INFO [BrokerServer id=1] Waiting for the broker metadata publishers to be installed (kafka.server.BrokerServer)
[2025-08-10 11:33:13,672] INFO [BrokerServer id=1] Finished waiting for the broker metadata publishers to be installed (kafka.server.BrokerServer)
[2025-08-10 11:33:13,672] INFO [BrokerServer id=1] Waiting for the controller to acknowledge that we are caught up (kafka.server.BrokerServer)
[2025-08-10 11:33:13,672] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing BrokerMetadataPublisher with a snapshot at offset 37210 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:33:13,673] INFO [BrokerMetadataPublisher id=1] Publishing initial metadata at offset OffsetAndEpoch(offset=37210, epoch=12) with metadata.version 3.6-IV2. (kafka.server.metadata.BrokerMetadataPublisher)
[2025-08-10 11:33:13,677] INFO Loading logs from log dirs ArraySeq(C:\tmp\server-1\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:13,699] INFO Recovering 20 logs from C:\tmp\server-1\kraft-combined-logs since no clean shutdown file was found (kafka.log.LogManager)
[2025-08-10 11:33:13,717] INFO [LogLoader partition=new-employee-created-event-0, dir=C:\tmp\server-1\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for new-employee-created-event-0. (kafka.log.LogLoader)
[2025-08-10 11:33:13,718] INFO [LogLoader partition=new-employee-created-event-0, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:13,718] INFO [LogLoader partition=new-employee-created-event-0, dir=C:\tmp\server-1\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:13,718] INFO Deleted producer state snapshot C:\tmp\server-1\kraft-combined-logs\new-employee-created-event-0\00000000000000000004.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2025-08-10 11:33:13,718] INFO [LogLoader partition=new-employee-created-event-0, dir=C:\tmp\server-1\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:13,726] INFO [ProducerStateManager partition=new-employee-created-event-0]Wrote producer snapshot at offset 4 with 4 producer ids in 1 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-08-10 11:33:13,734] INFO [LogLoader partition=new-employee-created-event-0, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 4 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:13,735] INFO [LogLoader partition=new-employee-created-event-0, dir=C:\tmp\server-1\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 4 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:13,735] INFO [ProducerStateManager partition=new-employee-created-event-0]Loading producer state from snapshot file 'SnapshotFile(offset=4, file=C:\tmp\server-1\kraft-combined-logs\new-employee-created-event-0\00000000000000000004.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-08-10 11:33:13,737] INFO [LogLoader partition=new-employee-created-event-0, dir=C:\tmp\server-1\kraft-combined-logs] Producer state recovery took 2ms for snapshot load and 0ms for segment recovery from offset 4 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:13,745] INFO Completed load of Log(dir=C:\tmp\server-1\kraft-combined-logs\new-employee-created-event-0, topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, topic=new-employee-created-event, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=4) with 1 segments, local-log-start-offset 0 and log-end-offset 4 in 35ms (1/20 completed in C:\tmp\server-1\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:13,745] INFO [BrokerLifecycleManager id=1] Unable to register broker 1 because the controller returned error DUPLICATE_BROKER_REGISTRATION (kafka.server.BrokerLifecycleManager)
[2025-08-10 11:33:13,755] INFO [LogLoader partition=new-employee-created-event-1, dir=C:\tmp\server-1\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for new-employee-created-event-1. (kafka.log.LogLoader)
[2025-08-10 11:33:13,756] INFO [LogLoader partition=new-employee-created-event-1, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:13,756] INFO [LogLoader partition=new-employee-created-event-1, dir=C:\tmp\server-1\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:13,758] INFO Deleted producer state snapshot C:\tmp\server-1\kraft-combined-logs\new-employee-created-event-1\00000000000000000006.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2025-08-10 11:33:13,759] INFO [LogLoader partition=new-employee-created-event-1, dir=C:\tmp\server-1\kraft-combined-logs] Producer state recovery took 3ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:13,786] INFO [ProducerStateManager partition=new-employee-created-event-1]Wrote producer snapshot at offset 6 with 3 producer ids in 18 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-08-10 11:33:13,807] INFO [LogLoader partition=new-employee-created-event-1, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:13,807] INFO [LogLoader partition=new-employee-created-event-1, dir=C:\tmp\server-1\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 6 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:13,807] INFO [ProducerStateManager partition=new-employee-created-event-1]Loading producer state from snapshot file 'SnapshotFile(offset=6, file=C:\tmp\server-1\kraft-combined-logs\new-employee-created-event-1\00000000000000000006.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-08-10 11:33:13,809] INFO [LogLoader partition=new-employee-created-event-1, dir=C:\tmp\server-1\kraft-combined-logs] Producer state recovery took 2ms for snapshot load and 0ms for segment recovery from offset 6 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:13,812] INFO Completed load of Log(dir=C:\tmp\server-1\kraft-combined-logs\new-employee-created-event-1, topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, topic=new-employee-created-event, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=6) with 1 segments, local-log-start-offset 0 and log-end-offset 6 in 68ms (2/20 completed in C:\tmp\server-1\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:13,833] INFO [LogLoader partition=new-employee-created-event-2, dir=C:\tmp\server-1\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for new-employee-created-event-2. (kafka.log.LogLoader)
[2025-08-10 11:33:13,834] INFO [LogLoader partition=new-employee-created-event-2, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:13,836] INFO [LogLoader partition=new-employee-created-event-2, dir=C:\tmp\server-1\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:13,837] INFO Deleted producer state snapshot C:\tmp\server-1\kraft-combined-logs\new-employee-created-event-2\00000000000000000003.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2025-08-10 11:33:13,837] INFO [LogLoader partition=new-employee-created-event-2, dir=C:\tmp\server-1\kraft-combined-logs] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:13,866] INFO [ProducerStateManager partition=new-employee-created-event-2]Wrote producer snapshot at offset 3 with 2 producer ids in 21 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-08-10 11:33:13,916] INFO [LogLoader partition=new-employee-created-event-2, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:13,917] INFO [LogLoader partition=new-employee-created-event-2, dir=C:\tmp\server-1\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 3 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:13,917] INFO [ProducerStateManager partition=new-employee-created-event-2]Loading producer state from snapshot file 'SnapshotFile(offset=3, file=C:\tmp\server-1\kraft-combined-logs\new-employee-created-event-2\00000000000000000003.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-08-10 11:33:13,918] INFO [LogLoader partition=new-employee-created-event-2, dir=C:\tmp\server-1\kraft-combined-logs] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 3 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:13,920] INFO Completed load of Log(dir=C:\tmp\server-1\kraft-combined-logs\new-employee-created-event-2, topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, topic=new-employee-created-event, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=3) with 1 segments, local-log-start-offset 0 and log-end-offset 3 in 109ms (3/20 completed in C:\tmp\server-1\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:13,934] INFO [LogLoader partition=__consumer_offsets-1, dir=C:\tmp\server-1\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-1. (kafka.log.LogLoader)
[2025-08-10 11:33:13,935] INFO [LogLoader partition=__consumer_offsets-1, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:13,935] INFO [LogLoader partition=__consumer_offsets-1, dir=C:\tmp\server-1\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:13,936] INFO [LogLoader partition=__consumer_offsets-1, dir=C:\tmp\server-1\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:13,944] INFO [BrokerLifecycleManager id=1] Unable to register broker 1 because the controller returned error DUPLICATE_BROKER_REGISTRATION (kafka.server.BrokerLifecycleManager)
[2025-08-10 11:33:13,963] INFO [LogLoader partition=__consumer_offsets-1, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:13,963] INFO [LogLoader partition=__consumer_offsets-1, dir=C:\tmp\server-1\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:13,963] INFO [LogLoader partition=__consumer_offsets-1, dir=C:\tmp\server-1\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:13,966] INFO Completed load of Log(dir=C:\tmp\server-1\kraft-combined-logs\__consumer_offsets-1, topicId=6g4QFzBuRcCnDf0xnmyCwA, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 44ms (4/20 completed in C:\tmp\server-1\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:13,972] INFO [LogLoader partition=__consumer_offsets-14, dir=C:\tmp\server-1\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-14. (kafka.log.LogLoader)
[2025-08-10 11:33:13,973] INFO [LogLoader partition=__consumer_offsets-14, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:13,973] INFO [LogLoader partition=__consumer_offsets-14, dir=C:\tmp\server-1\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:13,973] INFO [LogLoader partition=__consumer_offsets-14, dir=C:\tmp\server-1\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:13,999] INFO [LogLoader partition=__consumer_offsets-14, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:13,999] INFO [LogLoader partition=__consumer_offsets-14, dir=C:\tmp\server-1\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,001] INFO [LogLoader partition=__consumer_offsets-14, dir=C:\tmp\server-1\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,003] INFO Completed load of Log(dir=C:\tmp\server-1\kraft-combined-logs\__consumer_offsets-14, topicId=6g4QFzBuRcCnDf0xnmyCwA, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 37ms (5/20 completed in C:\tmp\server-1\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:14,009] INFO [LogLoader partition=__consumer_offsets-17, dir=C:\tmp\server-1\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-17. (kafka.log.LogLoader)
[2025-08-10 11:33:14,010] INFO [LogLoader partition=__consumer_offsets-17, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,010] INFO [LogLoader partition=__consumer_offsets-17, dir=C:\tmp\server-1\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,010] INFO [LogLoader partition=__consumer_offsets-17, dir=C:\tmp\server-1\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,047] INFO [LogLoader partition=__consumer_offsets-17, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,047] INFO [LogLoader partition=__consumer_offsets-17, dir=C:\tmp\server-1\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,047] INFO [LogLoader partition=__consumer_offsets-17, dir=C:\tmp\server-1\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,049] INFO Completed load of Log(dir=C:\tmp\server-1\kraft-combined-logs\__consumer_offsets-17, topicId=6g4QFzBuRcCnDf0xnmyCwA, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 47ms (6/20 completed in C:\tmp\server-1\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:14,063] INFO [LogLoader partition=__consumer_offsets-18, dir=C:\tmp\server-1\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-18. (kafka.log.LogLoader)
[2025-08-10 11:33:14,064] INFO [LogLoader partition=__consumer_offsets-18, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,065] INFO [LogLoader partition=__consumer_offsets-18, dir=C:\tmp\server-1\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,065] INFO [LogLoader partition=__consumer_offsets-18, dir=C:\tmp\server-1\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,118] INFO [LogLoader partition=__consumer_offsets-18, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,118] INFO [LogLoader partition=__consumer_offsets-18, dir=C:\tmp\server-1\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,118] INFO [LogLoader partition=__consumer_offsets-18, dir=C:\tmp\server-1\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,121] INFO Completed load of Log(dir=C:\tmp\server-1\kraft-combined-logs\__consumer_offsets-18, topicId=6g4QFzBuRcCnDf0xnmyCwA, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 72ms (7/20 completed in C:\tmp\server-1\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:14,134] INFO [LogLoader partition=__consumer_offsets-21, dir=C:\tmp\server-1\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-21. (kafka.log.LogLoader)
[2025-08-10 11:33:14,134] INFO [LogLoader partition=__consumer_offsets-21, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,135] INFO [LogLoader partition=__consumer_offsets-21, dir=C:\tmp\server-1\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,135] INFO [LogLoader partition=__consumer_offsets-21, dir=C:\tmp\server-1\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,167] INFO [LogLoader partition=__consumer_offsets-21, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,167] INFO [LogLoader partition=__consumer_offsets-21, dir=C:\tmp\server-1\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,167] INFO [LogLoader partition=__consumer_offsets-21, dir=C:\tmp\server-1\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,171] INFO Completed load of Log(dir=C:\tmp\server-1\kraft-combined-logs\__consumer_offsets-21, topicId=6g4QFzBuRcCnDf0xnmyCwA, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 49ms (8/20 completed in C:\tmp\server-1\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:14,196] INFO [LogLoader partition=__consumer_offsets-25, dir=C:\tmp\server-1\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-25. (kafka.log.LogLoader)
[2025-08-10 11:33:14,197] INFO [LogLoader partition=__consumer_offsets-25, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,197] INFO [LogLoader partition=__consumer_offsets-25, dir=C:\tmp\server-1\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,198] INFO Deleted producer state snapshot C:\tmp\server-1\kraft-combined-logs\__consumer_offsets-25\00000000000000000011.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2025-08-10 11:33:14,198] INFO [LogLoader partition=__consumer_offsets-25, dir=C:\tmp\server-1\kraft-combined-logs] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,206] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:14,206] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:14,206] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:14,206] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Connection to node 3 (localhost/127.0.0.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:14,207] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:14,207] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:14,207] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:14,207] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 3: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9096 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:14,207] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-2=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=3, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[7], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:14,207] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-1=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=6, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[5], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9096 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:14,266] INFO [ProducerStateManager partition=__consumer_offsets-25]Wrote producer snapshot at offset 11 with 0 producer ids in 59 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-08-10 11:33:14,270] INFO [LogLoader partition=__consumer_offsets-25, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 11 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,270] INFO [LogLoader partition=__consumer_offsets-25, dir=C:\tmp\server-1\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 11 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,270] INFO [ProducerStateManager partition=__consumer_offsets-25]Loading producer state from snapshot file 'SnapshotFile(offset=11, file=C:\tmp\server-1\kraft-combined-logs\__consumer_offsets-25\00000000000000000011.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-08-10 11:33:14,272] INFO [LogLoader partition=__consumer_offsets-25, dir=C:\tmp\server-1\kraft-combined-logs] Producer state recovery took 2ms for snapshot load and 0ms for segment recovery from offset 11 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,274] INFO Completed load of Log(dir=C:\tmp\server-1\kraft-combined-logs\__consumer_offsets-25, topicId=6g4QFzBuRcCnDf0xnmyCwA, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=11) with 1 segments, local-log-start-offset 0 and log-end-offset 11 in 103ms (9/20 completed in C:\tmp\server-1\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:14,281] INFO [LogLoader partition=__consumer_offsets-28, dir=C:\tmp\server-1\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-28. (kafka.log.LogLoader)
[2025-08-10 11:33:14,282] INFO [LogLoader partition=__consumer_offsets-28, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,282] INFO [LogLoader partition=__consumer_offsets-28, dir=C:\tmp\server-1\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,282] INFO [LogLoader partition=__consumer_offsets-28, dir=C:\tmp\server-1\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,289] INFO [LogLoader partition=__consumer_offsets-28, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,289] INFO [LogLoader partition=__consumer_offsets-28, dir=C:\tmp\server-1\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,289] INFO [LogLoader partition=__consumer_offsets-28, dir=C:\tmp\server-1\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,291] INFO Completed load of Log(dir=C:\tmp\server-1\kraft-combined-logs\__consumer_offsets-28, topicId=6g4QFzBuRcCnDf0xnmyCwA, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 17ms (10/20 completed in C:\tmp\server-1\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:14,297] INFO [LogLoader partition=__consumer_offsets-30, dir=C:\tmp\server-1\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-30. (kafka.log.LogLoader)
[2025-08-10 11:33:14,298] INFO [LogLoader partition=__consumer_offsets-30, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,298] INFO [LogLoader partition=__consumer_offsets-30, dir=C:\tmp\server-1\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,298] INFO [LogLoader partition=__consumer_offsets-30, dir=C:\tmp\server-1\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,305] INFO [LogLoader partition=__consumer_offsets-30, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,305] INFO [LogLoader partition=__consumer_offsets-30, dir=C:\tmp\server-1\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,305] INFO [LogLoader partition=__consumer_offsets-30, dir=C:\tmp\server-1\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,307] INFO Completed load of Log(dir=C:\tmp\server-1\kraft-combined-logs\__consumer_offsets-30, topicId=6g4QFzBuRcCnDf0xnmyCwA, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 15ms (11/20 completed in C:\tmp\server-1\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:14,313] INFO [LogLoader partition=__consumer_offsets-35, dir=C:\tmp\server-1\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-35. (kafka.log.LogLoader)
[2025-08-10 11:33:14,314] INFO [LogLoader partition=__consumer_offsets-35, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,314] INFO [LogLoader partition=__consumer_offsets-35, dir=C:\tmp\server-1\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,314] INFO [LogLoader partition=__consumer_offsets-35, dir=C:\tmp\server-1\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,320] INFO [LogLoader partition=__consumer_offsets-35, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,320] INFO [LogLoader partition=__consumer_offsets-35, dir=C:\tmp\server-1\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,320] INFO [LogLoader partition=__consumer_offsets-35, dir=C:\tmp\server-1\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,323] INFO Completed load of Log(dir=C:\tmp\server-1\kraft-combined-logs\__consumer_offsets-35, topicId=6g4QFzBuRcCnDf0xnmyCwA, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 16ms (12/20 completed in C:\tmp\server-1\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:14,329] INFO [LogLoader partition=__consumer_offsets-38, dir=C:\tmp\server-1\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-38. (kafka.log.LogLoader)
[2025-08-10 11:33:14,330] INFO [LogLoader partition=__consumer_offsets-38, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,330] INFO [LogLoader partition=__consumer_offsets-38, dir=C:\tmp\server-1\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,330] INFO [LogLoader partition=__consumer_offsets-38, dir=C:\tmp\server-1\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,336] INFO [LogLoader partition=__consumer_offsets-38, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,336] INFO [LogLoader partition=__consumer_offsets-38, dir=C:\tmp\server-1\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,336] INFO [LogLoader partition=__consumer_offsets-38, dir=C:\tmp\server-1\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,339] INFO Completed load of Log(dir=C:\tmp\server-1\kraft-combined-logs\__consumer_offsets-38, topicId=6g4QFzBuRcCnDf0xnmyCwA, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 15ms (13/20 completed in C:\tmp\server-1\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:14,344] INFO [LogLoader partition=__consumer_offsets-4, dir=C:\tmp\server-1\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-4. (kafka.log.LogLoader)
[2025-08-10 11:33:14,345] INFO [LogLoader partition=__consumer_offsets-4, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,345] INFO [LogLoader partition=__consumer_offsets-4, dir=C:\tmp\server-1\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,345] INFO [LogLoader partition=__consumer_offsets-4, dir=C:\tmp\server-1\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,348] INFO [BrokerLifecycleManager id=1] Unable to register broker 1 because the controller returned error DUPLICATE_BROKER_REGISTRATION (kafka.server.BrokerLifecycleManager)
[2025-08-10 11:33:14,353] INFO [LogLoader partition=__consumer_offsets-4, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,353] INFO [LogLoader partition=__consumer_offsets-4, dir=C:\tmp\server-1\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,353] INFO [LogLoader partition=__consumer_offsets-4, dir=C:\tmp\server-1\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,356] INFO Completed load of Log(dir=C:\tmp\server-1\kraft-combined-logs\__consumer_offsets-4, topicId=6g4QFzBuRcCnDf0xnmyCwA, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 17ms (14/20 completed in C:\tmp\server-1\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:14,363] INFO [LogLoader partition=__consumer_offsets-41, dir=C:\tmp\server-1\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-41. (kafka.log.LogLoader)
[2025-08-10 11:33:14,364] INFO [LogLoader partition=__consumer_offsets-41, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,364] INFO [LogLoader partition=__consumer_offsets-41, dir=C:\tmp\server-1\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,364] INFO [LogLoader partition=__consumer_offsets-41, dir=C:\tmp\server-1\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,370] INFO [LogLoader partition=__consumer_offsets-41, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,370] INFO [LogLoader partition=__consumer_offsets-41, dir=C:\tmp\server-1\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,370] INFO [LogLoader partition=__consumer_offsets-41, dir=C:\tmp\server-1\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,372] INFO Completed load of Log(dir=C:\tmp\server-1\kraft-combined-logs\__consumer_offsets-41, topicId=6g4QFzBuRcCnDf0xnmyCwA, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 16ms (15/20 completed in C:\tmp\server-1\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:14,378] INFO [LogLoader partition=__consumer_offsets-42, dir=C:\tmp\server-1\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-42. (kafka.log.LogLoader)
[2025-08-10 11:33:14,379] INFO [LogLoader partition=__consumer_offsets-42, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,379] INFO [LogLoader partition=__consumer_offsets-42, dir=C:\tmp\server-1\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,379] INFO [LogLoader partition=__consumer_offsets-42, dir=C:\tmp\server-1\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,385] INFO [LogLoader partition=__consumer_offsets-42, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,385] INFO [LogLoader partition=__consumer_offsets-42, dir=C:\tmp\server-1\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,385] INFO [LogLoader partition=__consumer_offsets-42, dir=C:\tmp\server-1\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,388] INFO Completed load of Log(dir=C:\tmp\server-1\kraft-combined-logs\__consumer_offsets-42, topicId=6g4QFzBuRcCnDf0xnmyCwA, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 16ms (16/20 completed in C:\tmp\server-1\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:14,393] INFO [LogLoader partition=__consumer_offsets-46, dir=C:\tmp\server-1\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-46. (kafka.log.LogLoader)
[2025-08-10 11:33:14,394] INFO [LogLoader partition=__consumer_offsets-46, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,394] INFO [LogLoader partition=__consumer_offsets-46, dir=C:\tmp\server-1\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,394] INFO [LogLoader partition=__consumer_offsets-46, dir=C:\tmp\server-1\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,399] INFO [LogLoader partition=__consumer_offsets-46, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,399] INFO [LogLoader partition=__consumer_offsets-46, dir=C:\tmp\server-1\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,399] INFO [LogLoader partition=__consumer_offsets-46, dir=C:\tmp\server-1\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,400] INFO Completed load of Log(dir=C:\tmp\server-1\kraft-combined-logs\__consumer_offsets-46, topicId=6g4QFzBuRcCnDf0xnmyCwA, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 13ms (17/20 completed in C:\tmp\server-1\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:14,406] INFO [LogLoader partition=__consumer_offsets-48, dir=C:\tmp\server-1\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-48. (kafka.log.LogLoader)
[2025-08-10 11:33:14,406] INFO [LogLoader partition=__consumer_offsets-48, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,406] INFO [LogLoader partition=__consumer_offsets-48, dir=C:\tmp\server-1\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,406] INFO [LogLoader partition=__consumer_offsets-48, dir=C:\tmp\server-1\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,413] INFO [LogLoader partition=__consumer_offsets-48, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,413] INFO [LogLoader partition=__consumer_offsets-48, dir=C:\tmp\server-1\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,413] INFO [LogLoader partition=__consumer_offsets-48, dir=C:\tmp\server-1\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,416] INFO Completed load of Log(dir=C:\tmp\server-1\kraft-combined-logs\__consumer_offsets-48, topicId=6g4QFzBuRcCnDf0xnmyCwA, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 15ms (18/20 completed in C:\tmp\server-1\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:14,421] INFO [LogLoader partition=__consumer_offsets-7, dir=C:\tmp\server-1\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-7. (kafka.log.LogLoader)
[2025-08-10 11:33:14,423] INFO [LogLoader partition=__consumer_offsets-7, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,423] INFO [LogLoader partition=__consumer_offsets-7, dir=C:\tmp\server-1\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,423] INFO [LogLoader partition=__consumer_offsets-7, dir=C:\tmp\server-1\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,428] INFO [LogLoader partition=__consumer_offsets-7, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,428] INFO [LogLoader partition=__consumer_offsets-7, dir=C:\tmp\server-1\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,428] INFO [LogLoader partition=__consumer_offsets-7, dir=C:\tmp\server-1\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,431] INFO Completed load of Log(dir=C:\tmp\server-1\kraft-combined-logs\__consumer_offsets-7, topicId=6g4QFzBuRcCnDf0xnmyCwA, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 14ms (19/20 completed in C:\tmp\server-1\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:14,435] INFO [LogLoader partition=__consumer_offsets-9, dir=C:\tmp\server-1\kraft-combined-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-9. (kafka.log.LogLoader)
[2025-08-10 11:33:14,436] INFO [LogLoader partition=__consumer_offsets-9, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,436] INFO [LogLoader partition=__consumer_offsets-9, dir=C:\tmp\server-1\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,436] INFO [LogLoader partition=__consumer_offsets-9, dir=C:\tmp\server-1\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,442] INFO [LogLoader partition=__consumer_offsets-9, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,442] INFO [LogLoader partition=__consumer_offsets-9, dir=C:\tmp\server-1\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,442] INFO [LogLoader partition=__consumer_offsets-9, dir=C:\tmp\server-1\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:33:14,445] INFO Completed load of Log(dir=C:\tmp\server-1\kraft-combined-logs\__consumer_offsets-9, topicId=6g4QFzBuRcCnDf0xnmyCwA, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 14ms (20/20 completed in C:\tmp\server-1\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:33:14,447] INFO Loaded 20 logs in 769ms (unclean log dirs = ArrayBuffer(C:\tmp\server-1\kraft-combined-logs)) (kafka.log.LogManager)
[2025-08-10 11:33:14,448] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2025-08-10 11:33:14,448] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2025-08-10 11:33:14,492] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2025-08-10 11:33:14,493] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-08-10 11:33:14,494] INFO [AddPartitionsToTxnSenderThread-1]: Starting (kafka.server.AddPartitionsToTxnManager)
[2025-08-10 11:33:14,494] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:14,496] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:14,497] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-08-10 11:33:14,498] INFO [TxnMarkerSenderThread-1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-08-10 11:33:14,499] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-08-10 11:33:14,500] INFO [BrokerMetadataPublisher id=1] Updating metadata.version to 14 at offset OffsetAndEpoch(offset=37210, epoch=12). (kafka.server.metadata.BrokerMetadataPublisher)
[2025-08-10 11:33:14,507] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(__consumer_offsets-48, __consumer_offsets-14, __consumer_offsets-46, new-employee-created-event-2, __consumer_offsets-9, __consumer_offsets-41, __consumer_offsets-42, __consumer_offsets-21, __consumer_offsets-17, __consumer_offsets-18, __consumer_offsets-30, __consumer_offsets-28, __consumer_offsets-25, __consumer_offsets-7, __consumer_offsets-38, __consumer_offsets-35, __consumer_offsets-4, __consumer_offsets-1) (kafka.server.ReplicaFetcherManager)
[2025-08-10 11:33:14,529] INFO [Partition __consumer_offsets-48 broker=1] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:33:14,544] INFO [Partition __consumer_offsets-14 broker=1] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:33:14,551] INFO [Partition __consumer_offsets-46 broker=1] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:33:14,559] INFO [Partition new-employee-created-event-2 broker=1] Log loaded for partition new-employee-created-event-2 with initial high watermark 3 (kafka.cluster.Partition)
[2025-08-10 11:33:14,566] INFO [Partition __consumer_offsets-9 broker=1] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:33:14,572] INFO [Partition __consumer_offsets-41 broker=1] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:33:14,578] INFO [Partition __consumer_offsets-42 broker=1] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:33:14,582] INFO [Partition __consumer_offsets-21 broker=1] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:33:14,585] INFO [Partition __consumer_offsets-17 broker=1] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:33:14,588] INFO [Partition __consumer_offsets-18 broker=1] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:33:14,591] INFO [Partition __consumer_offsets-30 broker=1] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:33:14,594] INFO [Partition __consumer_offsets-28 broker=1] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:33:14,598] INFO [Partition __consumer_offsets-25 broker=1] Log loaded for partition __consumer_offsets-25 with initial high watermark 11 (kafka.cluster.Partition)
[2025-08-10 11:33:14,598] INFO [Partition __consumer_offsets-7 broker=1] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:33:14,601] INFO [Partition __consumer_offsets-38 broker=1] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:33:14,605] INFO [Partition __consumer_offsets-35 broker=1] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:33:14,608] INFO [Partition __consumer_offsets-4 broker=1] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:33:14,610] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:14,610] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:14,610] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:14,611] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:14,611] INFO [Partition __consumer_offsets-1 broker=1] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:33:14,611] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-2=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=3, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[7], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:14,618] INFO [Partition new-employee-created-event-1 broker=1] Log loaded for partition new-employee-created-event-1 with initial high watermark 6 (kafka.cluster.Partition)
[2025-08-10 11:33:14,619] INFO [Partition new-employee-created-event-0 broker=1] Log loaded for partition new-employee-created-event-0 with initial high watermark 4 (kafka.cluster.Partition)
[2025-08-10 11:33:14,620] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(new-employee-created-event-0, new-employee-created-event-1) (kafka.server.ReplicaFetcherManager)
[2025-08-10 11:33:14,626] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:14,626] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Connection to node 2 (localhost/127.0.0.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:14,626] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:14,626] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9094 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:14,627] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-0=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=4, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[8], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9094 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:14,642] INFO [ReplicaFetcherThread-0-3]: Starting (kafka.server.ReplicaFetcherThread)
[2025-08-10 11:33:14,646] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 3 for partitions HashMap(new-employee-created-event-1 -> InitialFetchState(Some(x5jQ0eyLQ6GD6TVf1uZ4Lw),BrokerEndPoint(id=3, host=localhost:9096),5,6)) (kafka.server.ReplicaFetcherManager)
[2025-08-10 11:33:14,652] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 2 for partitions HashMap(new-employee-created-event-0 -> InitialFetchState(Some(x5jQ0eyLQ6GD6TVf1uZ4Lw),BrokerEndPoint(id=2, host=localhost:9094),8,4)) (kafka.server.ReplicaFetcherManager)
[2025-08-10 11:33:14,652] INFO [ReplicaFetcherThread-0-2]: Starting (kafka.server.ReplicaFetcherThread)
[2025-08-10 11:33:14,658] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:14,658] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:14,658] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Connection to node 2 (localhost/127.0.0.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:14,658] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Connection to node 3 (localhost/127.0.0.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:14,659] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:14,659] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:14,660] INFO [BrokerLifecycleManager id=2] Unable to register broker 2 because the controller returned error DUPLICATE_BROKER_REGISTRATION (kafka.server.BrokerLifecycleManager)
[2025-08-10 11:33:14,660] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9094 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:14,660] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 3: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9096 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:14,664] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-1=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=6, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[5], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9096 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:14,664] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-0=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=4, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[8], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9094 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:14,669] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 48 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:14,669] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:14,671] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 14 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:14,671] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:14,671] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 46 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:14,671] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:14,671] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 9 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:14,671] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:14,671] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 41 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:14,672] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:14,672] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 42 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:14,672] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:14,672] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 21 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:14,672] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:14,673] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 17 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:14,673] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:14,673] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 18 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:14,673] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:14,673] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 30 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:14,673] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:14,674] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 28 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:14,674] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:14,674] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 25 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:14,674] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:14,674] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 7 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:14,674] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:14,674] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 38 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:14,674] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:14,675] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 35 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:14,675] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:14,675] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 4 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:14,675] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:14,675] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 1 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:14,675] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:14,675] INFO [BrokerLifecycleManager id=3] Unable to register broker 3 because the controller returned error DUPLICATE_BROKER_REGISTRATION (kafka.server.BrokerLifecycleManager)
[2025-08-10 11:33:14,680] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 7 milliseconds for epoch 2, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:14,680] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 9 milliseconds for epoch 2, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:14,681] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-46 in 10 milliseconds for epoch 2, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:14,681] INFO [DynamicConfigPublisher broker id=1] Updating topic new-employee-created-event with new configuration : min.insync.replicas -> 2 (kafka.server.metadata.DynamicConfigPublisher)
[2025-08-10 11:33:14,681] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 10 milliseconds for epoch 2, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:14,681] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 9 milliseconds for epoch 2, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:14,681] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 9 milliseconds for epoch 2, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:14,682] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 9 milliseconds for epoch 2, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:14,682] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 9 milliseconds for epoch 2, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:14,682] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 9 milliseconds for epoch 2, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:14,682] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 8 milliseconds for epoch 2, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:14,683] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-28 in 9 milliseconds for epoch 2, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:14,690] INFO [DynamicConfigPublisher broker id=1] Updating topic __consumer_offsets with new configuration : compression.type -> producer,cleanup.policy -> compact,segment.bytes -> 104857600 (kafka.server.metadata.DynamicConfigPublisher)
[2025-08-10 11:33:14,704] INFO Loaded member MemberMetadata(memberId=consumer-new-employee-created-event-1-2-a208645a-27d0-4542-8dbb-2e1dbbf174f6, groupInstanceId=None, clientId=consumer-new-employee-created-event-1-2, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group new-employee-created-event-1 with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2025-08-10 11:33:14,715] INFO Loaded member MemberMetadata(memberId=consumer-new-employee-created-event-1-3-cb31c683-cf19-47dc-917c-784feea1adad, groupInstanceId=None, clientId=consumer-new-employee-created-event-1-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group new-employee-created-event-1 with generation 3. (kafka.coordinator.group.GroupMetadata$)
[2025-08-10 11:33:14,715] INFO Loaded member MemberMetadata(memberId=consumer-new-employee-created-event-1-3-b75a06e5-c678-48da-886d-411b27b3b654, groupInstanceId=None, clientId=consumer-new-employee-created-event-1-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group new-employee-created-event-1 with generation 5. (kafka.coordinator.group.GroupMetadata$)
[2025-08-10 11:33:14,717] INFO [GroupCoordinator 1]: Loading group metadata for new-employee-created-event-1 with generation 6 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:14,718] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-25 in 44 milliseconds for epoch 2, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:14,718] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-7 in 44 milliseconds for epoch 2, of which 44 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:14,718] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 43 milliseconds for epoch 2, of which 43 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:14,718] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 43 milliseconds for epoch 2, of which 43 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:14,718] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-4 in 43 milliseconds for epoch 2, of which 43 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:14,718] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-1 in 43 milliseconds for epoch 2, of which 43 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:15,168] INFO [BrokerLifecycleManager id=1] Unable to register broker 1 because the controller returned error DUPLICATE_BROKER_REGISTRATION (kafka.server.BrokerLifecycleManager)
[2025-08-10 11:33:15,213] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:15,213] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:15,214] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:15,214] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Connection to node 3 (localhost/127.0.0.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:15,214] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:15,214] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:15,214] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:15,214] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 3: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9096 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:15,216] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-2=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=3, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[7], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:15,216] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-1=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=6, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[5], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9096 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:15,615] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:15,615] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:15,615] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:15,615] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:15,616] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-2=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=3, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[7], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:15,630] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:15,630] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Connection to node 2 (localhost/127.0.0.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:15,630] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:15,630] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9094 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:15,631] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-0=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=4, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[8], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9094 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:15,676] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:15,676] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:15,677] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Connection to node 2 (localhost/127.0.0.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:15,677] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Connection to node 3 (localhost/127.0.0.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:15,677] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:15,677] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:15,677] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9094 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:15,677] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 3: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9096 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:15,678] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-0=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=4, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[8], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9094 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:15,678] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-1=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=6, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[5], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9096 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:16,219] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:16,219] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:16,219] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:16,220] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Connection to node 3 (localhost/127.0.0.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:16,220] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:16,220] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:16,220] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:16,220] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 3: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9096 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:16,221] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-2=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=3, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[7], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:16,221] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-1=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=6, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[5], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9096 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:16,624] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:16,624] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:16,625] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:16,625] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:16,626] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-2=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=3, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[7], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:16,638] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:16,638] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Connection to node 2 (localhost/127.0.0.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:16,640] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:16,640] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9094 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:16,640] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-0=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=4, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[8], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9094 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:16,685] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:16,685] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:16,685] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Connection to node 2 (localhost/127.0.0.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:16,685] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Connection to node 3 (localhost/127.0.0.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:16,685] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:16,686] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:16,686] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 3: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9096 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:16,686] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9094 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:16,686] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-1=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=6, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[5], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9096 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:16,687] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-0=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=4, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[8], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9094 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:16,794] INFO [BrokerLifecycleManager id=1] Unable to register broker 1 because the controller returned error DUPLICATE_BROKER_REGISTRATION (kafka.server.BrokerLifecycleManager)
[2025-08-10 11:33:17,227] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:17,227] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:17,228] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Connection to node 3 (localhost/127.0.0.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:17,228] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:17,228] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:17,228] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:17,228] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 3: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9096 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:17,228] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:17,228] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-1=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=6, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[5], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9096 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:17,229] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-2=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=3, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[7], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:17,630] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:17,630] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:17,630] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:17,630] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:17,631] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-2=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=3, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[7], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:17,645] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:17,645] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Connection to node 2 (localhost/127.0.0.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:17,645] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:17,646] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9094 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:17,646] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-0=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=4, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[8], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9094 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:17,690] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:17,690] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:17,691] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Connection to node 2 (localhost/127.0.0.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:17,691] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Connection to node 3 (localhost/127.0.0.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:17,691] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:17,691] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:17,691] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 3: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9096 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:17,691] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9094 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:17,692] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-1=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=6, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[5], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9096 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:17,692] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-0=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=4, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[8], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9094 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:17,834] INFO [BrokerLifecycleManager id=2] Unable to register broker 2 because the controller returned error DUPLICATE_BROKER_REGISTRATION (kafka.server.BrokerLifecycleManager)
[2025-08-10 11:33:17,894] INFO [BrokerLifecycleManager id=3] Unable to register broker 3 because the controller returned error DUPLICATE_BROKER_REGISTRATION (kafka.server.BrokerLifecycleManager)
[2025-08-10 11:33:18,234] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:18,234] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:18,235] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Connection to node 3 (localhost/127.0.0.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:18,235] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:18,235] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:18,235] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:18,235] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 3: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9096 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:18,235] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:18,236] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-1=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=6, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[5], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9096 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:18,236] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-2=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=3, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[7], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:18,642] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:18,642] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:18,642] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:18,642] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:18,644] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-2=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=3, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[7], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:18,656] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:18,657] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Connection to node 2 (localhost/127.0.0.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:18,657] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:18,657] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9094 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:18,657] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-0=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=4, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[8], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9094 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:18,704] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:18,704] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:18,704] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Connection to node 2 (localhost/127.0.0.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:18,704] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Connection to node 3 (localhost/127.0.0.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:18,704] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:18,705] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:18,705] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9094 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:18,705] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 3: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9096 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:18,705] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-0=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=4, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[8], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9094 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:18,706] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-1=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=6, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[5], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9096 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:19,244] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:19,244] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:19,244] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:19,244] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Connection to node 3 (localhost/127.0.0.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:19,244] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:19,244] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:19,245] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:19,245] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 3: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9096 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:19,246] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-2=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=3, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[7], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:19,246] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-1=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=6, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[5], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9096 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:19,650] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:19,650] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:19,650] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:19,650] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:19,651] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-2=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=3, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[7], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:19,665] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:19,665] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Connection to node 2 (localhost/127.0.0.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:19,665] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:19,665] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9094 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:19,665] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-0=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=4, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[8], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9094 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:19,712] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:19,712] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Connection to node 3 (localhost/127.0.0.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:19,712] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:19,712] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:19,712] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Connection to node 2 (localhost/127.0.0.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:19,712] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 3: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9096 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:19,713] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:19,713] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-1=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=6, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[5], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9096 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:19,713] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9094 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:19,714] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-0=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=4, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[8], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9094 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:20,071] INFO [BrokerLifecycleManager id=1] Unable to register broker 1 because the controller returned error DUPLICATE_BROKER_REGISTRATION (kafka.server.BrokerLifecycleManager)
[2025-08-10 11:33:20,257] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:20,257] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:20,257] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Connection to node 3 (localhost/127.0.0.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:20,258] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:20,258] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:20,258] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:20,258] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 3: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9096 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:20,258] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:20,259] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-1=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=6, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[5], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9096 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:20,260] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-2=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=3, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[7], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:20,660] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:20,660] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:20,661] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:20,661] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:20,662] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-2=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=3, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[7], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:20,677] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:20,677] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Connection to node 2 (localhost/127.0.0.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:20,678] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:20,678] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9094 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:20,679] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-0=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=4, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[8], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9094 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:20,723] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:20,723] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:20,723] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Connection to node 2 (localhost/127.0.0.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:20,723] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Connection to node 3 (localhost/127.0.0.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:20,723] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:20,723] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:20,724] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 3: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9096 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:20,724] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9094 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:20,724] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-1=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=6, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[5], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9096 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:20,724] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-0=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=4, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[8], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9094 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:21,269] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:21,269] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:21,269] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Connection to node 3 (localhost/127.0.0.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:21,269] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:21,269] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:21,269] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:21,269] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 3: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9096 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:21,269] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:21,270] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-1=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=6, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[5], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9096 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:21,271] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-2=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=3, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[7], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:21,671] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:21,673] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:21,673] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:21,673] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:21,674] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-2=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=3, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[7], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:21,687] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:21,687] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Connection to node 2 (localhost/127.0.0.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:21,687] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:21,687] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9094 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:21,688] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-0=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=4, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[8], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9094 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:21,732] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:21,732] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:21,734] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Connection to node 2 (localhost/127.0.0.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:21,734] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Connection to node 3 (localhost/127.0.0.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:21,734] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:21,734] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:21,734] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9094 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:21,734] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 3: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9096 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:21,735] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-0=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=4, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[8], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9094 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:21,735] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-1=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=6, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[5], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9096 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:22,279] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:22,279] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:22,280] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:22,280] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Connection to node 3 (localhost/127.0.0.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:22,280] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:22,280] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:22,281] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:22,281] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 3: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9096 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:22,282] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-2=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=3, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[7], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:22,282] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-1=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=6, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[5], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9096 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:22,681] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:22,681] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:22,681] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:22,681] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:22,682] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-2=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=3, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[7], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:22,696] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:22,696] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Connection to node 2 (localhost/127.0.0.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:22,696] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:22,696] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9094 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:22,697] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-0=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=4, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[8], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9094 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:22,741] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:22,741] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:22,741] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Connection to node 3 (localhost/127.0.0.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:22,741] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Connection to node 2 (localhost/127.0.0.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:22,741] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:22,743] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:22,743] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 3: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9096 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:22,743] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9094 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:22,743] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-1=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=6, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[5], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9096 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:22,743] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-0=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=4, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[8], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9094 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:23,287] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:23,287] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:23,287] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Connection to node 3 (localhost/127.0.0.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:23,287] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:23,287] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:23,288] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:23,288] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 3: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9096 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:23,288] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:23,288] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-1=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=6, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[5], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9096 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:23,288] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-2=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=3, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[7], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:23,689] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:23,689] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:23,689] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:23,689] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:23,690] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-2=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=3, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[7], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:23,706] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:23,706] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Connection to node 2 (localhost/127.0.0.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:23,706] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:23,706] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9094 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:23,707] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-0=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=4, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[8], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9094 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:23,754] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:23,754] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:23,754] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Connection to node 3 (localhost/127.0.0.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:23,755] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Connection to node 2 (localhost/127.0.0.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:23,755] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:23,755] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:23,755] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 3: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9096 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:23,755] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9094 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:23,756] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-1=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=6, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[5], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9096 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:23,756] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-0=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=4, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[8], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9094 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:24,271] INFO [BrokerLifecycleManager id=3] Successfully registered broker 3 with broker epoch 37233 (kafka.server.BrokerLifecycleManager)
[2025-08-10 11:33:24,274] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(new-employee-created-event-0, new-employee-created-event-2, new-employee-created-event-1) (kafka.server.ReplicaFetcherManager)
[2025-08-10 11:33:24,277] INFO [ReplicaFetcherThread-0-2]: Shutting down (kafka.server.ReplicaFetcherThread)
[2025-08-10 11:33:24,277] INFO [ReplicaFetcherThread-0-2]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2025-08-10 11:33:24,277] INFO [ReplicaFetcherThread-0-2]: Stopped (kafka.server.ReplicaFetcherThread)
[2025-08-10 11:33:24,281] INFO [ReplicaFetcherThread-0-1]: Shutting down (kafka.server.ReplicaFetcherThread)
[2025-08-10 11:33:24,281] INFO [ReplicaFetcherThread-0-1]: Stopped (kafka.server.ReplicaFetcherThread)
[2025-08-10 11:33:24,281] INFO [ReplicaFetcherThread-0-1]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2025-08-10 11:33:24,295] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:24,295] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:24,295] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:24,296] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Connection to node 3 (localhost/127.0.0.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:24,296] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:24,296] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:24,296] INFO [BrokerLifecycleManager id=3] The broker has caught up. Transitioning from STARTING to RECOVERY. (kafka.server.BrokerLifecycleManager)
[2025-08-10 11:33:24,296] INFO [BrokerServer id=3] Finished waiting for the controller to acknowledge that we are caught up (kafka.server.BrokerServer)
[2025-08-10 11:33:24,296] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:24,297] INFO [BrokerServer id=3] Waiting for the initial broker metadata update to be published (kafka.server.BrokerServer)
[2025-08-10 11:33:24,297] INFO [BrokerServer id=3] Finished waiting for the initial broker metadata update to be published (kafka.server.BrokerServer)
[2025-08-10 11:33:24,296] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 3: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9096 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:24,297] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-2=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=3, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[7], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:24,297] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-1=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=6, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[5], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9096 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:24,298] INFO KafkaConfig values: 
	advertised.listeners = PLAINTEXT://localhost:9096
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = CONTROLLER
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = [1@localhost:9093, 2@localhost:9095, 3@localhost:9097]
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.new.enable = false
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = PLAINTEXT
	inter.broker.protocol.version = 3.6-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9096,CONTROLLER://:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/server-3/kraft-combined-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 3
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = [broker, controller]
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unstable.api.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = null
	zookeeper.connection.timeout.ms = null
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2025-08-10 11:33:24,305] INFO [BrokerServer id=3] Waiting for the broker to be unfenced (kafka.server.BrokerServer)
[2025-08-10 11:33:24,348] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(new-employee-created-event-0, new-employee-created-event-2, new-employee-created-event-1) (kafka.server.ReplicaFetcherManager)
[2025-08-10 11:33:24,349] INFO [BrokerLifecycleManager id=3] The broker has been unfenced. Transitioning from RECOVERY to RUNNING. (kafka.server.BrokerLifecycleManager)
[2025-08-10 11:33:24,350] INFO [BrokerServer id=3] Finished waiting for the broker to be unfenced (kafka.server.BrokerServer)
[2025-08-10 11:33:24,350] INFO [BrokerLifecycleManager id=2] Successfully registered broker 2 with broker epoch 37280 (kafka.server.BrokerLifecycleManager)
[2025-08-10 11:33:24,351] INFO authorizerStart completed for endpoint PLAINTEXT. Endpoint is now READY. (org.apache.kafka.server.network.EndpointReadyFutures)
[2025-08-10 11:33:24,351] INFO [SocketServer listenerType=BROKER, nodeId=3] Enabling request processing. (kafka.network.SocketServer)
[2025-08-10 11:33:24,352] INFO Awaiting socket connections on 0.0.0.0:9096. (kafka.network.DataPlaneAcceptor)
[2025-08-10 11:33:24,353] INFO [BrokerServer id=3] Waiting for all of the authorizer futures to be completed (kafka.server.BrokerServer)
[2025-08-10 11:33:24,354] INFO [BrokerServer id=3] Finished waiting for all of the authorizer futures to be completed (kafka.server.BrokerServer)
[2025-08-10 11:33:24,354] INFO [BrokerServer id=3] Waiting for all of the SocketServer Acceptors to be started (kafka.server.BrokerServer)
[2025-08-10 11:33:24,354] INFO [BrokerServer id=3] Finished waiting for all of the SocketServer Acceptors to be started (kafka.server.BrokerServer)
[2025-08-10 11:33:24,354] INFO [BrokerServer id=3] Transition from STARTING to STARTED (kafka.server.BrokerServer)
[2025-08-10 11:33:24,355] INFO Kafka version: 3.6.2 (org.apache.kafka.common.utils.AppInfoParser)
[2025-08-10 11:33:24,355] INFO Kafka commitId: c4deed513057c94e (org.apache.kafka.common.utils.AppInfoParser)
[2025-08-10 11:33:24,355] INFO Kafka startTimeMs: 1754805804354 (org.apache.kafka.common.utils.AppInfoParser)
[2025-08-10 11:33:24,357] INFO [KafkaRaftServer nodeId=3] Kafka Server started (kafka.server.KafkaRaftServer)
[2025-08-10 11:33:24,361] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(__consumer_offsets-15, __consumer_offsets-47, __consumer_offsets-13, new-employee-created-event-0, __consumer_offsets-43, __consumer_offsets-11, new-employee-created-event-2, new-employee-created-event-1, __consumer_offsets-23, __consumer_offsets-20, __consumer_offsets-49, __consumer_offsets-31, __consumer_offsets-29, __consumer_offsets-26, __consumer_offsets-40, __consumer_offsets-5, __consumer_offsets-6, __consumer_offsets-36, __consumer_offsets-34, __consumer_offsets-2) (kafka.server.ReplicaFetcherManager)
[2025-08-10 11:33:24,361] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(__consumer_offsets-48, new-employee-created-event-0, __consumer_offsets-14, __consumer_offsets-46, new-employee-created-event-2, new-employee-created-event-1, __consumer_offsets-41, __consumer_offsets-9, __consumer_offsets-42, __consumer_offsets-21, __consumer_offsets-17, __consumer_offsets-18, __consumer_offsets-30, __consumer_offsets-28, __consumer_offsets-25, __consumer_offsets-7, __consumer_offsets-38, __consumer_offsets-35, __consumer_offsets-4, __consumer_offsets-1) (kafka.server.ReplicaFetcherManager)
[2025-08-10 11:33:24,364] INFO [ReplicaFetcherThread-0-2]: Shutting down (kafka.server.ReplicaFetcherThread)
[2025-08-10 11:33:24,364] INFO [ReplicaFetcherThread-0-1]: Shutting down (kafka.server.ReplicaFetcherThread)
[2025-08-10 11:33:24,365] INFO [ReplicaFetcherThread-0-2]: Stopped (kafka.server.ReplicaFetcherThread)
[2025-08-10 11:33:24,365] INFO [ReplicaFetcherThread-0-1]: Stopped (kafka.server.ReplicaFetcherThread)
[2025-08-10 11:33:24,365] INFO [ReplicaFetcherThread-0-2]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2025-08-10 11:33:24,365] INFO [ReplicaFetcherThread-0-1]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2025-08-10 11:33:24,369] INFO [ReplicaFetcherThread-0-3]: Shutting down (kafka.server.ReplicaFetcherThread)
[2025-08-10 11:33:24,369] INFO [ReplicaFetcherThread-0-3]: Stopped (kafka.server.ReplicaFetcherThread)
[2025-08-10 11:33:24,369] INFO [ReplicaFetcherThread-0-3]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2025-08-10 11:33:24,369] INFO [ReplicaFetcherThread-0-3]: Shutting down (kafka.server.ReplicaFetcherThread)
[2025-08-10 11:33:24,369] INFO [ReplicaFetcherThread-0-3]: Stopped (kafka.server.ReplicaFetcherThread)
[2025-08-10 11:33:24,369] INFO [ReplicaFetcherThread-0-3]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2025-08-10 11:33:24,372] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 48 in epoch OptionalInt[3] (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:24,372] INFO [GroupCoordinator 2]: Resigned as the group coordinator for partition 15 in epoch OptionalInt[5] (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:24,373] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,373] INFO [GroupMetadataManager brokerId=2] Scheduling unloading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,374] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 14 in epoch OptionalInt[3] (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:24,374] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,374] INFO [GroupCoordinator 2]: Resigned as the group coordinator for partition 47 in epoch OptionalInt[5] (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:24,374] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 46 in epoch OptionalInt[3] (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:24,374] INFO [GroupMetadataManager brokerId=2] Scheduling unloading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,374] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,374] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 9 in epoch OptionalInt[3] (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:24,374] INFO [GroupCoordinator 2]: Resigned as the group coordinator for partition 13 in epoch OptionalInt[5] (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:24,374] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,374] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 41 in epoch OptionalInt[3] (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:24,374] INFO [GroupMetadataManager brokerId=2] Scheduling unloading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,374] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,374] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 42 in epoch OptionalInt[3] (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:24,375] INFO [GroupCoordinator 2]: Resigned as the group coordinator for partition 11 in epoch OptionalInt[5] (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:24,375] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,375] INFO [GroupMetadataManager brokerId=2] Scheduling unloading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,375] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 21 in epoch OptionalInt[3] (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:24,375] INFO [GroupCoordinator 2]: Resigned as the group coordinator for partition 43 in epoch OptionalInt[5] (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:24,375] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,375] INFO [GroupMetadataManager brokerId=2] Scheduling unloading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,375] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 17 in epoch OptionalInt[3] (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:24,375] INFO [GroupCoordinator 2]: Resigned as the group coordinator for partition 23 in epoch OptionalInt[5] (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:24,375] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,375] INFO [GroupMetadataManager brokerId=2] Scheduling unloading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,375] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 18 in epoch OptionalInt[3] (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:24,375] INFO [GroupCoordinator 2]: Resigned as the group coordinator for partition 20 in epoch OptionalInt[5] (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:24,375] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,375] INFO [GroupMetadataManager brokerId=2] Scheduling unloading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,375] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 30 in epoch OptionalInt[3] (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:24,375] INFO [GroupCoordinator 2]: Resigned as the group coordinator for partition 49 in epoch OptionalInt[5] (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:24,375] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,375] INFO [GroupMetadataManager brokerId=2] Scheduling unloading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,375] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 28 in epoch OptionalInt[3] (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:24,376] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,376] INFO [GroupCoordinator 2]: Resigned as the group coordinator for partition 31 in epoch OptionalInt[5] (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:24,376] INFO [GroupMetadataManager brokerId=2] Scheduling unloading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,376] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 25 in epoch OptionalInt[3] (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:24,376] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,376] INFO [GroupCoordinator 2]: Resigned as the group coordinator for partition 29 in epoch OptionalInt[5] (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:24,376] INFO [GroupMetadataManager brokerId=2] Scheduling unloading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,376] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 7 in epoch OptionalInt[3] (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:24,376] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,376] INFO [GroupCoordinator 2]: Resigned as the group coordinator for partition 26 in epoch OptionalInt[5] (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:24,376] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 38 in epoch OptionalInt[3] (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:24,376] INFO [GroupMetadataManager brokerId=2] Scheduling unloading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,376] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,376] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 35 in epoch OptionalInt[3] (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:24,376] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,376] INFO [GroupCoordinator 2]: Resigned as the group coordinator for partition 40 in epoch OptionalInt[5] (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:24,376] INFO [GroupMetadataManager brokerId=2] Scheduling unloading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,376] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-48 for coordinator epoch OptionalInt[3]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,377] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 4 in epoch OptionalInt[3] (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:24,377] INFO [GroupMetadataManager brokerId=2] Finished unloading __consumer_offsets-15 for coordinator epoch OptionalInt[5]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,377] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,377] INFO [GroupCoordinator 2]: Resigned as the group coordinator for partition 5 in epoch OptionalInt[5] (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:24,377] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-14 for coordinator epoch OptionalInt[3]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,377] INFO [GroupMetadataManager brokerId=2] Finished unloading __consumer_offsets-47 for coordinator epoch OptionalInt[5]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,377] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 1 in epoch OptionalInt[3] (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:24,377] INFO [GroupMetadataManager brokerId=2] Scheduling unloading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,377] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,377] INFO [GroupMetadataManager brokerId=2] Finished unloading __consumer_offsets-13 for coordinator epoch OptionalInt[5]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,377] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-46 for coordinator epoch OptionalInt[3]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,377] INFO [GroupCoordinator 2]: Resigned as the group coordinator for partition 6 in epoch OptionalInt[5] (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:24,377] INFO [GroupMetadataManager brokerId=2] Scheduling unloading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,377] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-9 for coordinator epoch OptionalInt[3]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,378] INFO [GroupCoordinator 2]: Resigned as the group coordinator for partition 36 in epoch OptionalInt[5] (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:24,378] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-41 for coordinator epoch OptionalInt[3]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,378] INFO [GroupMetadataManager brokerId=2] Scheduling unloading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,378] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-42 for coordinator epoch OptionalInt[3]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,378] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-21 for coordinator epoch OptionalInt[3]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,378] INFO [GroupCoordinator 2]: Resigned as the group coordinator for partition 2 in epoch OptionalInt[5] (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:24,378] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-17 for coordinator epoch OptionalInt[3]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,378] INFO [GroupMetadataManager brokerId=2] Scheduling unloading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,378] INFO [GroupCoordinator 2]: Unloading group metadata for new-employee-created-event with generation 8 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:24,378] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-18 for coordinator epoch OptionalInt[3]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,378] INFO [GroupCoordinator 2]: Resigned as the group coordinator for partition 34 in epoch OptionalInt[5] (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:24,378] INFO [GroupMetadataManager brokerId=2] Scheduling unloading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,378] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-30 for coordinator epoch OptionalInt[3]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,379] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-28 for coordinator epoch OptionalInt[3]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,381] INFO [GroupCoordinator 1]: Unloading group metadata for new-employee-created-event-1 with generation 6 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:24,381] INFO [GroupMetadataManager brokerId=2] Finished unloading __consumer_offsets-11 for coordinator epoch OptionalInt[5]. Removed 3 cached offsets and 1 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,381] INFO [GroupMetadataManager brokerId=2] Finished unloading __consumer_offsets-43 for coordinator epoch OptionalInt[5]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,381] INFO [GroupMetadataManager brokerId=2] Finished unloading __consumer_offsets-23 for coordinator epoch OptionalInt[5]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,381] INFO [GroupMetadataManager brokerId=2] Finished unloading __consumer_offsets-20 for coordinator epoch OptionalInt[5]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,381] INFO [GroupMetadataManager brokerId=2] Finished unloading __consumer_offsets-49 for coordinator epoch OptionalInt[5]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,381] INFO [GroupMetadataManager brokerId=2] Finished unloading __consumer_offsets-31 for coordinator epoch OptionalInt[5]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,381] INFO [GroupMetadataManager brokerId=2] Finished unloading __consumer_offsets-29 for coordinator epoch OptionalInt[5]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,382] INFO [GroupCoordinator 2]: Unloading group metadata for new-employee-created-event-2 with generation 6 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:24,382] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-25 for coordinator epoch OptionalInt[3]. Removed 3 cached offsets and 1 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,382] INFO [GroupMetadataManager brokerId=2] Finished unloading __consumer_offsets-26 for coordinator epoch OptionalInt[5]. Removed 3 cached offsets and 1 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,382] INFO [GroupMetadataManager brokerId=2] Finished unloading __consumer_offsets-40 for coordinator epoch OptionalInt[5]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,382] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-7 for coordinator epoch OptionalInt[3]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,382] INFO [GroupMetadataManager brokerId=2] Finished unloading __consumer_offsets-5 for coordinator epoch OptionalInt[5]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,382] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-38 for coordinator epoch OptionalInt[3]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,382] INFO [GroupMetadataManager brokerId=2] Finished unloading __consumer_offsets-6 for coordinator epoch OptionalInt[5]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,382] INFO [GroupMetadataManager brokerId=2] Finished unloading __consumer_offsets-36 for coordinator epoch OptionalInt[5]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,382] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-35 for coordinator epoch OptionalInt[3]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,382] INFO [GroupMetadataManager brokerId=2] Finished unloading __consumer_offsets-2 for coordinator epoch OptionalInt[5]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,382] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-4 for coordinator epoch OptionalInt[3]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,382] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-1 for coordinator epoch OptionalInt[3]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,382] INFO [GroupMetadataManager brokerId=2] Finished unloading __consumer_offsets-34 for coordinator epoch OptionalInt[5]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:24,780] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(new-employee-created-event-0, new-employee-created-event-2, new-employee-created-event-1) (kafka.server.ReplicaFetcherManager)
[2025-08-10 11:33:24,781] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(new-employee-created-event-0, new-employee-created-event-2, new-employee-created-event-1) (kafka.server.ReplicaFetcherManager)
[2025-08-10 11:33:24,785] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 3 for partitions HashMap(new-employee-created-event-0 -> InitialFetchState(Some(x5jQ0eyLQ6GD6TVf1uZ4Lw),BrokerEndPoint(id=3, host=localhost:9096),11,4), new-employee-created-event-2 -> InitialFetchState(Some(x5jQ0eyLQ6GD6TVf1uZ4Lw),BrokerEndPoint(id=3, host=localhost:9096),9,3), new-employee-created-event-1 -> InitialFetchState(Some(x5jQ0eyLQ6GD6TVf1uZ4Lw),BrokerEndPoint(id=3, host=localhost:9096),8,6)) (kafka.server.ReplicaFetcherManager)
[2025-08-10 11:33:24,785] INFO [ReplicaFetcherThread-0-3]: Starting (kafka.server.ReplicaFetcherThread)
[2025-08-10 11:33:24,786] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 3 for partitions HashMap(new-employee-created-event-0 -> InitialFetchState(Some(x5jQ0eyLQ6GD6TVf1uZ4Lw),BrokerEndPoint(id=3, host=localhost:9096),11,4), new-employee-created-event-2 -> InitialFetchState(Some(x5jQ0eyLQ6GD6TVf1uZ4Lw),BrokerEndPoint(id=3, host=localhost:9096),9,3), new-employee-created-event-1 -> InitialFetchState(Some(x5jQ0eyLQ6GD6TVf1uZ4Lw),BrokerEndPoint(id=3, host=localhost:9096),8,6)) (kafka.server.ReplicaFetcherManager)
[2025-08-10 11:33:24,786] INFO [ReplicaFetcherThread-0-3]: Starting (kafka.server.ReplicaFetcherThread)
[2025-08-10 11:33:24,807] INFO [BrokerLifecycleManager id=2] The broker has caught up. Transitioning from STARTING to RECOVERY. (kafka.server.BrokerLifecycleManager)
[2025-08-10 11:33:24,807] INFO [BrokerServer id=2] Finished waiting for the controller to acknowledge that we are caught up (kafka.server.BrokerServer)
[2025-08-10 11:33:24,808] INFO [BrokerServer id=2] Waiting for the initial broker metadata update to be published (kafka.server.BrokerServer)
[2025-08-10 11:33:24,808] INFO [BrokerServer id=2] Finished waiting for the initial broker metadata update to be published (kafka.server.BrokerServer)
[2025-08-10 11:33:24,809] INFO KafkaConfig values: 
	advertised.listeners = PLAINTEXT://localhost:9094
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = CONTROLLER
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = [1@localhost:9093, 2@localhost:9095, 3@localhost:9097]
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.new.enable = false
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = PLAINTEXT
	inter.broker.protocol.version = 3.6-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094,CONTROLLER://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/server-2/kraft-combined-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = [broker, controller]
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unstable.api.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = null
	zookeeper.connection.timeout.ms = null
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2025-08-10 11:33:24,817] INFO [BrokerServer id=2] Waiting for the broker to be unfenced (kafka.server.BrokerServer)
[2025-08-10 11:33:24,851] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Truncating partition new-employee-created-event-2 with TruncationState(offset=3, completed=true) due to leader epoch and offset EpochEndOffset(errorCode=0, partition=2, leaderEpoch=0, endOffset=3) (kafka.server.ReplicaFetcherThread)
[2025-08-10 11:33:24,852] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Truncating partition new-employee-created-event-0 with TruncationState(offset=4, completed=true) due to leader epoch and offset EpochEndOffset(errorCode=0, partition=0, leaderEpoch=0, endOffset=4) (kafka.server.ReplicaFetcherThread)
[2025-08-10 11:33:24,853] INFO [UnifiedLog partition=new-employee-created-event-2, dir=C:\tmp\server-1\kraft-combined-logs] Truncating to 3 has no effect as the largest offset in the log is 2 (kafka.log.UnifiedLog)
[2025-08-10 11:33:24,855] INFO [UnifiedLog partition=new-employee-created-event-0, dir=C:\tmp\server-2\kraft-combined-logs] Truncating to 4 has no effect as the largest offset in the log is 3 (kafka.log.UnifiedLog)
[2025-08-10 11:33:24,862] INFO [BrokerLifecycleManager id=2] The broker has been unfenced. Transitioning from RECOVERY to RUNNING. (kafka.server.BrokerLifecycleManager)
[2025-08-10 11:33:24,862] INFO [BrokerServer id=2] Finished waiting for the broker to be unfenced (kafka.server.BrokerServer)
[2025-08-10 11:33:24,863] INFO authorizerStart completed for endpoint PLAINTEXT. Endpoint is now READY. (org.apache.kafka.server.network.EndpointReadyFutures)
[2025-08-10 11:33:24,864] INFO [SocketServer listenerType=BROKER, nodeId=2] Enabling request processing. (kafka.network.SocketServer)
[2025-08-10 11:33:24,864] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.DataPlaneAcceptor)
[2025-08-10 11:33:24,866] INFO [BrokerServer id=2] Waiting for all of the authorizer futures to be completed (kafka.server.BrokerServer)
[2025-08-10 11:33:24,866] INFO [BrokerServer id=2] Finished waiting for all of the authorizer futures to be completed (kafka.server.BrokerServer)
[2025-08-10 11:33:24,866] INFO [BrokerServer id=2] Waiting for all of the SocketServer Acceptors to be started (kafka.server.BrokerServer)
[2025-08-10 11:33:24,866] INFO [BrokerServer id=2] Finished waiting for all of the SocketServer Acceptors to be started (kafka.server.BrokerServer)
[2025-08-10 11:33:24,866] INFO [BrokerServer id=2] Transition from STARTING to STARTED (kafka.server.BrokerServer)
[2025-08-10 11:33:24,867] INFO Kafka version: 3.6.2 (org.apache.kafka.common.utils.AppInfoParser)
[2025-08-10 11:33:24,867] INFO Kafka commitId: c4deed513057c94e (org.apache.kafka.common.utils.AppInfoParser)
[2025-08-10 11:33:24,867] INFO Kafka startTimeMs: 1754805804866 (org.apache.kafka.common.utils.AppInfoParser)
[2025-08-10 11:33:24,870] INFO [KafkaRaftServer nodeId=2] Kafka Server started (kafka.server.KafkaRaftServer)
[2025-08-10 11:33:24,907] INFO [BrokerToControllerChannelManager id=3 name=alter-partition] Client requested disconnect from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:24,908] INFO [broker-3-to-controller-alter-partition-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:24,951] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(__consumer_offsets-15, __consumer_offsets-47, __consumer_offsets-13, __consumer_offsets-11, __consumer_offsets-43, __consumer_offsets-23, __consumer_offsets-20, __consumer_offsets-49, __consumer_offsets-31, __consumer_offsets-29, __consumer_offsets-26, __consumer_offsets-40, __consumer_offsets-5, __consumer_offsets-6, __consumer_offsets-36, __consumer_offsets-2, __consumer_offsets-34) (kafka.server.ReplicaFetcherManager)
[2025-08-10 11:33:24,951] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(new-employee-created-event-0) (kafka.server.ReplicaFetcherManager)
[2025-08-10 11:33:25,005] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(new-employee-created-event-2, new-employee-created-event-1) (kafka.server.ReplicaFetcherManager)
[2025-08-10 11:33:25,037] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 15 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:25,037] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:25,037] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 47 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:25,037] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:25,037] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 13 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:25,037] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:25,037] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds for epoch 6, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:25,038] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 11 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:25,038] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:25,038] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 43 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:25,038] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:25,038] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-47 in 1 milliseconds for epoch 6, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:25,038] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 23 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:25,038] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:25,038] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds for epoch 6, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:25,038] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 20 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:25,038] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:25,038] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 49 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:25,038] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:25,038] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 31 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:25,040] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:25,040] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 29 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:25,040] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:25,040] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 26 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:25,040] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:25,040] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 40 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:25,040] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:25,040] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 5 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:25,040] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:25,040] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 6 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:25,040] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:25,040] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 36 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:25,040] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:25,040] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 2 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:25,040] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:25,040] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 34 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:25,041] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:25,042] INFO Loaded member MemberMetadata(memberId=consumer-new-employee-created-event-1-83335fbb-1145-4cba-b23e-d24c97c8924d, groupInstanceId=None, clientId=consumer-new-employee-created-event-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group new-employee-created-event with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2025-08-10 11:33:25,042] INFO Loaded member MemberMetadata(memberId=consumer-new-employee-created-event-2-873684dc-c1e5-46ee-9625-6842871ae3e4, groupInstanceId=None, clientId=consumer-new-employee-created-event-2, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group new-employee-created-event with generation 3. (kafka.coordinator.group.GroupMetadata$)
[2025-08-10 11:33:25,043] INFO Loaded member MemberMetadata(memberId=consumer-new-employee-created-event-1-94b45227-4390-4459-96f0-b6c48921a680, groupInstanceId=None, clientId=consumer-new-employee-created-event-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group new-employee-created-event with generation 5. (kafka.coordinator.group.GroupMetadata$)
[2025-08-10 11:33:25,043] INFO Loaded member MemberMetadata(memberId=consumer-new-employee-created-event-1-94b45227-4390-4459-96f0-b6c48921a680, groupInstanceId=None, clientId=consumer-new-employee-created-event-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group new-employee-created-event with generation 6. (kafka.coordinator.group.GroupMetadata$)
[2025-08-10 11:33:25,043] INFO Loaded member MemberMetadata(memberId=consumer-new-employee-created-event-1-87edfd1d-8d78-45f7-8336-09cb36b45a30, groupInstanceId=None, clientId=consumer-new-employee-created-event-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group new-employee-created-event with generation 6. (kafka.coordinator.group.GroupMetadata$)
[2025-08-10 11:33:25,043] INFO Loaded member MemberMetadata(memberId=consumer-new-employee-created-event-1-94b45227-4390-4459-96f0-b6c48921a680, groupInstanceId=None, clientId=consumer-new-employee-created-event-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group new-employee-created-event with generation 7. (kafka.coordinator.group.GroupMetadata$)
[2025-08-10 11:33:25,044] INFO [GroupCoordinator 2]: Loading group metadata for new-employee-created-event with generation 8 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:25,044] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-11 in 6 milliseconds for epoch 6, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:25,045] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-43 in 7 milliseconds for epoch 6, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:25,045] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-23 in 7 milliseconds for epoch 6, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:25,046] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-20 in 8 milliseconds for epoch 6, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:25,046] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-49 in 8 milliseconds for epoch 6, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:25,046] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-31 in 6 milliseconds for epoch 6, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:25,047] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-29 in 7 milliseconds for epoch 6, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:25,050] INFO Loaded member MemberMetadata(memberId=consumer-new-employee-created-event-2-2-2307fe4f-3c55-425e-bebb-1711511a567b, groupInstanceId=None, clientId=consumer-new-employee-created-event-2-2, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group new-employee-created-event-2 with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2025-08-10 11:33:25,050] INFO Loaded member MemberMetadata(memberId=consumer-new-employee-created-event-2-3-557a1ed6-93ef-4f87-8f31-b897df06a44f, groupInstanceId=None, clientId=consumer-new-employee-created-event-2-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group new-employee-created-event-2 with generation 3. (kafka.coordinator.group.GroupMetadata$)
[2025-08-10 11:33:25,051] INFO Loaded member MemberMetadata(memberId=consumer-new-employee-created-event-2-3-e432c907-03e5-48bc-aa35-b2be72397e83, groupInstanceId=None, clientId=consumer-new-employee-created-event-2-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group new-employee-created-event-2 with generation 5. (kafka.coordinator.group.GroupMetadata$)
[2025-08-10 11:33:25,051] INFO [GroupCoordinator 2]: Loading group metadata for new-employee-created-event-2 with generation 6 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:25,051] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-26 in 11 milliseconds for epoch 6, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:25,052] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-40 in 12 milliseconds for epoch 6, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:25,052] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-5 in 12 milliseconds for epoch 6, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:25,052] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-6 in 12 milliseconds for epoch 6, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:25,052] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-36 in 12 milliseconds for epoch 6, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:25,053] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-2 in 13 milliseconds for epoch 6, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:25,053] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-34 in 12 milliseconds for epoch 6, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:26,475] INFO [BrokerLifecycleManager id=1] Successfully registered broker 1 with broker epoch 37306 (kafka.server.BrokerLifecycleManager)
[2025-08-10 11:33:26,856] INFO [BrokerLifecycleManager id=1] The broker has caught up. Transitioning from STARTING to RECOVERY. (kafka.server.BrokerLifecycleManager)
[2025-08-10 11:33:26,856] INFO [BrokerServer id=1] Finished waiting for the controller to acknowledge that we are caught up (kafka.server.BrokerServer)
[2025-08-10 11:33:26,856] INFO [BrokerServer id=1] Waiting for the initial broker metadata update to be published (kafka.server.BrokerServer)
[2025-08-10 11:33:26,857] INFO [BrokerServer id=1] Finished waiting for the initial broker metadata update to be published (kafka.server.BrokerServer)
[2025-08-10 11:33:26,858] INFO KafkaConfig values: 
	advertised.listeners = PLAINTEXT://localhost:9092
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = CONTROLLER
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = [1@localhost:9093, 2@localhost:9095, 3@localhost:9097]
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.new.enable = false
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = PLAINTEXT
	inter.broker.protocol.version = 3.6-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092,CONTROLLER://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/server-1/kraft-combined-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = [broker, controller]
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unstable.api.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = null
	zookeeper.connection.timeout.ms = null
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2025-08-10 11:33:26,864] INFO [BrokerServer id=1] Waiting for the broker to be unfenced (kafka.server.BrokerServer)
[2025-08-10 11:33:26,907] INFO [BrokerLifecycleManager id=1] The broker has been unfenced. Transitioning from RECOVERY to RUNNING. (kafka.server.BrokerLifecycleManager)
[2025-08-10 11:33:26,908] INFO [BrokerServer id=1] Finished waiting for the broker to be unfenced (kafka.server.BrokerServer)
[2025-08-10 11:33:26,908] INFO authorizerStart completed for endpoint PLAINTEXT. Endpoint is now READY. (org.apache.kafka.server.network.EndpointReadyFutures)
[2025-08-10 11:33:26,908] INFO [SocketServer listenerType=BROKER, nodeId=1] Enabling request processing. (kafka.network.SocketServer)
[2025-08-10 11:33:26,909] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.DataPlaneAcceptor)
[2025-08-10 11:33:26,909] INFO [BrokerServer id=1] Waiting for all of the authorizer futures to be completed (kafka.server.BrokerServer)
[2025-08-10 11:33:26,910] INFO [BrokerServer id=1] Finished waiting for all of the authorizer futures to be completed (kafka.server.BrokerServer)
[2025-08-10 11:33:26,910] INFO [BrokerServer id=1] Waiting for all of the SocketServer Acceptors to be started (kafka.server.BrokerServer)
[2025-08-10 11:33:26,910] INFO [BrokerServer id=1] Finished waiting for all of the SocketServer Acceptors to be started (kafka.server.BrokerServer)
[2025-08-10 11:33:26,910] INFO [BrokerServer id=1] Transition from STARTING to STARTED (kafka.server.BrokerServer)
[2025-08-10 11:33:26,910] INFO Kafka version: 3.6.2 (org.apache.kafka.common.utils.AppInfoParser)
[2025-08-10 11:33:26,910] INFO Kafka commitId: c4deed513057c94e (org.apache.kafka.common.utils.AppInfoParser)
[2025-08-10 11:33:26,910] INFO Kafka startTimeMs: 1754805806910 (org.apache.kafka.common.utils.AppInfoParser)
[2025-08-10 11:33:26,911] INFO [KafkaRaftServer nodeId=1] Kafka Server started (kafka.server.KafkaRaftServer)
[2025-08-10 11:33:26,952] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(__consumer_offsets-48, __consumer_offsets-14, __consumer_offsets-46, __consumer_offsets-9, __consumer_offsets-41, __consumer_offsets-42, __consumer_offsets-21, __consumer_offsets-17, __consumer_offsets-18, __consumer_offsets-30, __consumer_offsets-28, __consumer_offsets-25, __consumer_offsets-7, __consumer_offsets-38, __consumer_offsets-35, __consumer_offsets-4, __consumer_offsets-1) (kafka.server.ReplicaFetcherManager)
[2025-08-10 11:33:26,954] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(new-employee-created-event-0) (kafka.server.ReplicaFetcherManager)
[2025-08-10 11:33:27,002] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(new-employee-created-event-2, new-employee-created-event-1) (kafka.server.ReplicaFetcherManager)
[2025-08-10 11:33:27,003] INFO [Partition new-employee-created-event-2 broker=3] ISR updated to 3,2,1  and version updated to 17 (kafka.cluster.Partition)
[2025-08-10 11:33:27,004] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 48 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:27,004] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:27,004] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 14 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:27,004] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:27,004] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 46 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:27,004] INFO [Partition new-employee-created-event-1 broker=3] ISR updated to 3,2,1  and version updated to 17 (kafka.cluster.Partition)
[2025-08-10 11:33:27,004] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:27,004] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds for epoch 4, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:27,004] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 9 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:27,005] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:27,005] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 1 milliseconds for epoch 4, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:27,005] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 41 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:27,005] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-46 in 1 milliseconds for epoch 4, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:27,005] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:27,005] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds for epoch 4, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:27,005] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 42 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:27,005] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds for epoch 4, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:27,005] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:27,006] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 21 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:27,006] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:27,006] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds for epoch 4, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:27,006] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 17 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:27,006] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:27,006] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 18 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:27,006] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds for epoch 4, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:27,006] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:27,007] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 30 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:27,007] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 1 milliseconds for epoch 4, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:27,007] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:27,007] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 28 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:27,007] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 1 milliseconds for epoch 4, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:27,007] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:27,007] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 25 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:27,007] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds for epoch 4, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:27,007] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:27,007] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 7 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:27,007] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:27,007] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds for epoch 4, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:27,008] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 38 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:27,008] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:27,008] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 35 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:27,008] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:27,008] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 4 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:27,008] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:27,008] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 1 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:27,008] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:27,010] INFO Loaded member MemberMetadata(memberId=consumer-new-employee-created-event-1-2-a208645a-27d0-4542-8dbb-2e1dbbf174f6, groupInstanceId=None, clientId=consumer-new-employee-created-event-1-2, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group new-employee-created-event-1 with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2025-08-10 11:33:27,011] INFO Loaded member MemberMetadata(memberId=consumer-new-employee-created-event-1-3-cb31c683-cf19-47dc-917c-784feea1adad, groupInstanceId=None, clientId=consumer-new-employee-created-event-1-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group new-employee-created-event-1 with generation 3. (kafka.coordinator.group.GroupMetadata$)
[2025-08-10 11:33:27,011] INFO Loaded member MemberMetadata(memberId=consumer-new-employee-created-event-1-3-b75a06e5-c678-48da-886d-411b27b3b654, groupInstanceId=None, clientId=consumer-new-employee-created-event-1-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group new-employee-created-event-1 with generation 5. (kafka.coordinator.group.GroupMetadata$)
[2025-08-10 11:33:27,011] INFO [GroupCoordinator 1]: Loading group metadata for new-employee-created-event-1 with generation 6 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:33:27,012] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-25 in 5 milliseconds for epoch 4, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:27,012] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-7 in 5 milliseconds for epoch 4, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:27,012] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 4 milliseconds for epoch 4, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:27,012] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 4 milliseconds for epoch 4, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:27,012] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-4 in 4 milliseconds for epoch 4, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:27,013] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-1 in 5 milliseconds for epoch 4, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:33:42,252] INFO [LocalLog partition=new-employee-created-event-0, dir=C:\tmp\server-3\kraft-combined-logs] Rolled new log segment at offset 4 in 7 ms. (kafka.log.LocalLog)
[2025-08-10 11:33:42,254] INFO [UnifiedLog partition=new-employee-created-event-0, dir=C:\tmp\server-3\kraft-combined-logs] Deleting segment LogSegment(baseOffset=0, size=881, lastModifiedTime=1752573204345, largestRecordTimestamp=Some(1752573204327)) due to log retention time 604800000ms breach based on the largest record timestamp in the segment (kafka.log.UnifiedLog)
[2025-08-10 11:33:42,256] WARN Failed atomic move of C:\tmp\server-3\kraft-combined-logs\new-employee-created-event-0\00000000000000000000.timeindex to C:\tmp\server-3\kraft-combined-logs\new-employee-created-event-0\00000000000000000000.timeindex.deleted retrying with a non-atomic move (org.apache.kafka.common.utils.Utils)
java.nio.file.FileSystemException: C:\tmp\server-3\kraft-combined-logs\new-employee-created-event-0\00000000000000000000.timeindex -> C:\tmp\server-3\kraft-combined-logs\new-employee-created-event-0\00000000000000000000.timeindex.deleted: The process cannot access the file because it is being used by another process
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:317)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:293)
	at java.base/java.nio.file.Files.move(Files.java:1432)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:978)
	at org.apache.kafka.storage.internals.log.AbstractIndex.renameTo(AbstractIndex.java:227)
	at org.apache.kafka.storage.internals.log.LazyIndex$IndexValue.renameTo(LazyIndex.java:122)
	at org.apache.kafka.storage.internals.log.LazyIndex.renameTo(LazyIndex.java:202)
	at kafka.log.LogSegment.changeFileSuffixes(LogSegment.scala:495)
	at kafka.log.LocalLog$.$anonfun$deleteSegmentFiles$1(LocalLog.scala:942)
	at kafka.log.LocalLog$.$anonfun$deleteSegmentFiles$1$adapted(LocalLog.scala:940)
	at scala.collection.immutable.List.foreach(List.scala:333)
	at kafka.log.LocalLog$.deleteSegmentFiles(LocalLog.scala:940)
	at kafka.log.LocalLog.removeAndDeleteSegments(LocalLog.scala:317)
	at kafka.log.UnifiedLog.$anonfun$deleteSegments$2(UnifiedLog.scala:1469)
	at kafka.log.UnifiedLog.deleteSegments(UnifiedLog.scala:1845)
	at kafka.log.UnifiedLog.deleteRetentionMsBreachedSegments(UnifiedLog.scala:1443)
	at kafka.log.UnifiedLog.deleteOldSegments(UnifiedLog.scala:1487)
	at kafka.log.LogManager.$anonfun$cleanupLogs$3(LogManager.scala:1305)
	at kafka.log.LogManager.$anonfun$cleanupLogs$3$adapted(LogManager.scala:1302)
	at scala.collection.immutable.List.foreach(List.scala:333)
	at kafka.log.LogManager.cleanupLogs(LogManager.scala:1302)
	at kafka.log.LogManager.$anonfun$startupWithConfigOverrides$2(LogManager.scala:577)
	at org.apache.kafka.server.util.KafkaScheduler.lambda$schedule$1(KafkaScheduler.java:150)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
[2025-08-10 11:33:42,259] ERROR Error while deleting segments for new-employee-created-event-0 in dir C:\tmp\server-3\kraft-combined-logs (org.apache.kafka.storage.internals.log.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\tmp\server-3\kraft-combined-logs\new-employee-created-event-0\00000000000000000000.timeindex -> C:\tmp\server-3\kraft-combined-logs\new-employee-created-event-0\00000000000000000000.timeindex.deleted: The process cannot access the file because it is being used by another process
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:403)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:293)
	at java.base/java.nio.file.Files.move(Files.java:1432)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:982)
	at org.apache.kafka.storage.internals.log.AbstractIndex.renameTo(AbstractIndex.java:227)
	at org.apache.kafka.storage.internals.log.LazyIndex$IndexValue.renameTo(LazyIndex.java:122)
	at org.apache.kafka.storage.internals.log.LazyIndex.renameTo(LazyIndex.java:202)
	at kafka.log.LogSegment.changeFileSuffixes(LogSegment.scala:495)
	at kafka.log.LocalLog$.$anonfun$deleteSegmentFiles$1(LocalLog.scala:942)
	at kafka.log.LocalLog$.$anonfun$deleteSegmentFiles$1$adapted(LocalLog.scala:940)
	at scala.collection.immutable.List.foreach(List.scala:333)
	at kafka.log.LocalLog$.deleteSegmentFiles(LocalLog.scala:940)
	at kafka.log.LocalLog.removeAndDeleteSegments(LocalLog.scala:317)
	at kafka.log.UnifiedLog.$anonfun$deleteSegments$2(UnifiedLog.scala:1469)
	at kafka.log.UnifiedLog.deleteSegments(UnifiedLog.scala:1845)
	at kafka.log.UnifiedLog.deleteRetentionMsBreachedSegments(UnifiedLog.scala:1443)
	at kafka.log.UnifiedLog.deleteOldSegments(UnifiedLog.scala:1487)
	at kafka.log.LogManager.$anonfun$cleanupLogs$3(LogManager.scala:1305)
	at kafka.log.LogManager.$anonfun$cleanupLogs$3$adapted(LogManager.scala:1302)
	at scala.collection.immutable.List.foreach(List.scala:333)
	at kafka.log.LogManager.cleanupLogs(LogManager.scala:1302)
	at kafka.log.LogManager.$anonfun$startupWithConfigOverrides$2(LogManager.scala:577)
	at org.apache.kafka.server.util.KafkaScheduler.lambda$schedule$1(KafkaScheduler.java:150)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
	Suppressed: java.nio.file.FileSystemException: C:\tmp\server-3\kraft-combined-logs\new-employee-created-event-0\00000000000000000000.timeindex -> C:\tmp\server-3\kraft-combined-logs\new-employee-created-event-0\00000000000000000000.timeindex.deleted: The process cannot access the file because it is being used by another process
		at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
		at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
		at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:317)
		at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:293)
		at java.base/java.nio.file.Files.move(Files.java:1432)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:978)
		... 25 more
[2025-08-10 11:33:42,261] ERROR Uncaught exception in scheduled task 'kafka-log-retention' (org.apache.kafka.server.util.KafkaScheduler)
org.apache.kafka.common.errors.KafkaStorageException: Error while deleting segments for new-employee-created-event-0 in dir C:\tmp\server-3\kraft-combined-logs
Caused by: java.nio.file.FileSystemException: C:\tmp\server-3\kraft-combined-logs\new-employee-created-event-0\00000000000000000000.timeindex -> C:\tmp\server-3\kraft-combined-logs\new-employee-created-event-0\00000000000000000000.timeindex.deleted: The process cannot access the file because it is being used by another process
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:403)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:293)
	at java.base/java.nio.file.Files.move(Files.java:1432)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:982)
	at org.apache.kafka.storage.internals.log.AbstractIndex.renameTo(AbstractIndex.java:227)
	at org.apache.kafka.storage.internals.log.LazyIndex$IndexValue.renameTo(LazyIndex.java:122)
	at org.apache.kafka.storage.internals.log.LazyIndex.renameTo(LazyIndex.java:202)
	at kafka.log.LogSegment.changeFileSuffixes(LogSegment.scala:495)
	at kafka.log.LocalLog$.$anonfun$deleteSegmentFiles$1(LocalLog.scala:942)
	at kafka.log.LocalLog$.$anonfun$deleteSegmentFiles$1$adapted(LocalLog.scala:940)
	at scala.collection.immutable.List.foreach(List.scala:333)
	at kafka.log.LocalLog$.deleteSegmentFiles(LocalLog.scala:940)
	at kafka.log.LocalLog.removeAndDeleteSegments(LocalLog.scala:317)
	at kafka.log.UnifiedLog.$anonfun$deleteSegments$2(UnifiedLog.scala:1469)
	at kafka.log.UnifiedLog.deleteSegments(UnifiedLog.scala:1845)
	at kafka.log.UnifiedLog.deleteRetentionMsBreachedSegments(UnifiedLog.scala:1443)
	at kafka.log.UnifiedLog.deleteOldSegments(UnifiedLog.scala:1487)
	at kafka.log.LogManager.$anonfun$cleanupLogs$3(LogManager.scala:1305)
	at kafka.log.LogManager.$anonfun$cleanupLogs$3$adapted(LogManager.scala:1302)
	at scala.collection.immutable.List.foreach(List.scala:333)
	at kafka.log.LogManager.cleanupLogs(LogManager.scala:1302)
	at kafka.log.LogManager.$anonfun$startupWithConfigOverrides$2(LogManager.scala:577)
	at org.apache.kafka.server.util.KafkaScheduler.lambda$schedule$1(KafkaScheduler.java:150)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
	Suppressed: java.nio.file.FileSystemException: C:\tmp\server-3\kraft-combined-logs\new-employee-created-event-0\00000000000000000000.timeindex -> C:\tmp\server-3\kraft-combined-logs\new-employee-created-event-0\00000000000000000000.timeindex.deleted: The process cannot access the file because it is being used by another process
		at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
		at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
		at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:317)
		at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:293)
		at java.base/java.nio.file.Files.move(Files.java:1432)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:978)
		... 25 more
[2025-08-10 11:33:42,261] WARN [ReplicaManager broker=3] Stopping serving replicas in dir C:\tmp\server-3\kraft-combined-logs (kafka.server.ReplicaManager)
[2025-08-10 11:33:42,265] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions HashSet(__consumer_offsets-22, new-employee-created-event-1, __consumer_offsets-8, __consumer_offsets-27, __consumer_offsets-33, __consumer_offsets-16, __consumer_offsets-3, __consumer_offsets-37, __consumer_offsets-24, new-employee-created-event-0, __consumer_offsets-45, __consumer_offsets-19, new-employee-created-event-2, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-10, __consumer_offsets-32) (kafka.server.ReplicaFetcherManager)
[2025-08-10 11:33:42,266] INFO [ReplicaAlterLogDirsManager on broker 3] Removed fetcher for partitions HashSet(__consumer_offsets-22, new-employee-created-event-1, __consumer_offsets-8, __consumer_offsets-27, __consumer_offsets-33, __consumer_offsets-16, __consumer_offsets-3, __consumer_offsets-37, __consumer_offsets-24, new-employee-created-event-0, __consumer_offsets-45, __consumer_offsets-19, new-employee-created-event-2, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-10, __consumer_offsets-32) (kafka.server.ReplicaAlterLogDirsManager)
[2025-08-10 11:33:42,273] WARN [ReplicaManager broker=3] Broker 3 stopped fetcher for partitions __consumer_offsets-22,new-employee-created-event-1,__consumer_offsets-8,__consumer_offsets-27,__consumer_offsets-33,__consumer_offsets-16,__consumer_offsets-3,__consumer_offsets-37,__consumer_offsets-24,new-employee-created-event-0,__consumer_offsets-45,__consumer_offsets-19,new-employee-created-event-2,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-39,__consumer_offsets-12,__consumer_offsets-10,__consumer_offsets-32 and stopped moving logs for partitions  because they are in the failed log directory C:\tmp\server-3\kraft-combined-logs. (kafka.server.ReplicaManager)
[2025-08-10 11:33:42,273] WARN Stopping serving logs in dir C:\tmp\server-3\kraft-combined-logs (kafka.log.LogManager)
[2025-08-10 11:33:42,277] ERROR Shutdown broker because all log dirs in C:\tmp\server-3\kraft-combined-logs have failed (kafka.log.LogManager)
[2025-08-10 11:33:42,788] INFO [RaftManager id=2] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:42,788] INFO [BrokerToControllerChannelManager id=2 name=heartbeat] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:42,789] INFO [RaftManager id=2] Cancelled in-flight FETCH request with correlation id 101 due to node 3 being disconnected (elapsed time since creation: 641ms, elapsed time since send: 641ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:42,789] INFO [BrokerToControllerChannelManager id=1 name=heartbeat] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:42,790] INFO [RaftManager id=1] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:42,790] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:42,790] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:42,790] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Cancelled in-flight FETCH request with correlation id 35 due to node 3 being disconnected (elapsed time since creation: 538ms, elapsed time since send: 538ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:42,790] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:42,790] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=1549650017, epoch=35) to node 3: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to 3 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:99)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:113)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:42,791] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Cancelled in-flight FETCH request with correlation id 35 due to node 3 being disconnected (elapsed time since creation: 538ms, elapsed time since send: 538ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:42,791] INFO [RaftManager id=1] Cancelled in-flight FETCH request with correlation id 98 due to node 3 being disconnected (elapsed time since creation: 642ms, elapsed time since send: 642ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:42,791] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=1549650017, epoch=35), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 3 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:99)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:113)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:42,791] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:42,791] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=1016051336, epoch=35) to node 3: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to 3 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:99)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:113)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:42,792] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=1016051336, epoch=35), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 3 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:99)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:113)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:42,891] INFO [RaftManager id=2] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:42,891] INFO [RaftManager id=1] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:42,891] WARN [RaftManager id=2] Connection to node 3 (localhost/127.0.0.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:42,891] WARN [RaftManager id=1] Connection to node 3 (localhost/127.0.0.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:42,929] INFO [LocalLog partition=new-employee-created-event-0, dir=C:\tmp\server-2\kraft-combined-logs] Rolled new log segment at offset 4 in 2 ms. (kafka.log.LocalLog)
[2025-08-10 11:33:42,930] INFO [UnifiedLog partition=new-employee-created-event-0, dir=C:\tmp\server-2\kraft-combined-logs] Deleting segment LogSegment(baseOffset=0, size=881, lastModifiedTime=1752573204336, largestRecordTimestamp=Some(1752573204327)) due to log retention time 604800000ms breach based on the largest record timestamp in the segment (kafka.log.UnifiedLog)
[2025-08-10 11:33:42,932] WARN Failed atomic move of C:\tmp\server-2\kraft-combined-logs\new-employee-created-event-0\00000000000000000000.timeindex to C:\tmp\server-2\kraft-combined-logs\new-employee-created-event-0\00000000000000000000.timeindex.deleted retrying with a non-atomic move (org.apache.kafka.common.utils.Utils)
java.nio.file.FileSystemException: C:\tmp\server-2\kraft-combined-logs\new-employee-created-event-0\00000000000000000000.timeindex -> C:\tmp\server-2\kraft-combined-logs\new-employee-created-event-0\00000000000000000000.timeindex.deleted: The process cannot access the file because it is being used by another process
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:317)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:293)
	at java.base/java.nio.file.Files.move(Files.java:1432)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:978)
	at org.apache.kafka.storage.internals.log.AbstractIndex.renameTo(AbstractIndex.java:227)
	at org.apache.kafka.storage.internals.log.LazyIndex$IndexValue.renameTo(LazyIndex.java:122)
	at org.apache.kafka.storage.internals.log.LazyIndex.renameTo(LazyIndex.java:202)
	at kafka.log.LogSegment.changeFileSuffixes(LogSegment.scala:495)
	at kafka.log.LocalLog$.$anonfun$deleteSegmentFiles$1(LocalLog.scala:942)
	at kafka.log.LocalLog$.$anonfun$deleteSegmentFiles$1$adapted(LocalLog.scala:940)
	at scala.collection.immutable.List.foreach(List.scala:333)
	at kafka.log.LocalLog$.deleteSegmentFiles(LocalLog.scala:940)
	at kafka.log.LocalLog.removeAndDeleteSegments(LocalLog.scala:317)
	at kafka.log.UnifiedLog.$anonfun$deleteSegments$2(UnifiedLog.scala:1469)
	at kafka.log.UnifiedLog.deleteSegments(UnifiedLog.scala:1845)
	at kafka.log.UnifiedLog.deleteRetentionMsBreachedSegments(UnifiedLog.scala:1443)
	at kafka.log.UnifiedLog.deleteOldSegments(UnifiedLog.scala:1487)
	at kafka.log.LogManager.$anonfun$cleanupLogs$3(LogManager.scala:1305)
	at kafka.log.LogManager.$anonfun$cleanupLogs$3$adapted(LogManager.scala:1302)
	at scala.collection.immutable.List.foreach(List.scala:333)
	at kafka.log.LogManager.cleanupLogs(LogManager.scala:1302)
	at kafka.log.LogManager.$anonfun$startupWithConfigOverrides$2(LogManager.scala:577)
	at org.apache.kafka.server.util.KafkaScheduler.lambda$schedule$1(KafkaScheduler.java:150)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
[2025-08-10 11:33:42,933] ERROR Error while deleting segments for new-employee-created-event-0 in dir C:\tmp\server-2\kraft-combined-logs (org.apache.kafka.storage.internals.log.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\tmp\server-2\kraft-combined-logs\new-employee-created-event-0\00000000000000000000.timeindex -> C:\tmp\server-2\kraft-combined-logs\new-employee-created-event-0\00000000000000000000.timeindex.deleted: The process cannot access the file because it is being used by another process
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:403)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:293)
	at java.base/java.nio.file.Files.move(Files.java:1432)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:982)
	at org.apache.kafka.storage.internals.log.AbstractIndex.renameTo(AbstractIndex.java:227)
	at org.apache.kafka.storage.internals.log.LazyIndex$IndexValue.renameTo(LazyIndex.java:122)
	at org.apache.kafka.storage.internals.log.LazyIndex.renameTo(LazyIndex.java:202)
	at kafka.log.LogSegment.changeFileSuffixes(LogSegment.scala:495)
	at kafka.log.LocalLog$.$anonfun$deleteSegmentFiles$1(LocalLog.scala:942)
	at kafka.log.LocalLog$.$anonfun$deleteSegmentFiles$1$adapted(LocalLog.scala:940)
	at scala.collection.immutable.List.foreach(List.scala:333)
	at kafka.log.LocalLog$.deleteSegmentFiles(LocalLog.scala:940)
	at kafka.log.LocalLog.removeAndDeleteSegments(LocalLog.scala:317)
	at kafka.log.UnifiedLog.$anonfun$deleteSegments$2(UnifiedLog.scala:1469)
	at kafka.log.UnifiedLog.deleteSegments(UnifiedLog.scala:1845)
	at kafka.log.UnifiedLog.deleteRetentionMsBreachedSegments(UnifiedLog.scala:1443)
	at kafka.log.UnifiedLog.deleteOldSegments(UnifiedLog.scala:1487)
	at kafka.log.LogManager.$anonfun$cleanupLogs$3(LogManager.scala:1305)
	at kafka.log.LogManager.$anonfun$cleanupLogs$3$adapted(LogManager.scala:1302)
	at scala.collection.immutable.List.foreach(List.scala:333)
	at kafka.log.LogManager.cleanupLogs(LogManager.scala:1302)
	at kafka.log.LogManager.$anonfun$startupWithConfigOverrides$2(LogManager.scala:577)
	at org.apache.kafka.server.util.KafkaScheduler.lambda$schedule$1(KafkaScheduler.java:150)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
	Suppressed: java.nio.file.FileSystemException: C:\tmp\server-2\kraft-combined-logs\new-employee-created-event-0\00000000000000000000.timeindex -> C:\tmp\server-2\kraft-combined-logs\new-employee-created-event-0\00000000000000000000.timeindex.deleted: The process cannot access the file because it is being used by another process
		at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
		at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
		at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:317)
		at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:293)
		at java.base/java.nio.file.Files.move(Files.java:1432)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:978)
		... 25 more
[2025-08-10 11:33:42,936] WARN [ReplicaManager broker=2] Stopping serving replicas in dir C:\tmp\server-2\kraft-combined-logs (kafka.server.ReplicaManager)
[2025-08-10 11:33:42,936] ERROR Uncaught exception in scheduled task 'kafka-log-retention' (org.apache.kafka.server.util.KafkaScheduler)
org.apache.kafka.common.errors.KafkaStorageException: Error while deleting segments for new-employee-created-event-0 in dir C:\tmp\server-2\kraft-combined-logs
Caused by: java.nio.file.FileSystemException: C:\tmp\server-2\kraft-combined-logs\new-employee-created-event-0\00000000000000000000.timeindex -> C:\tmp\server-2\kraft-combined-logs\new-employee-created-event-0\00000000000000000000.timeindex.deleted: The process cannot access the file because it is being used by another process
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:403)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:293)
	at java.base/java.nio.file.Files.move(Files.java:1432)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:982)
	at org.apache.kafka.storage.internals.log.AbstractIndex.renameTo(AbstractIndex.java:227)
	at org.apache.kafka.storage.internals.log.LazyIndex$IndexValue.renameTo(LazyIndex.java:122)
	at org.apache.kafka.storage.internals.log.LazyIndex.renameTo(LazyIndex.java:202)
	at kafka.log.LogSegment.changeFileSuffixes(LogSegment.scala:495)
	at kafka.log.LocalLog$.$anonfun$deleteSegmentFiles$1(LocalLog.scala:942)
	at kafka.log.LocalLog$.$anonfun$deleteSegmentFiles$1$adapted(LocalLog.scala:940)
	at scala.collection.immutable.List.foreach(List.scala:333)
	at kafka.log.LocalLog$.deleteSegmentFiles(LocalLog.scala:940)
	at kafka.log.LocalLog.removeAndDeleteSegments(LocalLog.scala:317)
	at kafka.log.UnifiedLog.$anonfun$deleteSegments$2(UnifiedLog.scala:1469)
	at kafka.log.UnifiedLog.deleteSegments(UnifiedLog.scala:1845)
	at kafka.log.UnifiedLog.deleteRetentionMsBreachedSegments(UnifiedLog.scala:1443)
	at kafka.log.UnifiedLog.deleteOldSegments(UnifiedLog.scala:1487)
	at kafka.log.LogManager.$anonfun$cleanupLogs$3(LogManager.scala:1305)
	at kafka.log.LogManager.$anonfun$cleanupLogs$3$adapted(LogManager.scala:1302)
	at scala.collection.immutable.List.foreach(List.scala:333)
	at kafka.log.LogManager.cleanupLogs(LogManager.scala:1302)
	at kafka.log.LogManager.$anonfun$startupWithConfigOverrides$2(LogManager.scala:577)
	at org.apache.kafka.server.util.KafkaScheduler.lambda$schedule$1(KafkaScheduler.java:150)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
	Suppressed: java.nio.file.FileSystemException: C:\tmp\server-2\kraft-combined-logs\new-employee-created-event-0\00000000000000000000.timeindex -> C:\tmp\server-2\kraft-combined-logs\new-employee-created-event-0\00000000000000000000.timeindex.deleted: The process cannot access the file because it is being used by another process
		at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
		at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
		at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:317)
		at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:293)
		at java.base/java.nio.file.Files.move(Files.java:1432)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:978)
		... 25 more
[2025-08-10 11:33:42,938] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(new-employee-created-event-1, __consumer_offsets-47, __consumer_offsets-15, __consumer_offsets-13, new-employee-created-event-0, __consumer_offsets-20, __consumer_offsets-40, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-11, new-employee-created-event-2, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34) (kafka.server.ReplicaFetcherManager)
[2025-08-10 11:33:42,939] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions HashSet(new-employee-created-event-1, __consumer_offsets-47, __consumer_offsets-15, __consumer_offsets-13, new-employee-created-event-0, __consumer_offsets-20, __consumer_offsets-40, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-11, new-employee-created-event-2, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34) (kafka.server.ReplicaAlterLogDirsManager)
[2025-08-10 11:33:42,947] WARN [ReplicaManager broker=2] Broker 2 stopped fetcher for partitions new-employee-created-event-1,__consumer_offsets-47,__consumer_offsets-15,__consumer_offsets-13,new-employee-created-event-0,__consumer_offsets-20,__consumer_offsets-40,__consumer_offsets-23,__consumer_offsets-49,__consumer_offsets-31,__consumer_offsets-36,__consumer_offsets-11,new-employee-created-event-2,__consumer_offsets-2,__consumer_offsets-43,__consumer_offsets-6,__consumer_offsets-5,__consumer_offsets-26,__consumer_offsets-29,__consumer_offsets-34 and stopped moving logs for partitions  because they are in the failed log directory C:\tmp\server-2\kraft-combined-logs. (kafka.server.ReplicaManager)
[2025-08-10 11:33:42,948] WARN Stopping serving logs in dir C:\tmp\server-2\kraft-combined-logs (kafka.log.LogManager)
[2025-08-10 11:33:42,950] ERROR Shutdown broker because all log dirs in C:\tmp\server-2\kraft-combined-logs have failed (kafka.log.LogManager)
[2025-08-10 11:33:43,013] INFO [RaftManager id=1] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:43,013] WARN [RaftManager id=1] Connection to node 3 (localhost/127.0.0.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:43,137] INFO [BrokerToControllerChannelManager id=1 name=heartbeat] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:43,138] WARN [BrokerToControllerChannelManager id=1 name=heartbeat] Connection to node 3 (localhost/127.0.0.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:43,138] INFO [broker-1-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:43,198] INFO [broker-1-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:43,199] INFO [BrokerToControllerChannelManager id=1 name=heartbeat] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:43,199] WARN [BrokerToControllerChannelManager id=1 name=heartbeat] Connection to node 3 (localhost/127.0.0.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:43,200] INFO [broker-1-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:43,260] INFO [broker-1-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:43,261] INFO [BrokerToControllerChannelManager id=1 name=heartbeat] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:43,261] WARN [BrokerToControllerChannelManager id=1 name=heartbeat] Connection to node 3 (localhost/127.0.0.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:43,261] INFO [broker-1-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:43,292] INFO [RaftManager id=1] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:43,292] WARN [RaftManager id=1] Connection to node 3 (localhost/127.0.0.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:43,322] INFO [broker-1-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:43,324] INFO [BrokerToControllerChannelManager id=1 name=heartbeat] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:43,324] WARN [BrokerToControllerChannelManager id=1 name=heartbeat] Connection to node 3 (localhost/127.0.0.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:43,325] INFO [broker-1-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:43,383] INFO [broker-1-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:43,384] INFO [BrokerToControllerChannelManager id=1 name=heartbeat] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:43,385] WARN [BrokerToControllerChannelManager id=1 name=heartbeat] Connection to node 3 (localhost/127.0.0.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:43,385] INFO [broker-1-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:43,444] INFO [broker-1-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:43,446] INFO [BrokerToControllerChannelManager id=1 name=heartbeat] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:43,446] WARN [BrokerToControllerChannelManager id=1 name=heartbeat] Connection to node 3 (localhost/127.0.0.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:43,446] INFO [broker-1-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:43,453] INFO [RaftManager id=1] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:43,506] INFO [broker-1-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:43,507] INFO [BrokerToControllerChannelManager id=1 name=heartbeat] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:43,507] WARN [BrokerToControllerChannelManager id=1 name=heartbeat] Connection to node 3 (localhost/127.0.0.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:43,507] INFO [broker-1-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:43,567] INFO [broker-1-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:43,568] INFO [BrokerToControllerChannelManager id=1 name=heartbeat] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:43,568] WARN [BrokerToControllerChannelManager id=1 name=heartbeat] Connection to node 3 (localhost/127.0.0.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:43,569] INFO [broker-1-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:43,628] INFO [broker-1-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:43,630] INFO [BrokerToControllerChannelManager id=1 name=heartbeat] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:43,630] WARN [BrokerToControllerChannelManager id=1 name=heartbeat] Connection to node 3 (localhost/127.0.0.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:43,631] INFO [broker-1-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:43,689] INFO [broker-1-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:43,690] INFO [BrokerToControllerChannelManager id=1 name=heartbeat] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:43,690] WARN [BrokerToControllerChannelManager id=1 name=heartbeat] Connection to node 3 (localhost/127.0.0.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:43,690] INFO [broker-1-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:43,750] INFO [broker-1-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:43,752] INFO [BrokerToControllerChannelManager id=1 name=heartbeat] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:43,752] WARN [BrokerToControllerChannelManager id=1 name=heartbeat] Connection to node 3 (localhost/127.0.0.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:43,752] INFO [broker-1-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:43,783] INFO [RaftManager id=1] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:43,783] WARN [RaftManager id=1] Connection to node 3 (localhost/127.0.0.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:43,798] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:43,799] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Connection to node 3 (localhost/127.0.0.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:43,799] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:43,799] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=1016051336, epoch=INITIAL) to node 3: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to localhost:9096 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:43,799] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={new-employee-created-event-0=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=4, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[11], lastFetchedEpoch=Optional.empty), new-employee-created-event-2=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=3, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[9], lastFetchedEpoch=Optional[0]), new-employee-created-event-1=PartitionData(topicId=x5jQ0eyLQ6GD6TVf1uZ4Lw, fetchOffset=6, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[8], lastFetchedEpoch=Optional.empty)}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=1016051336, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9096 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:108)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2025-08-10 11:33:43,812] INFO [broker-1-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:43,814] INFO [BrokerToControllerChannelManager id=1 name=heartbeat] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:43,814] WARN [BrokerToControllerChannelManager id=1 name=heartbeat] Connection to node 3 (localhost/127.0.0.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:43,814] INFO [broker-1-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:43,874] INFO [broker-1-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:43,875] INFO [BrokerToControllerChannelManager id=1 name=heartbeat] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:43,875] WARN [BrokerToControllerChannelManager id=1 name=heartbeat] Connection to node 3 (localhost/127.0.0.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:43,875] INFO [broker-1-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:43,936] INFO [broker-1-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:43,937] INFO [BrokerToControllerChannelManager id=1 name=heartbeat] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:43,937] WARN [BrokerToControllerChannelManager id=1 name=heartbeat] Connection to node 3 (localhost/127.0.0.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:43,937] INFO [broker-1-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:43,998] INFO [broker-1-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:43,999] INFO [BrokerToControllerChannelManager id=1 name=heartbeat] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:43,999] WARN [BrokerToControllerChannelManager id=1 name=heartbeat] Connection to node 3 (localhost/127.0.0.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:43,999] INFO [broker-1-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:44,060] INFO [broker-1-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:44,062] INFO [BrokerToControllerChannelManager id=1 name=heartbeat] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:44,062] WARN [BrokerToControllerChannelManager id=1 name=heartbeat] Connection to node 3 (localhost/127.0.0.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:44,062] INFO [broker-1-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:44,122] INFO [broker-1-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:44,123] INFO [BrokerToControllerChannelManager id=1 name=heartbeat] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:44,123] WARN [BrokerToControllerChannelManager id=1 name=heartbeat] Connection to node 3 (localhost/127.0.0.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:44,123] INFO [broker-1-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:33:44,153] INFO [RaftManager id=1] Become candidate due to fetch timeout (org.apache.kafka.raft.KafkaRaftClient)
[2025-08-10 11:33:44,168] INFO [RaftManager id=1] Completed transition to CandidateState(localId=1, epoch=13, retries=1, voteStates={1=GRANTED, 2=UNRECORDED, 3=UNRECORDED}, highWatermark=Optional[LogOffsetMetadata(offset=37358, metadata=Optional.empty)], electionTimeoutMs=1943) from FollowerState(fetchTimeoutMs=2000, epoch=12, leaderId=3, voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=37358, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2025-08-10 11:33:44,171] INFO [RaftManager id=1] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:44,171] WARN [RaftManager id=1] Connection to node 2 (localhost/127.0.0.1:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:44,232] INFO [RaftManager id=1] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:44,233] WARN [RaftManager id=1] Connection to node 3 (localhost/127.0.0.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:44,309] INFO [RaftManager id=1] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:44,309] WARN [RaftManager id=1] Connection to node 2 (localhost/127.0.0.1:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:33:44,470] INFO [LocalLog partition=new-employee-created-event-0, dir=C:\tmp\server-1\kraft-combined-logs] Rolled new log segment at offset 4 in 8 ms. (kafka.log.LocalLog)
[2025-08-10 11:33:44,471] INFO [UnifiedLog partition=new-employee-created-event-0, dir=C:\tmp\server-1\kraft-combined-logs] Deleting segment LogSegment(baseOffset=0, size=881, lastModifiedTime=1752573204341, largestRecordTimestamp=Some(1752573204327)) due to log retention time 604800000ms breach based on the largest record timestamp in the segment (kafka.log.UnifiedLog)
[2025-08-10 11:33:44,473] WARN Failed atomic move of C:\tmp\server-1\kraft-combined-logs\new-employee-created-event-0\00000000000000000000.timeindex to C:\tmp\server-1\kraft-combined-logs\new-employee-created-event-0\00000000000000000000.timeindex.deleted retrying with a non-atomic move (org.apache.kafka.common.utils.Utils)
java.nio.file.FileSystemException: C:\tmp\server-1\kraft-combined-logs\new-employee-created-event-0\00000000000000000000.timeindex -> C:\tmp\server-1\kraft-combined-logs\new-employee-created-event-0\00000000000000000000.timeindex.deleted: The process cannot access the file because it is being used by another process
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:317)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:293)
	at java.base/java.nio.file.Files.move(Files.java:1432)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:978)
	at org.apache.kafka.storage.internals.log.AbstractIndex.renameTo(AbstractIndex.java:227)
	at org.apache.kafka.storage.internals.log.LazyIndex$IndexValue.renameTo(LazyIndex.java:122)
	at org.apache.kafka.storage.internals.log.LazyIndex.renameTo(LazyIndex.java:202)
	at kafka.log.LogSegment.changeFileSuffixes(LogSegment.scala:495)
	at kafka.log.LocalLog$.$anonfun$deleteSegmentFiles$1(LocalLog.scala:942)
	at kafka.log.LocalLog$.$anonfun$deleteSegmentFiles$1$adapted(LocalLog.scala:940)
	at scala.collection.immutable.List.foreach(List.scala:333)
	at kafka.log.LocalLog$.deleteSegmentFiles(LocalLog.scala:940)
	at kafka.log.LocalLog.removeAndDeleteSegments(LocalLog.scala:317)
	at kafka.log.UnifiedLog.$anonfun$deleteSegments$2(UnifiedLog.scala:1469)
	at kafka.log.UnifiedLog.deleteSegments(UnifiedLog.scala:1845)
	at kafka.log.UnifiedLog.deleteRetentionMsBreachedSegments(UnifiedLog.scala:1443)
	at kafka.log.UnifiedLog.deleteOldSegments(UnifiedLog.scala:1487)
	at kafka.log.LogManager.$anonfun$cleanupLogs$3(LogManager.scala:1305)
	at kafka.log.LogManager.$anonfun$cleanupLogs$3$adapted(LogManager.scala:1302)
	at scala.collection.immutable.List.foreach(List.scala:333)
	at kafka.log.LogManager.cleanupLogs(LogManager.scala:1302)
	at kafka.log.LogManager.$anonfun$startupWithConfigOverrides$2(LogManager.scala:577)
	at org.apache.kafka.server.util.KafkaScheduler.lambda$schedule$1(KafkaScheduler.java:150)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
[2025-08-10 11:33:44,475] ERROR Error while deleting segments for new-employee-created-event-0 in dir C:\tmp\server-1\kraft-combined-logs (org.apache.kafka.storage.internals.log.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\tmp\server-1\kraft-combined-logs\new-employee-created-event-0\00000000000000000000.timeindex -> C:\tmp\server-1\kraft-combined-logs\new-employee-created-event-0\00000000000000000000.timeindex.deleted: The process cannot access the file because it is being used by another process
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:403)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:293)
	at java.base/java.nio.file.Files.move(Files.java:1432)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:982)
	at org.apache.kafka.storage.internals.log.AbstractIndex.renameTo(AbstractIndex.java:227)
	at org.apache.kafka.storage.internals.log.LazyIndex$IndexValue.renameTo(LazyIndex.java:122)
	at org.apache.kafka.storage.internals.log.LazyIndex.renameTo(LazyIndex.java:202)
	at kafka.log.LogSegment.changeFileSuffixes(LogSegment.scala:495)
	at kafka.log.LocalLog$.$anonfun$deleteSegmentFiles$1(LocalLog.scala:942)
	at kafka.log.LocalLog$.$anonfun$deleteSegmentFiles$1$adapted(LocalLog.scala:940)
	at scala.collection.immutable.List.foreach(List.scala:333)
	at kafka.log.LocalLog$.deleteSegmentFiles(LocalLog.scala:940)
	at kafka.log.LocalLog.removeAndDeleteSegments(LocalLog.scala:317)
	at kafka.log.UnifiedLog.$anonfun$deleteSegments$2(UnifiedLog.scala:1469)
	at kafka.log.UnifiedLog.deleteSegments(UnifiedLog.scala:1845)
	at kafka.log.UnifiedLog.deleteRetentionMsBreachedSegments(UnifiedLog.scala:1443)
	at kafka.log.UnifiedLog.deleteOldSegments(UnifiedLog.scala:1487)
	at kafka.log.LogManager.$anonfun$cleanupLogs$3(LogManager.scala:1305)
	at kafka.log.LogManager.$anonfun$cleanupLogs$3$adapted(LogManager.scala:1302)
	at scala.collection.immutable.List.foreach(List.scala:333)
	at kafka.log.LogManager.cleanupLogs(LogManager.scala:1302)
	at kafka.log.LogManager.$anonfun$startupWithConfigOverrides$2(LogManager.scala:577)
	at org.apache.kafka.server.util.KafkaScheduler.lambda$schedule$1(KafkaScheduler.java:150)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
	Suppressed: java.nio.file.FileSystemException: C:\tmp\server-1\kraft-combined-logs\new-employee-created-event-0\00000000000000000000.timeindex -> C:\tmp\server-1\kraft-combined-logs\new-employee-created-event-0\00000000000000000000.timeindex.deleted: The process cannot access the file because it is being used by another process
		at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
		at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
		at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:317)
		at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:293)
		at java.base/java.nio.file.Files.move(Files.java:1432)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:978)
		... 25 more
[2025-08-10 11:33:44,478] ERROR Uncaught exception in scheduled task 'kafka-log-retention' (org.apache.kafka.server.util.KafkaScheduler)
org.apache.kafka.common.errors.KafkaStorageException: Error while deleting segments for new-employee-created-event-0 in dir C:\tmp\server-1\kraft-combined-logs
Caused by: java.nio.file.FileSystemException: C:\tmp\server-1\kraft-combined-logs\new-employee-created-event-0\00000000000000000000.timeindex -> C:\tmp\server-1\kraft-combined-logs\new-employee-created-event-0\00000000000000000000.timeindex.deleted: The process cannot access the file because it is being used by another process
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:403)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:293)
	at java.base/java.nio.file.Files.move(Files.java:1432)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:982)
	at org.apache.kafka.storage.internals.log.AbstractIndex.renameTo(AbstractIndex.java:227)
	at org.apache.kafka.storage.internals.log.LazyIndex$IndexValue.renameTo(LazyIndex.java:122)
	at org.apache.kafka.storage.internals.log.LazyIndex.renameTo(LazyIndex.java:202)
	at kafka.log.LogSegment.changeFileSuffixes(LogSegment.scala:495)
	at kafka.log.LocalLog$.$anonfun$deleteSegmentFiles$1(LocalLog.scala:942)
	at kafka.log.LocalLog$.$anonfun$deleteSegmentFiles$1$adapted(LocalLog.scala:940)
	at scala.collection.immutable.List.foreach(List.scala:333)
	at kafka.log.LocalLog$.deleteSegmentFiles(LocalLog.scala:940)
	at kafka.log.LocalLog.removeAndDeleteSegments(LocalLog.scala:317)
	at kafka.log.UnifiedLog.$anonfun$deleteSegments$2(UnifiedLog.scala:1469)
	at kafka.log.UnifiedLog.deleteSegments(UnifiedLog.scala:1845)
	at kafka.log.UnifiedLog.deleteRetentionMsBreachedSegments(UnifiedLog.scala:1443)
	at kafka.log.UnifiedLog.deleteOldSegments(UnifiedLog.scala:1487)
	at kafka.log.LogManager.$anonfun$cleanupLogs$3(LogManager.scala:1305)
	at kafka.log.LogManager.$anonfun$cleanupLogs$3$adapted(LogManager.scala:1302)
	at scala.collection.immutable.List.foreach(List.scala:333)
	at kafka.log.LogManager.cleanupLogs(LogManager.scala:1302)
	at kafka.log.LogManager.$anonfun$startupWithConfigOverrides$2(LogManager.scala:577)
	at org.apache.kafka.server.util.KafkaScheduler.lambda$schedule$1(KafkaScheduler.java:150)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
	Suppressed: java.nio.file.FileSystemException: C:\tmp\server-1\kraft-combined-logs\new-employee-created-event-0\00000000000000000000.timeindex -> C:\tmp\server-1\kraft-combined-logs\new-employee-created-event-0\00000000000000000000.timeindex.deleted: The process cannot access the file because it is being used by another process
		at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
		at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
		at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:317)
		at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:293)
		at java.base/java.nio.file.Files.move(Files.java:1432)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:978)
		... 25 more
[2025-08-10 11:33:44,478] WARN [ReplicaManager broker=1] Stopping serving replicas in dir C:\tmp\server-1\kraft-combined-logs (kafka.server.ReplicaManager)
[2025-08-10 11:33:44,482] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-28, __consumer_offsets-38, new-employee-created-event-2, __consumer_offsets-14, new-employee-created-event-0, __consumer_offsets-1, __consumer_offsets-30, new-employee-created-event-1, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-42, __consumer_offsets-18, __consumer_offsets-17, __consumer_offsets-48) (kafka.server.ReplicaFetcherManager)
[2025-08-10 11:33:44,484] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-28, __consumer_offsets-38, new-employee-created-event-2, __consumer_offsets-14, new-employee-created-event-0, __consumer_offsets-1, __consumer_offsets-30, new-employee-created-event-1, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-42, __consumer_offsets-18, __consumer_offsets-17, __consumer_offsets-48) (kafka.server.ReplicaAlterLogDirsManager)
[2025-08-10 11:33:44,490] WARN [ReplicaManager broker=1] Broker 1 stopped fetcher for partitions __consumer_offsets-25,__consumer_offsets-35,__consumer_offsets-41,__consumer_offsets-28,__consumer_offsets-38,new-employee-created-event-2,__consumer_offsets-14,new-employee-created-event-0,__consumer_offsets-1,__consumer_offsets-30,new-employee-created-event-1,__consumer_offsets-21,__consumer_offsets-4,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-46,__consumer_offsets-42,__consumer_offsets-18,__consumer_offsets-17,__consumer_offsets-48 and stopped moving logs for partitions  because they are in the failed log directory C:\tmp\server-1\kraft-combined-logs. (kafka.server.ReplicaManager)
[2025-08-10 11:33:44,490] WARN Stopping serving logs in dir C:\tmp\server-1\kraft-combined-logs (kafka.log.LogManager)
[2025-08-10 11:33:44,493] ERROR Shutdown broker because all log dirs in C:\tmp\server-1\kraft-combined-logs have failed (kafka.log.LogManager)
[2025-08-10 11:36:00,375] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2025-08-10 11:36:00,591] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2025-08-10 11:36:00,667] WARN No meta.properties file under dir C:\tmp\server-3\kraft-combined-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2025-08-10 11:36:00,669] ERROR Exiting Kafka due to fatal exception (kafka.Kafka$)
org.apache.kafka.common.KafkaException: No `meta.properties` found in /tmp/server-3/kraft-combined-logs (have you run `kafka-storage.sh` to format the directory?)
	at kafka.server.BrokerMetadataCheckpoint$.$anonfun$getBrokerMetadataAndOfflineDirs$2(BrokerMetadataCheckpoint.scala:179)
	at scala.collection.immutable.List.foreach(List.scala:333)
	at kafka.server.BrokerMetadataCheckpoint$.getBrokerMetadataAndOfflineDirs(BrokerMetadataCheckpoint.scala:168)
	at kafka.server.KafkaRaftServer$.initializeLogDirs(KafkaRaftServer.scala:141)
	at kafka.server.KafkaRaftServer.<init>(KafkaRaftServer.scala:57)
	at kafka.Kafka$.buildServer(Kafka.scala:83)
	at kafka.Kafka$.main(Kafka.scala:91)
	at kafka.Kafka.main(Kafka.scala)
[2025-08-10 11:36:32,815] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2025-08-10 11:36:33,032] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2025-08-10 11:36:33,108] WARN No meta.properties file under dir C:\tmp\server-3\kraft-combined-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2025-08-10 11:36:33,110] ERROR Exiting Kafka due to fatal exception (kafka.Kafka$)
org.apache.kafka.common.KafkaException: No `meta.properties` found in /tmp/server-3/kraft-combined-logs (have you run `kafka-storage.sh` to format the directory?)
	at kafka.server.BrokerMetadataCheckpoint$.$anonfun$getBrokerMetadataAndOfflineDirs$2(BrokerMetadataCheckpoint.scala:179)
	at scala.collection.immutable.List.foreach(List.scala:333)
	at kafka.server.BrokerMetadataCheckpoint$.getBrokerMetadataAndOfflineDirs(BrokerMetadataCheckpoint.scala:168)
	at kafka.server.KafkaRaftServer$.initializeLogDirs(KafkaRaftServer.scala:141)
	at kafka.server.KafkaRaftServer.<init>(KafkaRaftServer.scala:57)
	at kafka.Kafka$.buildServer(Kafka.scala:83)
	at kafka.Kafka$.main(Kafka.scala:91)
	at kafka.Kafka.main(Kafka.scala)
[2025-08-10 11:36:34,116] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2025-08-10 11:36:34,343] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2025-08-10 11:36:34,430] WARN No meta.properties file under dir C:\tmp\server-2\kraft-combined-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2025-08-10 11:36:34,432] ERROR Exiting Kafka due to fatal exception (kafka.Kafka$)
org.apache.kafka.common.KafkaException: No `meta.properties` found in /tmp/server-2/kraft-combined-logs (have you run `kafka-storage.sh` to format the directory?)
	at kafka.server.BrokerMetadataCheckpoint$.$anonfun$getBrokerMetadataAndOfflineDirs$2(BrokerMetadataCheckpoint.scala:179)
	at scala.collection.immutable.List.foreach(List.scala:333)
	at kafka.server.BrokerMetadataCheckpoint$.getBrokerMetadataAndOfflineDirs(BrokerMetadataCheckpoint.scala:168)
	at kafka.server.KafkaRaftServer$.initializeLogDirs(KafkaRaftServer.scala:141)
	at kafka.server.KafkaRaftServer.<init>(KafkaRaftServer.scala:57)
	at kafka.Kafka$.buildServer(Kafka.scala:83)
	at kafka.Kafka$.main(Kafka.scala:91)
	at kafka.Kafka.main(Kafka.scala)
[2025-08-10 11:36:35,324] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2025-08-10 11:36:35,537] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2025-08-10 11:36:35,613] WARN No meta.properties file under dir C:\tmp\server-1\kraft-combined-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2025-08-10 11:36:35,615] ERROR Exiting Kafka due to fatal exception (kafka.Kafka$)
org.apache.kafka.common.KafkaException: No `meta.properties` found in /tmp/server-1/kraft-combined-logs (have you run `kafka-storage.sh` to format the directory?)
	at kafka.server.BrokerMetadataCheckpoint$.$anonfun$getBrokerMetadataAndOfflineDirs$2(BrokerMetadataCheckpoint.scala:179)
	at scala.collection.immutable.List.foreach(List.scala:333)
	at kafka.server.BrokerMetadataCheckpoint$.getBrokerMetadataAndOfflineDirs(BrokerMetadataCheckpoint.scala:168)
	at kafka.server.KafkaRaftServer$.initializeLogDirs(KafkaRaftServer.scala:141)
	at kafka.server.KafkaRaftServer.<init>(KafkaRaftServer.scala:57)
	at kafka.Kafka$.buildServer(Kafka.scala:83)
	at kafka.Kafka$.main(Kafka.scala:91)
	at kafka.Kafka.main(Kafka.scala)
[2025-08-10 11:38:15,680] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2025-08-10 11:38:15,902] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2025-08-10 11:38:16,057] INFO [ControllerServer id=3] Starting controller (kafka.server.ControllerServer)
[2025-08-10 11:38:16,078] INFO authorizerStart completed for endpoint CONTROLLER. Endpoint is now READY. (org.apache.kafka.server.network.EndpointReadyFutures)
[2025-08-10 11:38:16,360] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2025-08-10 11:38:16,427] INFO [SocketServer listenerType=CONTROLLER, nodeId=3] Created data-plane acceptor and processors for endpoint : ListenerName(CONTROLLER) (kafka.network.SocketServer)
[2025-08-10 11:38:16,428] INFO [SharedServer id=3] Starting SharedServer (kafka.server.SharedServer)
[2025-08-10 11:38:16,489] INFO [LogLoader partition=__cluster_metadata-0, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:38:16,490] INFO [LogLoader partition=__cluster_metadata-0, dir=C:\tmp\server-3\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:38:16,490] INFO [LogLoader partition=__cluster_metadata-0, dir=C:\tmp\server-3\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:38:16,518] INFO Initialized snapshots with IDs SortedSet() from C:\tmp\server-3\kraft-combined-logs\__cluster_metadata-0 (kafka.raft.KafkaMetadataLog$)
[2025-08-10 11:38:16,529] INFO [raft-expiration-reaper]: Starting (kafka.raft.TimingWheelExpirationService$ExpiredOperationReaper)
[2025-08-10 11:38:16,638] INFO [RaftManager id=3] Completed transition to Unattached(epoch=0, voters=[1, 2, 3], electionTimeoutMs=1584) from null (org.apache.kafka.raft.QuorumState)
[2025-08-10 11:38:16,642] INFO [kafka-3-raft-outbound-request-thread]: Starting (kafka.raft.RaftSendThread)
[2025-08-10 11:38:16,642] INFO [kafka-3-raft-io-thread]: Starting (kafka.raft.KafkaRaftManager$RaftIoThread)
[2025-08-10 11:38:16,664] INFO [MetadataLoader id=3] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:16,666] INFO [ControllerServer id=3] Waiting for controller quorum voters future (kafka.server.ControllerServer)
[2025-08-10 11:38:16,666] INFO [RaftManager id=3] Registered the listener org.apache.kafka.image.loader.MetadataLoader@1171484896 (org.apache.kafka.raft.KafkaRaftClient)
[2025-08-10 11:38:16,666] INFO [ControllerServer id=3] Finished waiting for controller quorum voters future (kafka.server.ControllerServer)
[2025-08-10 11:38:16,705] INFO [RaftManager id=3] Registered the listener org.apache.kafka.controller.QuorumController$QuorumMetaLogListener@556276159 (org.apache.kafka.raft.KafkaRaftClient)
[2025-08-10 11:38:16,712] INFO [controller-3-ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-08-10 11:38:16,713] INFO [controller-3-ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-08-10 11:38:16,715] INFO [controller-3-ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-08-10 11:38:16,717] INFO [controller-3-ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-08-10 11:38:16,736] INFO [ExpirationReaper-3-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-08-10 11:38:16,749] INFO [ControllerServer id=3] Waiting for the controller metadata publishers to be installed (kafka.server.ControllerServer)
[2025-08-10 11:38:16,749] INFO [MetadataLoader id=3] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:16,749] INFO [ControllerServer id=3] Finished waiting for the controller metadata publishers to be installed (kafka.server.ControllerServer)
[2025-08-10 11:38:16,750] INFO [SocketServer listenerType=CONTROLLER, nodeId=3] Enabling request processing. (kafka.network.SocketServer)
[2025-08-10 11:38:16,754] INFO Awaiting socket connections on 0.0.0.0:9097. (kafka.network.DataPlaneAcceptor)
[2025-08-10 11:38:16,757] INFO [ControllerServer id=3] Waiting for all of the authorizer futures to be completed (kafka.server.ControllerServer)
[2025-08-10 11:38:16,757] INFO [ControllerServer id=3] Finished waiting for all of the authorizer futures to be completed (kafka.server.ControllerServer)
[2025-08-10 11:38:16,757] INFO [ControllerServer id=3] Waiting for all of the SocketServer Acceptors to be started (kafka.server.ControllerServer)
[2025-08-10 11:38:16,757] INFO [ControllerServer id=3] Finished waiting for all of the SocketServer Acceptors to be started (kafka.server.ControllerServer)
[2025-08-10 11:38:16,759] INFO [BrokerServer id=3] Transition from SHUTDOWN to STARTING (kafka.server.BrokerServer)
[2025-08-10 11:38:16,760] INFO [BrokerServer id=3] Starting broker (kafka.server.BrokerServer)
[2025-08-10 11:38:16,769] INFO [broker-3-ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-08-10 11:38:16,769] INFO [broker-3-ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-08-10 11:38:16,769] INFO [broker-3-ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-08-10 11:38:16,769] INFO [broker-3-ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-08-10 11:38:16,791] INFO [BrokerServer id=3] Waiting for controller quorum voters future (kafka.server.BrokerServer)
[2025-08-10 11:38:16,791] INFO [BrokerServer id=3] Finished waiting for controller quorum voters future (kafka.server.BrokerServer)
[2025-08-10 11:38:16,803] INFO [broker-3-to-controller-forwarding-channel-manager]: Starting (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:38:16,833] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2025-08-10 11:38:16,845] INFO [SocketServer listenerType=BROKER, nodeId=3] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2025-08-10 11:38:16,852] INFO [broker-3-to-controller-alter-partition-channel-manager]: Starting (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:38:16,856] INFO [MetadataLoader id=3] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:16,869] INFO [ExpirationReaper-3-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-08-10 11:38:16,870] INFO [ExpirationReaper-3-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-08-10 11:38:16,871] INFO [ExpirationReaper-3-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-08-10 11:38:16,872] INFO [ExpirationReaper-3-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-08-10 11:38:16,872] INFO [ExpirationReaper-3-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-08-10 11:38:16,887] INFO [ExpirationReaper-3-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-08-10 11:38:16,888] INFO [ExpirationReaper-3-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-08-10 11:38:16,925] INFO [broker-3-to-controller-heartbeat-channel-manager]: Starting (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:38:16,928] INFO [BrokerLifecycleManager id=3] Incarnation kY-QsuzURjKKGYRWn_yjrQ of broker 3 in cluster aDD5tmu7SImkoi2TMhth9A is now STARTING. (kafka.server.BrokerLifecycleManager)
[2025-08-10 11:38:16,942] INFO [ExpirationReaper-3-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-08-10 11:38:16,955] INFO [BrokerServer id=3] Waiting for the broker metadata publishers to be installed (kafka.server.BrokerServer)
[2025-08-10 11:38:16,955] INFO [MetadataLoader id=3] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:16,956] INFO [BrokerServer id=3] Finished waiting for the broker metadata publishers to be installed (kafka.server.BrokerServer)
[2025-08-10 11:38:16,956] INFO [BrokerServer id=3] Waiting for the controller to acknowledge that we are caught up (kafka.server.BrokerServer)
[2025-08-10 11:38:17,059] INFO [MetadataLoader id=3] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:17,167] INFO [MetadataLoader id=3] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:17,276] INFO [MetadataLoader id=3] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:17,385] INFO [MetadataLoader id=3] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:17,488] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2025-08-10 11:38:17,493] INFO [MetadataLoader id=3] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:17,604] INFO [MetadataLoader id=3] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:17,711] INFO [MetadataLoader id=3] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:17,714] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2025-08-10 11:38:17,821] INFO [MetadataLoader id=3] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:17,874] INFO [ControllerServer id=2] Starting controller (kafka.server.ControllerServer)
[2025-08-10 11:38:17,896] INFO authorizerStart completed for endpoint CONTROLLER. Endpoint is now READY. (org.apache.kafka.server.network.EndpointReadyFutures)
[2025-08-10 11:38:17,932] INFO [MetadataLoader id=3] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:18,040] INFO [MetadataLoader id=3] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:18,137] INFO [RaftManager id=3] Completed transition to CandidateState(localId=3, epoch=1, retries=1, voteStates={1=UNRECORDED, 2=UNRECORDED, 3=GRANTED}, highWatermark=Optional.empty, electionTimeoutMs=1048) from Unattached(epoch=0, voters=[1, 2, 3], electionTimeoutMs=1584) (org.apache.kafka.raft.QuorumState)
[2025-08-10 11:38:18,149] INFO [MetadataLoader id=3] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:18,170] INFO [RaftManager id=3] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:38:18,172] WARN [RaftManager id=3] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:38:18,173] INFO [RaftManager id=3] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:38:18,173] WARN [RaftManager id=3] Connection to node 2 (localhost/127.0.0.1:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:38:18,189] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2025-08-10 11:38:18,230] INFO [RaftManager id=3] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:38:18,231] WARN [RaftManager id=3] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:38:18,231] INFO [RaftManager id=3] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:38:18,231] WARN [RaftManager id=3] Connection to node 2 (localhost/127.0.0.1:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:38:18,258] INFO [MetadataLoader id=3] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:18,267] INFO [SocketServer listenerType=CONTROLLER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(CONTROLLER) (kafka.network.SocketServer)
[2025-08-10 11:38:18,269] INFO [SharedServer id=2] Starting SharedServer (kafka.server.SharedServer)
[2025-08-10 11:38:18,334] INFO [LogLoader partition=__cluster_metadata-0, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:38:18,335] INFO [LogLoader partition=__cluster_metadata-0, dir=C:\tmp\server-2\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:38:18,335] INFO [LogLoader partition=__cluster_metadata-0, dir=C:\tmp\server-2\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:38:18,365] INFO Initialized snapshots with IDs SortedSet() from C:\tmp\server-2\kraft-combined-logs\__cluster_metadata-0 (kafka.raft.KafkaMetadataLog$)
[2025-08-10 11:38:18,368] INFO [MetadataLoader id=3] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:18,379] INFO [raft-expiration-reaper]: Starting (kafka.raft.TimingWheelExpirationService$ExpiredOperationReaper)
[2025-08-10 11:38:18,385] INFO [RaftManager id=3] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:38:18,385] WARN [RaftManager id=3] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:38:18,386] INFO [RaftManager id=3] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:38:18,386] WARN [RaftManager id=3] Connection to node 2 (localhost/127.0.0.1:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:38:18,476] INFO [MetadataLoader id=3] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:18,498] INFO [RaftManager id=2] Completed transition to Unattached(epoch=0, voters=[1, 2, 3], electionTimeoutMs=1608) from null (org.apache.kafka.raft.QuorumState)
[2025-08-10 11:38:18,501] INFO [kafka-2-raft-outbound-request-thread]: Starting (kafka.raft.RaftSendThread)
[2025-08-10 11:38:18,501] INFO [kafka-2-raft-io-thread]: Starting (kafka.raft.KafkaRaftManager$RaftIoThread)
[2025-08-10 11:38:18,522] INFO [MetadataLoader id=2] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:18,523] INFO [ControllerServer id=2] Waiting for controller quorum voters future (kafka.server.ControllerServer)
[2025-08-10 11:38:18,524] INFO [RaftManager id=2] Registered the listener org.apache.kafka.image.loader.MetadataLoader@1735859855 (org.apache.kafka.raft.KafkaRaftClient)
[2025-08-10 11:38:18,524] INFO [ControllerServer id=2] Finished waiting for controller quorum voters future (kafka.server.ControllerServer)
[2025-08-10 11:38:18,553] INFO [RaftManager id=2] Registered the listener org.apache.kafka.controller.QuorumController$QuorumMetaLogListener@496799836 (org.apache.kafka.raft.KafkaRaftClient)
[2025-08-10 11:38:18,558] INFO [controller-2-ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-08-10 11:38:18,559] INFO [controller-2-ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-08-10 11:38:18,560] INFO [controller-2-ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-08-10 11:38:18,562] INFO [controller-2-ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-08-10 11:38:18,577] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-08-10 11:38:18,586] INFO [MetadataLoader id=3] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:18,588] INFO [ControllerServer id=2] Waiting for the controller metadata publishers to be installed (kafka.server.ControllerServer)
[2025-08-10 11:38:18,588] INFO [MetadataLoader id=2] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:18,588] INFO [ControllerServer id=2] Finished waiting for the controller metadata publishers to be installed (kafka.server.ControllerServer)
[2025-08-10 11:38:18,589] INFO [SocketServer listenerType=CONTROLLER, nodeId=2] Enabling request processing. (kafka.network.SocketServer)
[2025-08-10 11:38:18,592] INFO Awaiting socket connections on 0.0.0.0:9095. (kafka.network.DataPlaneAcceptor)
[2025-08-10 11:38:18,595] INFO [ControllerServer id=2] Waiting for all of the authorizer futures to be completed (kafka.server.ControllerServer)
[2025-08-10 11:38:18,595] INFO [ControllerServer id=2] Finished waiting for all of the authorizer futures to be completed (kafka.server.ControllerServer)
[2025-08-10 11:38:18,595] INFO [ControllerServer id=2] Waiting for all of the SocketServer Acceptors to be started (kafka.server.ControllerServer)
[2025-08-10 11:38:18,596] INFO [ControllerServer id=2] Finished waiting for all of the SocketServer Acceptors to be started (kafka.server.ControllerServer)
[2025-08-10 11:38:18,596] INFO [BrokerServer id=2] Transition from SHUTDOWN to STARTING (kafka.server.BrokerServer)
[2025-08-10 11:38:18,597] INFO [BrokerServer id=2] Starting broker (kafka.server.BrokerServer)
[2025-08-10 11:38:18,605] INFO [broker-2-ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-08-10 11:38:18,605] INFO [broker-2-ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-08-10 11:38:18,605] INFO [broker-2-ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-08-10 11:38:18,605] INFO [broker-2-ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-08-10 11:38:18,630] INFO [BrokerServer id=2] Waiting for controller quorum voters future (kafka.server.BrokerServer)
[2025-08-10 11:38:18,630] INFO [BrokerServer id=2] Finished waiting for controller quorum voters future (kafka.server.BrokerServer)
[2025-08-10 11:38:18,634] INFO [RaftManager id=3] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:38:18,635] WARN [RaftManager id=3] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:38:18,641] INFO [broker-2-to-controller-forwarding-channel-manager]: Starting (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:38:18,678] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2025-08-10 11:38:18,691] INFO [SocketServer listenerType=BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2025-08-10 11:38:18,697] INFO [MetadataLoader id=3] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:18,697] INFO [MetadataLoader id=2] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:18,701] INFO [broker-2-to-controller-alter-partition-channel-manager]: Starting (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:38:18,714] INFO [RaftManager id=2] Completed transition to Unattached(epoch=1, voters=[1, 2, 3], electionTimeoutMs=1293) from Unattached(epoch=0, voters=[1, 2, 3], electionTimeoutMs=1608) (org.apache.kafka.raft.QuorumState)
[2025-08-10 11:38:18,720] INFO [RaftManager id=2] Completed transition to Voted(epoch=1, votedId=3, voters=[1, 2, 3], electionTimeoutMs=1893) from Unattached(epoch=1, voters=[1, 2, 3], electionTimeoutMs=1293) (org.apache.kafka.raft.QuorumState)
[2025-08-10 11:38:18,720] INFO [RaftManager id=2] Vote request VoteRequestData(clusterId='aDD5tmu7SImkoi2TMhth9A', topics=[TopicData(topicName='__cluster_metadata', partitions=[PartitionData(partitionIndex=0, candidateEpoch=1, candidateId=3, lastOffsetEpoch=0, lastOffset=0)])]) with epoch 1 is granted (org.apache.kafka.raft.KafkaRaftClient)
[2025-08-10 11:38:18,729] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-08-10 11:38:18,730] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-08-10 11:38:18,731] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-08-10 11:38:18,732] INFO [RaftManager id=3] Completed transition to Leader(localId=3, epoch=1, epochStartOffset=0, highWatermark=Optional.empty, voterStates={1=ReplicaState(nodeId=1, endOffset=Optional.empty, lastFetchTimestamp=-1, lastCaughtUpTimestamp=-1, hasAcknowledgedLeader=false), 2=ReplicaState(nodeId=2, endOffset=Optional.empty, lastFetchTimestamp=-1, lastCaughtUpTimestamp=-1, hasAcknowledgedLeader=false), 3=ReplicaState(nodeId=3, endOffset=Optional.empty, lastFetchTimestamp=-1, lastCaughtUpTimestamp=-1, hasAcknowledgedLeader=true)}) from CandidateState(localId=3, epoch=1, retries=1, voteStates={1=UNRECORDED, 2=GRANTED, 3=GRANTED}, highWatermark=Optional.empty, electionTimeoutMs=1048) (org.apache.kafka.raft.QuorumState)
[2025-08-10 11:38:18,738] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-08-10 11:38:18,739] INFO [ExpirationReaper-2-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-08-10 11:38:18,762] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-08-10 11:38:18,762] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-08-10 11:38:18,774] INFO [broker-3-to-controller-forwarding-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:38:18,774] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:38:18,803] INFO [MetadataLoader id=2] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:18,803] INFO [RaftManager id=2] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=1, leaderId=3, voters=[1, 2, 3], highWatermark=Optional.empty, fetchingSnapshot=Optional.empty) from Voted(epoch=1, votedId=3, voters=[1, 2, 3], electionTimeoutMs=1893) (org.apache.kafka.raft.QuorumState)
[2025-08-10 11:38:18,804] INFO [broker-2-to-controller-alter-partition-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:38:18,804] INFO [MetadataLoader id=3] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:18,816] INFO [broker-2-to-controller-heartbeat-channel-manager]: Starting (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:38:18,816] INFO [broker-2-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:38:18,821] INFO [broker-3-to-controller-alter-partition-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:38:18,823] INFO [BrokerLifecycleManager id=2] Incarnation J-dm-FJdRSSELBSqgnhkZA of broker 2 in cluster aDD5tmu7SImkoi2TMhth9A is now STARTING. (kafka.server.BrokerLifecycleManager)
[2025-08-10 11:38:18,831] INFO [BrokerToControllerChannelManager id=3 name=heartbeat] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:38:18,833] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:38:18,844] INFO [BrokerToControllerChannelManager id=2 name=heartbeat] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:38:18,847] INFO [broker-2-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:38:18,850] INFO [broker-2-to-controller-forwarding-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:38:18,863] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-08-10 11:38:18,884] INFO [BrokerServer id=2] Waiting for the broker metadata publishers to be installed (kafka.server.BrokerServer)
[2025-08-10 11:38:18,884] INFO [MetadataLoader id=2] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:18,884] INFO [BrokerServer id=2] Finished waiting for the broker metadata publishers to be installed (kafka.server.BrokerServer)
[2025-08-10 11:38:18,884] INFO [BrokerServer id=2] Waiting for the controller to acknowledge that we are caught up (kafka.server.BrokerServer)
[2025-08-10 11:38:18,898] INFO [broker-2-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:38:18,898] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:38:18,903] INFO [BrokerToControllerChannelManager id=3 name=heartbeat] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:38:18,904] INFO [BrokerToControllerChannelManager id=2 name=heartbeat] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:38:18,904] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:38:18,904] INFO [broker-2-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:38:18,912] INFO [RaftManager id=3] High watermark set to LogOffsetMetadata(offset=1, metadata=Optional[(segmentBaseOffset=0,relativePositionInSegment=106)]) for the first time for epoch 1 based on indexOfHw 1 and voters [ReplicaState(nodeId=2, endOffset=Optional[LogOffsetMetadata(offset=1, metadata=Optional[(segmentBaseOffset=0,relativePositionInSegment=106)])], lastFetchTimestamp=1754806098910, lastCaughtUpTimestamp=1754806098910, hasAcknowledgedLeader=true), ReplicaState(nodeId=3, endOffset=Optional[LogOffsetMetadata(offset=1, metadata=Optional[(segmentBaseOffset=0,relativePositionInSegment=106)])], lastFetchTimestamp=-1, lastCaughtUpTimestamp=-1, hasAcknowledgedLeader=true), ReplicaState(nodeId=1, endOffset=Optional.empty, lastFetchTimestamp=-1, lastCaughtUpTimestamp=-1, hasAcknowledgedLeader=false)] (org.apache.kafka.raft.LeaderState)
[2025-08-10 11:38:18,913] INFO [MetadataLoader id=3] initializeNewPublishers: The loader is still catching up because we have loaded up to offset -1, but the high water mark is 1 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:18,923] INFO [MetadataLoader id=3] maybePublishMetadata(LOG_DELTA): The loader is still catching up because we have not loaded a controller record as of offset 0 and high water mark is 1 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:18,942] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2025-08-10 11:38:18,960] INFO [broker-3-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:38:18,960] INFO [broker-2-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:38:18,978] INFO [RaftManager id=2] High watermark set to Optional[LogOffsetMetadata(offset=1, metadata=Optional.empty)] for the first time for epoch 1 (org.apache.kafka.raft.FollowerState)
[2025-08-10 11:38:18,985] INFO [MetadataLoader id=2] initializeNewPublishers: The loader is still catching up because we have loaded up to offset -1, but the high water mark is 1 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:18,991] INFO [MetadataLoader id=2] maybePublishMetadata(LOG_DELTA): The loader is still catching up because we have not loaded a controller record as of offset 0 and high water mark is 1 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:18,993] INFO [BrokerLifecycleManager id=3] Successfully registered broker 3 with broker epoch 5 (kafka.server.BrokerLifecycleManager)
[2025-08-10 11:38:18,996] INFO [MetadataLoader id=3] maybePublishMetadata(LOG_DELTA): The loader finished catching up to the current high water mark of 6 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:19,017] INFO [RaftManager id=3] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:38:19,017] WARN [RaftManager id=3] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:38:19,017] INFO [BrokerLifecycleManager id=2] Successfully registered broker 2 with broker epoch 6 (kafka.server.BrokerLifecycleManager)
[2025-08-10 11:38:19,019] INFO [MetadataLoader id=3] InitializeNewPublishers: initializing SnapshotGenerator with a snapshot at offset 5 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:19,021] INFO [MetadataLoader id=3] InitializeNewPublishers: initializing FeaturesPublisher with a snapshot at offset 5 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:19,022] INFO [MetadataLoader id=3] InitializeNewPublishers: initializing DynamicConfigPublisher controller id=3 with a snapshot at offset 5 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:19,024] INFO [MetadataLoader id=3] InitializeNewPublishers: initializing DynamicClientQuotaPublisher controller id=3 with a snapshot at offset 5 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:19,025] INFO [MetadataLoader id=3] InitializeNewPublishers: initializing ScramPublisher controller id=3 with a snapshot at offset 5 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:19,026] INFO [MetadataLoader id=2] maybePublishMetadata(LOG_DELTA): The loader finished catching up to the current high water mark of 6 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:19,027] INFO [MetadataLoader id=3] InitializeNewPublishers: initializing DelegationTokenPublisher controller id=3 with a snapshot at offset 5 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:19,029] INFO [MetadataLoader id=3] InitializeNewPublishers: initializing ControllerMetadataMetricsPublisher with a snapshot at offset 5 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:19,030] INFO [MetadataLoader id=3] InitializeNewPublishers: initializing AclPublisher controller id=3 with a snapshot at offset 5 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:19,031] INFO [MetadataLoader id=3] InitializeNewPublishers: initializing BrokerMetadataPublisher with a snapshot at offset 5 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:19,031] INFO [BrokerMetadataPublisher id=3] Publishing initial metadata at offset OffsetAndEpoch(offset=5, epoch=1) with metadata.version 3.6-IV2. (kafka.server.metadata.BrokerMetadataPublisher)
[2025-08-10 11:38:19,033] INFO Loading logs from log dirs ArraySeq(C:\tmp\server-3\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:38:19,040] INFO No logs found to be loaded in C:\tmp\server-3\kraft-combined-logs (kafka.log.LogManager)
[2025-08-10 11:38:19,042] INFO [BrokerLifecycleManager id=3] The broker has caught up. Transitioning from STARTING to RECOVERY. (kafka.server.BrokerLifecycleManager)
[2025-08-10 11:38:19,042] INFO [BrokerServer id=3] Finished waiting for the controller to acknowledge that we are caught up (kafka.server.BrokerServer)
[2025-08-10 11:38:19,042] INFO [BrokerServer id=3] Waiting for the initial broker metadata update to be published (kafka.server.BrokerServer)
[2025-08-10 11:38:19,047] INFO Loaded 0 logs in 15ms (kafka.log.LogManager)
[2025-08-10 11:38:19,048] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2025-08-10 11:38:19,049] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2025-08-10 11:38:19,057] INFO [BrokerLifecycleManager id=3] The broker is in RECOVERY. (kafka.server.BrokerLifecycleManager)
[2025-08-10 11:38:19,099] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2025-08-10 11:38:19,101] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-08-10 11:38:19,103] INFO [AddPartitionsToTxnSenderThread-3]: Starting (kafka.server.AddPartitionsToTxnManager)
[2025-08-10 11:38:19,105] INFO [GroupCoordinator 3]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:38:19,108] INFO [MetadataLoader id=2] InitializeNewPublishers: initializing SnapshotGenerator with a snapshot at offset 5 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:19,108] INFO [GroupCoordinator 3]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:38:19,108] INFO [MetadataLoader id=2] InitializeNewPublishers: initializing FeaturesPublisher with a snapshot at offset 5 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:19,109] INFO [MetadataLoader id=2] InitializeNewPublishers: initializing DynamicConfigPublisher controller id=2 with a snapshot at offset 5 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:19,109] INFO [TransactionCoordinator id=3] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-08-10 11:38:19,110] INFO [MetadataLoader id=2] InitializeNewPublishers: initializing DynamicClientQuotaPublisher controller id=2 with a snapshot at offset 5 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:19,111] INFO [TransactionCoordinator id=3] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-08-10 11:38:19,111] INFO [TxnMarkerSenderThread-3]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-08-10 11:38:19,112] INFO [MetadataLoader id=2] InitializeNewPublishers: initializing ScramPublisher controller id=2 with a snapshot at offset 5 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:19,114] INFO [BrokerMetadataPublisher id=3] Updating metadata.version to 14 at offset OffsetAndEpoch(offset=5, epoch=1). (kafka.server.metadata.BrokerMetadataPublisher)
[2025-08-10 11:38:19,114] INFO [MetadataLoader id=2] InitializeNewPublishers: initializing DelegationTokenPublisher controller id=2 with a snapshot at offset 5 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:19,117] INFO [MetadataLoader id=2] InitializeNewPublishers: initializing ControllerMetadataMetricsPublisher with a snapshot at offset 5 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:19,118] INFO [MetadataLoader id=2] InitializeNewPublishers: initializing AclPublisher controller id=2 with a snapshot at offset 5 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:19,120] INFO [MetadataLoader id=2] InitializeNewPublishers: initializing BrokerMetadataPublisher with a snapshot at offset 5 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:19,120] INFO [BrokerMetadataPublisher id=2] Publishing initial metadata at offset OffsetAndEpoch(offset=5, epoch=1) with metadata.version 3.6-IV2. (kafka.server.metadata.BrokerMetadataPublisher)
[2025-08-10 11:38:19,123] INFO Loading logs from log dirs ArraySeq(C:\tmp\server-2\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:38:19,124] INFO [BrokerServer id=3] Finished waiting for the initial broker metadata update to be published (kafka.server.BrokerServer)
[2025-08-10 11:38:19,125] INFO KafkaConfig values: 
	advertised.listeners = PLAINTEXT://localhost:9096
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = CONTROLLER
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = [1@localhost:9093, 2@localhost:9095, 3@localhost:9097]
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.new.enable = false
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = PLAINTEXT
	inter.broker.protocol.version = 3.6-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9096,CONTROLLER://:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/server-3/kraft-combined-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 3
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = [broker, controller]
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unstable.api.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = null
	zookeeper.connection.timeout.ms = null
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2025-08-10 11:38:19,130] INFO No logs found to be loaded in C:\tmp\server-2\kraft-combined-logs (kafka.log.LogManager)
[2025-08-10 11:38:19,140] INFO [BrokerServer id=3] Waiting for the broker to be unfenced (kafka.server.BrokerServer)
[2025-08-10 11:38:19,144] INFO Loaded 0 logs in 21ms (kafka.log.LogManager)
[2025-08-10 11:38:19,145] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2025-08-10 11:38:19,146] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2025-08-10 11:38:19,193] INFO [BrokerLifecycleManager id=3] The broker has been unfenced. Transitioning from RECOVERY to RUNNING. (kafka.server.BrokerLifecycleManager)
[2025-08-10 11:38:19,193] INFO [BrokerServer id=3] Finished waiting for the broker to be unfenced (kafka.server.BrokerServer)
[2025-08-10 11:38:19,194] INFO authorizerStart completed for endpoint PLAINTEXT. Endpoint is now READY. (org.apache.kafka.server.network.EndpointReadyFutures)
[2025-08-10 11:38:19,194] INFO [SocketServer listenerType=BROKER, nodeId=3] Enabling request processing. (kafka.network.SocketServer)
[2025-08-10 11:38:19,196] INFO Awaiting socket connections on 0.0.0.0:9096. (kafka.network.DataPlaneAcceptor)
[2025-08-10 11:38:19,197] INFO [BrokerServer id=3] Waiting for all of the authorizer futures to be completed (kafka.server.BrokerServer)
[2025-08-10 11:38:19,198] INFO [BrokerServer id=3] Finished waiting for all of the authorizer futures to be completed (kafka.server.BrokerServer)
[2025-08-10 11:38:19,198] INFO [BrokerServer id=3] Waiting for all of the SocketServer Acceptors to be started (kafka.server.BrokerServer)
[2025-08-10 11:38:19,198] INFO [BrokerServer id=3] Finished waiting for all of the SocketServer Acceptors to be started (kafka.server.BrokerServer)
[2025-08-10 11:38:19,198] INFO [BrokerServer id=3] Transition from STARTING to STARTED (kafka.server.BrokerServer)
[2025-08-10 11:38:19,199] INFO Kafka version: 3.6.2 (org.apache.kafka.common.utils.AppInfoParser)
[2025-08-10 11:38:19,199] INFO Kafka commitId: c4deed513057c94e (org.apache.kafka.common.utils.AppInfoParser)
[2025-08-10 11:38:19,199] INFO Kafka startTimeMs: 1754806099198 (org.apache.kafka.common.utils.AppInfoParser)
[2025-08-10 11:38:19,201] INFO [KafkaRaftServer nodeId=3] Kafka Server started (kafka.server.KafkaRaftServer)
[2025-08-10 11:38:19,212] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2025-08-10 11:38:19,214] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-08-10 11:38:19,216] INFO [AddPartitionsToTxnSenderThread-2]: Starting (kafka.server.AddPartitionsToTxnManager)
[2025-08-10 11:38:19,216] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:38:19,219] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:38:19,220] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-08-10 11:38:19,222] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-08-10 11:38:19,222] INFO [TxnMarkerSenderThread-2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-08-10 11:38:19,224] INFO [BrokerMetadataPublisher id=2] Updating metadata.version to 14 at offset OffsetAndEpoch(offset=5, epoch=1). (kafka.server.metadata.BrokerMetadataPublisher)
[2025-08-10 11:38:19,243] INFO [BrokerLifecycleManager id=2] The broker has caught up. Transitioning from STARTING to RECOVERY. (kafka.server.BrokerLifecycleManager)
[2025-08-10 11:38:19,243] INFO [BrokerServer id=2] Finished waiting for the controller to acknowledge that we are caught up (kafka.server.BrokerServer)
[2025-08-10 11:38:19,243] INFO [BrokerServer id=2] Waiting for the initial broker metadata update to be published (kafka.server.BrokerServer)
[2025-08-10 11:38:19,243] INFO [BrokerServer id=2] Finished waiting for the initial broker metadata update to be published (kafka.server.BrokerServer)
[2025-08-10 11:38:19,245] INFO KafkaConfig values: 
	advertised.listeners = PLAINTEXT://localhost:9094
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = CONTROLLER
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = [1@localhost:9093, 2@localhost:9095, 3@localhost:9097]
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.new.enable = false
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = PLAINTEXT
	inter.broker.protocol.version = 3.6-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094,CONTROLLER://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/server-2/kraft-combined-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = [broker, controller]
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unstable.api.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = null
	zookeeper.connection.timeout.ms = null
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2025-08-10 11:38:19,253] INFO [BrokerServer id=2] Waiting for the broker to be unfenced (kafka.server.BrokerServer)
[2025-08-10 11:38:19,289] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2025-08-10 11:38:19,294] INFO [BrokerLifecycleManager id=2] The broker has been unfenced. Transitioning from RECOVERY to RUNNING. (kafka.server.BrokerLifecycleManager)
[2025-08-10 11:38:19,295] INFO [BrokerServer id=2] Finished waiting for the broker to be unfenced (kafka.server.BrokerServer)
[2025-08-10 11:38:19,296] INFO authorizerStart completed for endpoint PLAINTEXT. Endpoint is now READY. (org.apache.kafka.server.network.EndpointReadyFutures)
[2025-08-10 11:38:19,296] INFO [SocketServer listenerType=BROKER, nodeId=2] Enabling request processing. (kafka.network.SocketServer)
[2025-08-10 11:38:19,297] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.DataPlaneAcceptor)
[2025-08-10 11:38:19,298] INFO [BrokerServer id=2] Waiting for all of the authorizer futures to be completed (kafka.server.BrokerServer)
[2025-08-10 11:38:19,298] INFO [BrokerServer id=2] Finished waiting for all of the authorizer futures to be completed (kafka.server.BrokerServer)
[2025-08-10 11:38:19,298] INFO [BrokerServer id=2] Waiting for all of the SocketServer Acceptors to be started (kafka.server.BrokerServer)
[2025-08-10 11:38:19,298] INFO [BrokerServer id=2] Finished waiting for all of the SocketServer Acceptors to be started (kafka.server.BrokerServer)
[2025-08-10 11:38:19,298] INFO [BrokerServer id=2] Transition from STARTING to STARTED (kafka.server.BrokerServer)
[2025-08-10 11:38:19,300] INFO Kafka version: 3.6.2 (org.apache.kafka.common.utils.AppInfoParser)
[2025-08-10 11:38:19,300] INFO Kafka commitId: c4deed513057c94e (org.apache.kafka.common.utils.AppInfoParser)
[2025-08-10 11:38:19,301] INFO Kafka startTimeMs: 1754806099300 (org.apache.kafka.common.utils.AppInfoParser)
[2025-08-10 11:38:19,302] INFO [KafkaRaftServer nodeId=2] Kafka Server started (kafka.server.KafkaRaftServer)
[2025-08-10 11:38:19,474] INFO [ControllerServer id=1] Starting controller (kafka.server.ControllerServer)
[2025-08-10 11:38:19,497] INFO authorizerStart completed for endpoint CONTROLLER. Endpoint is now READY. (org.apache.kafka.server.network.EndpointReadyFutures)
[2025-08-10 11:38:19,611] INFO [RaftManager id=3] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:38:19,611] WARN [RaftManager id=3] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:38:19,790] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2025-08-10 11:38:19,866] INFO [SocketServer listenerType=CONTROLLER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(CONTROLLER) (kafka.network.SocketServer)
[2025-08-10 11:38:19,868] INFO [SharedServer id=1] Starting SharedServer (kafka.server.SharedServer)
[2025-08-10 11:38:19,933] INFO [LogLoader partition=__cluster_metadata-0, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:38:19,934] INFO [LogLoader partition=__cluster_metadata-0, dir=C:\tmp\server-1\kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:38:19,934] INFO [LogLoader partition=__cluster_metadata-0, dir=C:\tmp\server-1\kraft-combined-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-08-10 11:38:19,965] INFO Initialized snapshots with IDs SortedSet() from C:\tmp\server-1\kraft-combined-logs\__cluster_metadata-0 (kafka.raft.KafkaMetadataLog$)
[2025-08-10 11:38:19,979] INFO [raft-expiration-reaper]: Starting (kafka.raft.TimingWheelExpirationService$ExpiredOperationReaper)
[2025-08-10 11:38:20,097] INFO [RaftManager id=1] Completed transition to Unattached(epoch=0, voters=[1, 2, 3], electionTimeoutMs=1129) from null (org.apache.kafka.raft.QuorumState)
[2025-08-10 11:38:20,100] INFO [kafka-1-raft-outbound-request-thread]: Starting (kafka.raft.RaftSendThread)
[2025-08-10 11:38:20,100] INFO [kafka-1-raft-io-thread]: Starting (kafka.raft.KafkaRaftManager$RaftIoThread)
[2025-08-10 11:38:20,119] INFO [MetadataLoader id=1] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:20,121] INFO [RaftManager id=1] Registered the listener org.apache.kafka.image.loader.MetadataLoader@1171484896 (org.apache.kafka.raft.KafkaRaftClient)
[2025-08-10 11:38:20,121] INFO [ControllerServer id=1] Waiting for controller quorum voters future (kafka.server.ControllerServer)
[2025-08-10 11:38:20,122] INFO [ControllerServer id=1] Finished waiting for controller quorum voters future (kafka.server.ControllerServer)
[2025-08-10 11:38:20,152] INFO [RaftManager id=3] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:38:20,153] WARN [RaftManager id=3] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:38:20,154] INFO [RaftManager id=1] Registered the listener org.apache.kafka.controller.QuorumController$QuorumMetaLogListener@556276159 (org.apache.kafka.raft.KafkaRaftClient)
[2025-08-10 11:38:20,162] INFO [controller-1-ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-08-10 11:38:20,162] INFO [controller-1-ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-08-10 11:38:20,163] INFO [controller-1-ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-08-10 11:38:20,165] INFO [controller-1-ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-08-10 11:38:20,184] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-08-10 11:38:20,194] INFO [ControllerServer id=1] Waiting for the controller metadata publishers to be installed (kafka.server.ControllerServer)
[2025-08-10 11:38:20,195] INFO [MetadataLoader id=1] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:20,195] INFO [ControllerServer id=1] Finished waiting for the controller metadata publishers to be installed (kafka.server.ControllerServer)
[2025-08-10 11:38:20,195] INFO [SocketServer listenerType=CONTROLLER, nodeId=1] Enabling request processing. (kafka.network.SocketServer)
[2025-08-10 11:38:20,200] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.DataPlaneAcceptor)
[2025-08-10 11:38:20,202] INFO [ControllerServer id=1] Waiting for all of the authorizer futures to be completed (kafka.server.ControllerServer)
[2025-08-10 11:38:20,203] INFO [ControllerServer id=1] Finished waiting for all of the authorizer futures to be completed (kafka.server.ControllerServer)
[2025-08-10 11:38:20,203] INFO [ControllerServer id=1] Waiting for all of the SocketServer Acceptors to be started (kafka.server.ControllerServer)
[2025-08-10 11:38:20,203] INFO [ControllerServer id=1] Finished waiting for all of the SocketServer Acceptors to be started (kafka.server.ControllerServer)
[2025-08-10 11:38:20,204] INFO [BrokerServer id=1] Transition from SHUTDOWN to STARTING (kafka.server.BrokerServer)
[2025-08-10 11:38:20,205] INFO [BrokerServer id=1] Starting broker (kafka.server.BrokerServer)
[2025-08-10 11:38:20,215] INFO [broker-1-ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-08-10 11:38:20,215] INFO [broker-1-ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-08-10 11:38:20,215] INFO [broker-1-ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-08-10 11:38:20,215] INFO [broker-1-ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-08-10 11:38:20,240] INFO [BrokerServer id=1] Waiting for controller quorum voters future (kafka.server.BrokerServer)
[2025-08-10 11:38:20,240] INFO [BrokerServer id=1] Finished waiting for controller quorum voters future (kafka.server.BrokerServer)
[2025-08-10 11:38:20,248] INFO [broker-1-to-controller-forwarding-channel-manager]: Starting (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:38:20,278] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2025-08-10 11:38:20,291] INFO [SocketServer listenerType=BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2025-08-10 11:38:20,298] INFO [broker-1-to-controller-alter-partition-channel-manager]: Starting (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:38:20,307] INFO [MetadataLoader id=1] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:20,318] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-08-10 11:38:20,319] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-08-10 11:38:20,321] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-08-10 11:38:20,322] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-08-10 11:38:20,323] INFO [ExpirationReaper-1-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-08-10 11:38:20,338] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-08-10 11:38:20,339] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-08-10 11:38:20,378] INFO [broker-1-to-controller-heartbeat-channel-manager]: Starting (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:38:20,381] INFO [BrokerLifecycleManager id=1] Incarnation wyAkRzMvSS6yu91Qn5qWvA of broker 1 in cluster aDD5tmu7SImkoi2TMhth9A is now STARTING. (kafka.server.BrokerLifecycleManager)
[2025-08-10 11:38:20,398] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-08-10 11:38:20,412] INFO [BrokerServer id=1] Waiting for the broker metadata publishers to be installed (kafka.server.BrokerServer)
[2025-08-10 11:38:20,412] INFO [MetadataLoader id=1] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:20,413] INFO [MetadataLoader id=1] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:20,413] INFO [BrokerServer id=1] Finished waiting for the broker metadata publishers to be installed (kafka.server.BrokerServer)
[2025-08-10 11:38:20,413] INFO [BrokerServer id=1] Waiting for the controller to acknowledge that we are caught up (kafka.server.BrokerServer)
[2025-08-10 11:38:20,523] INFO [MetadataLoader id=1] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:20,632] INFO [MetadataLoader id=1] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:20,671] INFO [RaftManager id=1] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=1, leaderId=3, voters=[1, 2, 3], highWatermark=Optional.empty, fetchingSnapshot=Optional.empty) from Unattached(epoch=0, voters=[1, 2, 3], electionTimeoutMs=1129) (org.apache.kafka.raft.QuorumState)
[2025-08-10 11:38:20,679] INFO [broker-1-to-controller-forwarding-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:38:20,693] INFO [broker-1-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:38:20,709] INFO [broker-1-to-controller-alter-partition-channel-manager]: Recorded new controller, from now on will use node localhost:9097 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2025-08-10 11:38:20,734] INFO [RaftManager id=1] High watermark set to Optional[LogOffsetMetadata(offset=12, metadata=Optional.empty)] for the first time for epoch 1 (org.apache.kafka.raft.FollowerState)
[2025-08-10 11:38:20,741] INFO [MetadataLoader id=1] initializeNewPublishers: The loader is still catching up because we have loaded up to offset -1, but the high water mark is 12 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:20,751] INFO [BrokerLifecycleManager id=1] Successfully registered broker 1 with broker epoch 12 (kafka.server.BrokerLifecycleManager)
[2025-08-10 11:38:20,752] INFO [MetadataLoader id=1] maybePublishMetadata(LOG_DELTA): The loader is still catching up because we have loaded up to offset 0, but the high water mark is 12 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:20,762] INFO [MetadataLoader id=1] maybePublishMetadata(LOG_DELTA): The loader finished catching up to the current high water mark of 12 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:20,852] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing SnapshotGenerator with a snapshot at offset 11 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:20,853] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing FeaturesPublisher with a snapshot at offset 11 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:20,853] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing DynamicConfigPublisher controller id=1 with a snapshot at offset 11 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:20,855] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing DynamicClientQuotaPublisher controller id=1 with a snapshot at offset 11 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:20,856] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing ScramPublisher controller id=1 with a snapshot at offset 11 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:20,857] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing DelegationTokenPublisher controller id=1 with a snapshot at offset 11 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:20,858] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing ControllerMetadataMetricsPublisher with a snapshot at offset 11 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:20,859] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing AclPublisher controller id=1 with a snapshot at offset 11 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:20,859] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing BrokerMetadataPublisher with a snapshot at offset 11 (org.apache.kafka.image.loader.MetadataLoader)
[2025-08-10 11:38:20,860] INFO [BrokerMetadataPublisher id=1] Publishing initial metadata at offset OffsetAndEpoch(offset=11, epoch=1) with metadata.version 3.6-IV2. (kafka.server.metadata.BrokerMetadataPublisher)
[2025-08-10 11:38:20,861] INFO Loading logs from log dirs ArraySeq(C:\tmp\server-1\kraft-combined-logs) (kafka.log.LogManager)
[2025-08-10 11:38:20,865] INFO No logs found to be loaded in C:\tmp\server-1\kraft-combined-logs (kafka.log.LogManager)
[2025-08-10 11:38:20,872] INFO Loaded 0 logs in 11ms (kafka.log.LogManager)
[2025-08-10 11:38:20,873] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2025-08-10 11:38:20,874] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2025-08-10 11:38:20,931] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2025-08-10 11:38:20,933] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-08-10 11:38:20,934] INFO [AddPartitionsToTxnSenderThread-1]: Starting (kafka.server.AddPartitionsToTxnManager)
[2025-08-10 11:38:20,934] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:38:20,937] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:38:20,938] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-08-10 11:38:20,940] INFO [TxnMarkerSenderThread-1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-08-10 11:38:20,940] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-08-10 11:38:20,941] INFO [BrokerMetadataPublisher id=1] Updating metadata.version to 14 at offset OffsetAndEpoch(offset=11, epoch=1). (kafka.server.metadata.BrokerMetadataPublisher)
[2025-08-10 11:38:21,040] INFO [BrokerLifecycleManager id=1] The broker has caught up. Transitioning from STARTING to RECOVERY. (kafka.server.BrokerLifecycleManager)
[2025-08-10 11:38:21,040] INFO [BrokerServer id=1] Finished waiting for the controller to acknowledge that we are caught up (kafka.server.BrokerServer)
[2025-08-10 11:38:21,042] INFO [BrokerServer id=1] Waiting for the initial broker metadata update to be published (kafka.server.BrokerServer)
[2025-08-10 11:38:21,042] INFO [BrokerServer id=1] Finished waiting for the initial broker metadata update to be published (kafka.server.BrokerServer)
[2025-08-10 11:38:21,043] INFO KafkaConfig values: 
	advertised.listeners = PLAINTEXT://localhost:9092
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = CONTROLLER
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = [1@localhost:9093, 2@localhost:9095, 3@localhost:9097]
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.new.enable = false
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = PLAINTEXT
	inter.broker.protocol.version = 3.6-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092,CONTROLLER://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/server-1/kraft-combined-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = [broker, controller]
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unstable.api.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = null
	zookeeper.connection.timeout.ms = null
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2025-08-10 11:38:21,051] INFO [BrokerServer id=1] Waiting for the broker to be unfenced (kafka.server.BrokerServer)
[2025-08-10 11:38:21,092] INFO [BrokerLifecycleManager id=1] The broker has been unfenced. Transitioning from RECOVERY to RUNNING. (kafka.server.BrokerLifecycleManager)
[2025-08-10 11:38:21,092] INFO [BrokerServer id=1] Finished waiting for the broker to be unfenced (kafka.server.BrokerServer)
[2025-08-10 11:38:21,094] INFO authorizerStart completed for endpoint PLAINTEXT. Endpoint is now READY. (org.apache.kafka.server.network.EndpointReadyFutures)
[2025-08-10 11:38:21,094] INFO [SocketServer listenerType=BROKER, nodeId=1] Enabling request processing. (kafka.network.SocketServer)
[2025-08-10 11:38:21,095] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.DataPlaneAcceptor)
[2025-08-10 11:38:21,096] INFO [BrokerServer id=1] Waiting for all of the authorizer futures to be completed (kafka.server.BrokerServer)
[2025-08-10 11:38:21,096] INFO [BrokerServer id=1] Finished waiting for all of the authorizer futures to be completed (kafka.server.BrokerServer)
[2025-08-10 11:38:21,096] INFO [BrokerServer id=1] Waiting for all of the SocketServer Acceptors to be started (kafka.server.BrokerServer)
[2025-08-10 11:38:21,096] INFO [BrokerServer id=1] Finished waiting for all of the SocketServer Acceptors to be started (kafka.server.BrokerServer)
[2025-08-10 11:38:21,096] INFO [BrokerServer id=1] Transition from STARTING to STARTED (kafka.server.BrokerServer)
[2025-08-10 11:38:21,097] INFO Kafka version: 3.6.2 (org.apache.kafka.common.utils.AppInfoParser)
[2025-08-10 11:38:21,097] INFO Kafka commitId: c4deed513057c94e (org.apache.kafka.common.utils.AppInfoParser)
[2025-08-10 11:38:21,097] INFO Kafka startTimeMs: 1754806101096 (org.apache.kafka.common.utils.AppInfoParser)
[2025-08-10 11:38:21,099] INFO [KafkaRaftServer nodeId=1] Kafka Server started (kafka.server.KafkaRaftServer)
[2025-08-10 11:38:51,019] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(new-employee-created-event-1) (kafka.server.ReplicaFetcherManager)
[2025-08-10 11:38:51,044] INFO [LogLoader partition=new-employee-created-event-1, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:38:51,047] INFO Created log for partition new-employee-created-event-1 in C:\tmp\server-3\kraft-combined-logs\new-employee-created-event-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2025-08-10 11:38:51,050] INFO [Partition new-employee-created-event-1 broker=3] No checkpointed highwatermark is found for partition new-employee-created-event-1 (kafka.cluster.Partition)
[2025-08-10 11:38:51,051] INFO [Partition new-employee-created-event-1 broker=3] Log loaded for partition new-employee-created-event-1 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:38:51,075] INFO [LogLoader partition=new-employee-created-event-2, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:38:51,076] INFO Created log for partition new-employee-created-event-2 in C:\tmp\server-3\kraft-combined-logs\new-employee-created-event-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2025-08-10 11:38:51,076] INFO [Partition new-employee-created-event-2 broker=3] No checkpointed highwatermark is found for partition new-employee-created-event-2 (kafka.cluster.Partition)
[2025-08-10 11:38:51,076] INFO [Partition new-employee-created-event-2 broker=3] Log loaded for partition new-employee-created-event-2 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:38:51,084] INFO [LogLoader partition=new-employee-created-event-0, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:38:51,085] INFO Created log for partition new-employee-created-event-0 in C:\tmp\server-3\kraft-combined-logs\new-employee-created-event-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2025-08-10 11:38:51,085] INFO [Partition new-employee-created-event-0 broker=3] No checkpointed highwatermark is found for partition new-employee-created-event-0 (kafka.cluster.Partition)
[2025-08-10 11:38:51,086] INFO [Partition new-employee-created-event-0 broker=3] Log loaded for partition new-employee-created-event-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:38:51,087] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(new-employee-created-event-0, new-employee-created-event-2) (kafka.server.ReplicaFetcherManager)
[2025-08-10 11:38:51,106] INFO [ReplicaFetcherThread-0-2]: Starting (kafka.server.ReplicaFetcherThread)
[2025-08-10 11:38:51,109] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker 2 for partitions HashMap(new-employee-created-event-0 -> InitialFetchState(Some(p4uIezIWQNKkDwl6hI_7Nw),BrokerEndPoint(id=2, host=localhost:9094),0,0)) (kafka.server.ReplicaFetcherManager)
[2025-08-10 11:38:51,112] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Truncating partition new-employee-created-event-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2025-08-10 11:38:51,113] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker 1 for partitions HashMap(new-employee-created-event-2 -> InitialFetchState(Some(p4uIezIWQNKkDwl6hI_7Nw),BrokerEndPoint(id=1, host=localhost:9092),0,0)) (kafka.server.ReplicaFetcherManager)
[2025-08-10 11:38:51,113] INFO [ReplicaFetcherThread-0-1]: Starting (kafka.server.ReplicaFetcherThread)
[2025-08-10 11:38:51,113] INFO [UnifiedLog partition=new-employee-created-event-0, dir=C:\tmp\server-3\kraft-combined-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2025-08-10 11:38:51,115] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Truncating partition new-employee-created-event-2 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2025-08-10 11:38:51,115] INFO [UnifiedLog partition=new-employee-created-event-2, dir=C:\tmp\server-3\kraft-combined-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2025-08-10 11:38:51,127] INFO [DynamicConfigPublisher broker id=3] Updating topic new-employee-created-event with new configuration : min.insync.replicas -> 2 (kafka.server.metadata.DynamicConfigPublisher)
[2025-08-10 11:38:51,176] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(new-employee-created-event-0) (kafka.server.ReplicaFetcherManager)
[2025-08-10 11:38:51,185] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(new-employee-created-event-2) (kafka.server.ReplicaFetcherManager)
[2025-08-10 11:38:51,194] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition new-employee-created-event-2. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2025-08-10 11:38:51,194] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition new-employee-created-event-0. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2025-08-10 11:38:51,224] INFO [LogLoader partition=new-employee-created-event-0, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:38:51,230] INFO Created log for partition new-employee-created-event-0 in C:\tmp\server-2\kraft-combined-logs\new-employee-created-event-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2025-08-10 11:38:51,231] INFO [LogLoader partition=new-employee-created-event-2, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:38:51,233] INFO [Partition new-employee-created-event-0 broker=2] No checkpointed highwatermark is found for partition new-employee-created-event-0 (kafka.cluster.Partition)
[2025-08-10 11:38:51,236] INFO Created log for partition new-employee-created-event-2 in C:\tmp\server-1\kraft-combined-logs\new-employee-created-event-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2025-08-10 11:38:51,236] INFO [Partition new-employee-created-event-0 broker=2] Log loaded for partition new-employee-created-event-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:38:51,239] INFO [Partition new-employee-created-event-2 broker=1] No checkpointed highwatermark is found for partition new-employee-created-event-2 (kafka.cluster.Partition)
[2025-08-10 11:38:51,242] INFO [Partition new-employee-created-event-2 broker=1] Log loaded for partition new-employee-created-event-2 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:38:51,271] INFO [LogLoader partition=new-employee-created-event-2, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:38:51,274] INFO Created log for partition new-employee-created-event-2 in C:\tmp\server-2\kraft-combined-logs\new-employee-created-event-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2025-08-10 11:38:51,275] INFO [Partition new-employee-created-event-2 broker=2] No checkpointed highwatermark is found for partition new-employee-created-event-2 (kafka.cluster.Partition)
[2025-08-10 11:38:51,275] INFO [Partition new-employee-created-event-2 broker=2] Log loaded for partition new-employee-created-event-2 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:38:51,278] INFO [LogLoader partition=new-employee-created-event-1, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:38:51,280] INFO Created log for partition new-employee-created-event-1 in C:\tmp\server-1\kraft-combined-logs\new-employee-created-event-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2025-08-10 11:38:51,280] INFO [Partition new-employee-created-event-1 broker=1] No checkpointed highwatermark is found for partition new-employee-created-event-1 (kafka.cluster.Partition)
[2025-08-10 11:38:51,280] INFO [Partition new-employee-created-event-1 broker=1] Log loaded for partition new-employee-created-event-1 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:38:51,291] INFO [LogLoader partition=new-employee-created-event-1, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:38:51,292] INFO Created log for partition new-employee-created-event-1 in C:\tmp\server-2\kraft-combined-logs\new-employee-created-event-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2025-08-10 11:38:51,292] INFO [Partition new-employee-created-event-1 broker=2] No checkpointed highwatermark is found for partition new-employee-created-event-1 (kafka.cluster.Partition)
[2025-08-10 11:38:51,294] INFO [Partition new-employee-created-event-1 broker=2] Log loaded for partition new-employee-created-event-1 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:38:51,295] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(new-employee-created-event-2, new-employee-created-event-1) (kafka.server.ReplicaFetcherManager)
[2025-08-10 11:38:51,297] INFO [LogLoader partition=new-employee-created-event-0, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:38:51,300] INFO Created log for partition new-employee-created-event-0 in C:\tmp\server-1\kraft-combined-logs\new-employee-created-event-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2025-08-10 11:38:51,302] INFO [Partition new-employee-created-event-0 broker=1] No checkpointed highwatermark is found for partition new-employee-created-event-0 (kafka.cluster.Partition)
[2025-08-10 11:38:51,302] INFO [Partition new-employee-created-event-0 broker=1] Log loaded for partition new-employee-created-event-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:38:51,304] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(new-employee-created-event-0, new-employee-created-event-1) (kafka.server.ReplicaFetcherManager)
[2025-08-10 11:38:51,332] INFO [ReplicaFetcherThread-0-3]: Starting (kafka.server.ReplicaFetcherThread)
[2025-08-10 11:38:51,337] INFO [ReplicaFetcherThread-0-3]: Starting (kafka.server.ReplicaFetcherThread)
[2025-08-10 11:38:51,337] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 3 for partitions HashMap(new-employee-created-event-1 -> InitialFetchState(Some(p4uIezIWQNKkDwl6hI_7Nw),BrokerEndPoint(id=3, host=localhost:9096),0,0)) (kafka.server.ReplicaFetcherManager)
[2025-08-10 11:38:51,339] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Truncating partition new-employee-created-event-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2025-08-10 11:38:51,342] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 3 for partitions HashMap(new-employee-created-event-1 -> InitialFetchState(Some(p4uIezIWQNKkDwl6hI_7Nw),BrokerEndPoint(id=3, host=localhost:9096),0,0)) (kafka.server.ReplicaFetcherManager)
[2025-08-10 11:38:51,343] INFO [UnifiedLog partition=new-employee-created-event-1, dir=C:\tmp\server-2\kraft-combined-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2025-08-10 11:38:51,344] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 1 for partitions HashMap(new-employee-created-event-2 -> InitialFetchState(Some(p4uIezIWQNKkDwl6hI_7Nw),BrokerEndPoint(id=1, host=localhost:9092),0,0)) (kafka.server.ReplicaFetcherManager)
[2025-08-10 11:38:51,344] INFO [ReplicaFetcherThread-0-1]: Starting (kafka.server.ReplicaFetcherThread)
[2025-08-10 11:38:51,345] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition new-employee-created-event-2 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2025-08-10 11:38:51,345] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Truncating partition new-employee-created-event-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2025-08-10 11:38:51,346] INFO [UnifiedLog partition=new-employee-created-event-2, dir=C:\tmp\server-2\kraft-combined-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2025-08-10 11:38:51,348] INFO [UnifiedLog partition=new-employee-created-event-1, dir=C:\tmp\server-1\kraft-combined-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2025-08-10 11:38:51,349] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 2 for partitions HashMap(new-employee-created-event-0 -> InitialFetchState(Some(p4uIezIWQNKkDwl6hI_7Nw),BrokerEndPoint(id=2, host=localhost:9094),0,0)) (kafka.server.ReplicaFetcherManager)
[2025-08-10 11:38:51,350] INFO [ReplicaFetcherThread-0-2]: Starting (kafka.server.ReplicaFetcherThread)
[2025-08-10 11:38:51,353] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition new-employee-created-event-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2025-08-10 11:38:51,355] INFO [UnifiedLog partition=new-employee-created-event-0, dir=C:\tmp\server-1\kraft-combined-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2025-08-10 11:38:51,372] INFO [DynamicConfigPublisher broker id=2] Updating topic new-employee-created-event with new configuration : min.insync.replicas -> 2 (kafka.server.metadata.DynamicConfigPublisher)
[2025-08-10 11:38:51,383] INFO [DynamicConfigPublisher broker id=1] Updating topic new-employee-created-event with new configuration : min.insync.replicas -> 2 (kafka.server.metadata.DynamicConfigPublisher)
[2025-08-10 11:39:11,887] INFO Sent auto-creation request for Set(__consumer_offsets) to the active controller. (kafka.server.DefaultAutoTopicCreationManager)
[2025-08-10 11:39:11,953] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(__consumer_offsets-47, __consumer_offsets-14, __consumer_offsets-11, __consumer_offsets-42, __consumer_offsets-22, __consumer_offsets-20, __consumer_offsets-17, __consumer_offsets-30, __consumer_offsets-28, __consumer_offsets-26, __consumer_offsets-39, __consumer_offsets-6, __consumer_offsets-3, __consumer_offsets-35, __consumer_offsets-36, __consumer_offsets-2) (kafka.server.ReplicaFetcherManager)
[2025-08-10 11:39:11,963] INFO [LogLoader partition=__consumer_offsets-47, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:39:11,965] INFO Created log for partition __consumer_offsets-47 in C:\tmp\server-3\kraft-combined-logs\__consumer_offsets-47 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-08-10 11:39:11,996] INFO [Partition __consumer_offsets-47 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2025-08-10 11:39:11,997] INFO [Partition __consumer_offsets-47 broker=3] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:39:12,012] INFO [LogLoader partition=__consumer_offsets-14, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:39:12,014] INFO Created log for partition __consumer_offsets-14 in C:\tmp\server-3\kraft-combined-logs\__consumer_offsets-14 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-08-10 11:39:12,014] INFO [Partition __consumer_offsets-14 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2025-08-10 11:39:12,014] INFO [Partition __consumer_offsets-14 broker=3] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:39:12,034] INFO [LogLoader partition=__consumer_offsets-11, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:39:12,035] INFO Created log for partition __consumer_offsets-11 in C:\tmp\server-3\kraft-combined-logs\__consumer_offsets-11 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-08-10 11:39:12,036] INFO [Partition __consumer_offsets-11 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2025-08-10 11:39:12,037] INFO [Partition __consumer_offsets-11 broker=3] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:39:12,057] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(__consumer_offsets-16, __consumer_offsets-48, __consumer_offsets-45, __consumer_offsets-12, __consumer_offsets-44, __consumer_offsets-41, __consumer_offsets-10, __consumer_offsets-21, __consumer_offsets-18, __consumer_offsets-31, __consumer_offsets-0, __consumer_offsets-29, __consumer_offsets-25, __consumer_offsets-7, __consumer_offsets-5, __consumer_offsets-38, __consumer_offsets-33) (kafka.server.ReplicaFetcherManager)
[2025-08-10 11:39:12,059] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(__consumer_offsets-15, __consumer_offsets-13, __consumer_offsets-46, __consumer_offsets-43, __consumer_offsets-9, __consumer_offsets-23, __consumer_offsets-24, __consumer_offsets-19, __consumer_offsets-49, __consumer_offsets-32, __consumer_offsets-27, __consumer_offsets-8, __consumer_offsets-40, __consumer_offsets-37, __consumer_offsets-4, __consumer_offsets-1, __consumer_offsets-34) (kafka.server.ReplicaFetcherManager)
[2025-08-10 11:39:12,063] INFO [LogLoader partition=__consumer_offsets-42, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:39:12,065] INFO Created log for partition __consumer_offsets-42 in C:\tmp\server-3\kraft-combined-logs\__consumer_offsets-42 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-08-10 11:39:12,066] INFO [Partition __consumer_offsets-42 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2025-08-10 11:39:12,071] INFO [Partition __consumer_offsets-42 broker=3] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:39:12,073] INFO [LogLoader partition=__consumer_offsets-16, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:39:12,077] INFO Created log for partition __consumer_offsets-16 in C:\tmp\server-1\kraft-combined-logs\__consumer_offsets-16 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-08-10 11:39:12,079] INFO [LogLoader partition=__consumer_offsets-15, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:39:12,080] INFO [Partition __consumer_offsets-16 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2025-08-10 11:39:12,084] INFO [Partition __consumer_offsets-16 broker=1] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:39:12,082] INFO Created log for partition __consumer_offsets-15 in C:\tmp\server-2\kraft-combined-logs\__consumer_offsets-15 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-08-10 11:39:12,091] INFO [Partition __consumer_offsets-15 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2025-08-10 11:39:12,092] INFO [Partition __consumer_offsets-15 broker=2] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:39:12,095] INFO [LogLoader partition=__consumer_offsets-22, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:39:12,098] INFO Created log for partition __consumer_offsets-22 in C:\tmp\server-3\kraft-combined-logs\__consumer_offsets-22 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-08-10 11:39:12,100] INFO [Partition __consumer_offsets-22 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2025-08-10 11:39:12,101] INFO [Partition __consumer_offsets-22 broker=3] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:39:12,110] INFO [LogLoader partition=__consumer_offsets-48, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:39:12,112] INFO Created log for partition __consumer_offsets-48 in C:\tmp\server-1\kraft-combined-logs\__consumer_offsets-48 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-08-10 11:39:12,112] INFO [Partition __consumer_offsets-48 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2025-08-10 11:39:12,112] INFO [Partition __consumer_offsets-48 broker=1] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:39:12,115] INFO [LogLoader partition=__consumer_offsets-13, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:39:12,123] INFO Created log for partition __consumer_offsets-13 in C:\tmp\server-2\kraft-combined-logs\__consumer_offsets-13 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-08-10 11:39:12,124] INFO [Partition __consumer_offsets-13 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2025-08-10 11:39:12,124] INFO [Partition __consumer_offsets-13 broker=2] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:39:12,126] INFO [LogLoader partition=__consumer_offsets-20, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:39:12,137] INFO Created log for partition __consumer_offsets-20 in C:\tmp\server-3\kraft-combined-logs\__consumer_offsets-20 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-08-10 11:39:12,138] INFO [Partition __consumer_offsets-20 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2025-08-10 11:39:12,138] INFO [Partition __consumer_offsets-20 broker=3] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:39:12,141] INFO [LogLoader partition=__consumer_offsets-45, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:39:12,145] INFO Created log for partition __consumer_offsets-45 in C:\tmp\server-1\kraft-combined-logs\__consumer_offsets-45 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-08-10 11:39:12,145] INFO [LogLoader partition=__consumer_offsets-46, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:39:12,146] INFO [Partition __consumer_offsets-45 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2025-08-10 11:39:12,149] INFO [Partition __consumer_offsets-45 broker=1] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:39:12,148] INFO Created log for partition __consumer_offsets-46 in C:\tmp\server-2\kraft-combined-logs\__consumer_offsets-46 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-08-10 11:39:12,150] INFO [Partition __consumer_offsets-46 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2025-08-10 11:39:12,151] INFO [Partition __consumer_offsets-46 broker=2] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:39:12,158] INFO [LogLoader partition=__consumer_offsets-17, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:39:12,163] INFO Created log for partition __consumer_offsets-17 in C:\tmp\server-3\kraft-combined-logs\__consumer_offsets-17 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-08-10 11:39:12,164] INFO [Partition __consumer_offsets-17 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2025-08-10 11:39:12,164] INFO [Partition __consumer_offsets-17 broker=3] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:39:12,172] INFO [LogLoader partition=__consumer_offsets-43, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:39:12,173] INFO [LogLoader partition=__consumer_offsets-12, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:39:12,173] INFO Created log for partition __consumer_offsets-43 in C:\tmp\server-2\kraft-combined-logs\__consumer_offsets-43 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-08-10 11:39:12,176] INFO Created log for partition __consumer_offsets-12 in C:\tmp\server-1\kraft-combined-logs\__consumer_offsets-12 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-08-10 11:39:12,176] INFO [Partition __consumer_offsets-43 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2025-08-10 11:39:12,178] INFO [Partition __consumer_offsets-12 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2025-08-10 11:39:12,178] INFO [Partition __consumer_offsets-43 broker=2] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:39:12,179] INFO [Partition __consumer_offsets-12 broker=1] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:39:12,186] INFO [LogLoader partition=__consumer_offsets-30, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:39:12,188] INFO Created log for partition __consumer_offsets-30 in C:\tmp\server-3\kraft-combined-logs\__consumer_offsets-30 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-08-10 11:39:12,188] INFO [Partition __consumer_offsets-30 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2025-08-10 11:39:12,189] INFO [Partition __consumer_offsets-30 broker=3] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:39:12,203] INFO [LogLoader partition=__consumer_offsets-9, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:39:12,206] INFO [LogLoader partition=__consumer_offsets-44, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:39:12,211] INFO Created log for partition __consumer_offsets-44 in C:\tmp\server-1\kraft-combined-logs\__consumer_offsets-44 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-08-10 11:39:12,211] INFO Created log for partition __consumer_offsets-9 in C:\tmp\server-2\kraft-combined-logs\__consumer_offsets-9 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-08-10 11:39:12,212] INFO [Partition __consumer_offsets-44 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2025-08-10 11:39:12,212] INFO [Partition __consumer_offsets-9 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2025-08-10 11:39:12,213] INFO [Partition __consumer_offsets-9 broker=2] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:39:12,213] INFO [Partition __consumer_offsets-44 broker=1] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:39:12,220] INFO [LogLoader partition=__consumer_offsets-28, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:39:12,223] INFO Created log for partition __consumer_offsets-28 in C:\tmp\server-3\kraft-combined-logs\__consumer_offsets-28 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-08-10 11:39:12,227] INFO [Partition __consumer_offsets-28 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2025-08-10 11:39:12,228] INFO [Partition __consumer_offsets-28 broker=3] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:39:12,236] INFO [LogLoader partition=__consumer_offsets-41, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:39:12,244] INFO Created log for partition __consumer_offsets-41 in C:\tmp\server-1\kraft-combined-logs\__consumer_offsets-41 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-08-10 11:39:12,244] INFO [LogLoader partition=__consumer_offsets-23, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:39:12,244] INFO [Partition __consumer_offsets-41 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2025-08-10 11:39:12,246] INFO [Partition __consumer_offsets-41 broker=1] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:39:12,246] INFO Created log for partition __consumer_offsets-23 in C:\tmp\server-2\kraft-combined-logs\__consumer_offsets-23 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-08-10 11:39:12,246] INFO [Partition __consumer_offsets-23 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2025-08-10 11:39:12,247] INFO [Partition __consumer_offsets-23 broker=2] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:39:12,254] INFO [LogLoader partition=__consumer_offsets-26, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:39:12,257] INFO Created log for partition __consumer_offsets-26 in C:\tmp\server-3\kraft-combined-logs\__consumer_offsets-26 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-08-10 11:39:12,257] INFO [Partition __consumer_offsets-26 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2025-08-10 11:39:12,257] INFO [Partition __consumer_offsets-26 broker=3] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:39:12,262] INFO [LogLoader partition=__consumer_offsets-10, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:39:12,264] INFO Created log for partition __consumer_offsets-10 in C:\tmp\server-1\kraft-combined-logs\__consumer_offsets-10 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-08-10 11:39:12,264] INFO [Partition __consumer_offsets-10 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2025-08-10 11:39:12,264] INFO [Partition __consumer_offsets-10 broker=1] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:39:12,266] INFO [LogLoader partition=__consumer_offsets-24, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:39:12,268] INFO Created log for partition __consumer_offsets-24 in C:\tmp\server-2\kraft-combined-logs\__consumer_offsets-24 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-08-10 11:39:12,270] INFO [Partition __consumer_offsets-24 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2025-08-10 11:39:12,271] INFO [Partition __consumer_offsets-24 broker=2] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:39:12,278] INFO [LogLoader partition=__consumer_offsets-39, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:39:12,280] INFO Created log for partition __consumer_offsets-39 in C:\tmp\server-3\kraft-combined-logs\__consumer_offsets-39 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-08-10 11:39:12,281] INFO [Partition __consumer_offsets-39 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2025-08-10 11:39:12,281] INFO [Partition __consumer_offsets-39 broker=3] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:39:12,284] INFO [LogLoader partition=__consumer_offsets-21, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:39:12,288] INFO Created log for partition __consumer_offsets-21 in C:\tmp\server-1\kraft-combined-logs\__consumer_offsets-21 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-08-10 11:39:12,289] INFO [Partition __consumer_offsets-21 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2025-08-10 11:39:12,289] INFO [Partition __consumer_offsets-21 broker=1] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:39:12,295] INFO [LogLoader partition=__consumer_offsets-19, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:39:12,297] INFO Created log for partition __consumer_offsets-19 in C:\tmp\server-2\kraft-combined-logs\__consumer_offsets-19 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-08-10 11:39:12,297] INFO [Partition __consumer_offsets-19 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2025-08-10 11:39:12,297] INFO [Partition __consumer_offsets-19 broker=2] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:39:12,299] INFO [LogLoader partition=__consumer_offsets-6, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:39:12,303] INFO Created log for partition __consumer_offsets-6 in C:\tmp\server-3\kraft-combined-logs\__consumer_offsets-6 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-08-10 11:39:12,304] INFO [Partition __consumer_offsets-6 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2025-08-10 11:39:12,304] INFO [Partition __consumer_offsets-6 broker=3] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:39:12,310] INFO [LogLoader partition=__consumer_offsets-18, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:39:12,312] INFO Created log for partition __consumer_offsets-18 in C:\tmp\server-1\kraft-combined-logs\__consumer_offsets-18 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-08-10 11:39:12,312] INFO [Partition __consumer_offsets-18 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2025-08-10 11:39:12,313] INFO [Partition __consumer_offsets-18 broker=1] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:39:12,315] INFO [LogLoader partition=__consumer_offsets-49, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:39:12,319] INFO Created log for partition __consumer_offsets-49 in C:\tmp\server-2\kraft-combined-logs\__consumer_offsets-49 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-08-10 11:39:12,320] INFO [Partition __consumer_offsets-49 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2025-08-10 11:39:12,320] INFO [Partition __consumer_offsets-49 broker=2] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:39:12,325] INFO [LogLoader partition=__consumer_offsets-3, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:39:12,328] INFO Created log for partition __consumer_offsets-3 in C:\tmp\server-3\kraft-combined-logs\__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-08-10 11:39:12,329] INFO [Partition __consumer_offsets-3 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2025-08-10 11:39:12,329] INFO [Partition __consumer_offsets-3 broker=3] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:39:12,343] INFO [LogLoader partition=__consumer_offsets-31, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:39:12,344] INFO [LogLoader partition=__consumer_offsets-32, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:39:12,345] INFO Created log for partition __consumer_offsets-31 in C:\tmp\server-1\kraft-combined-logs\__consumer_offsets-31 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-08-10 11:39:12,345] INFO [Partition __consumer_offsets-31 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2025-08-10 11:39:12,346] INFO Created log for partition __consumer_offsets-32 in C:\tmp\server-2\kraft-combined-logs\__consumer_offsets-32 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-08-10 11:39:12,347] INFO [Partition __consumer_offsets-31 broker=1] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:39:12,348] INFO [Partition __consumer_offsets-32 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2025-08-10 11:39:12,349] INFO [Partition __consumer_offsets-32 broker=2] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:39:12,352] INFO [LogLoader partition=__consumer_offsets-35, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:39:12,354] INFO Created log for partition __consumer_offsets-35 in C:\tmp\server-3\kraft-combined-logs\__consumer_offsets-35 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-08-10 11:39:12,354] INFO [Partition __consumer_offsets-35 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2025-08-10 11:39:12,355] INFO [Partition __consumer_offsets-35 broker=3] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:39:12,369] INFO [LogLoader partition=__consumer_offsets-0, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:39:12,369] INFO [LogLoader partition=__consumer_offsets-27, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:39:12,371] INFO Created log for partition __consumer_offsets-0 in C:\tmp\server-1\kraft-combined-logs\__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-08-10 11:39:12,371] INFO Created log for partition __consumer_offsets-27 in C:\tmp\server-2\kraft-combined-logs\__consumer_offsets-27 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-08-10 11:39:12,372] INFO [Partition __consumer_offsets-0 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2025-08-10 11:39:12,372] INFO [Partition __consumer_offsets-27 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2025-08-10 11:39:12,372] INFO [Partition __consumer_offsets-0 broker=1] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:39:12,372] INFO [Partition __consumer_offsets-27 broker=2] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:39:12,377] INFO [LogLoader partition=__consumer_offsets-36, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:39:12,380] INFO Created log for partition __consumer_offsets-36 in C:\tmp\server-3\kraft-combined-logs\__consumer_offsets-36 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-08-10 11:39:12,381] INFO [Partition __consumer_offsets-36 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2025-08-10 11:39:12,381] INFO [Partition __consumer_offsets-36 broker=3] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:39:12,390] INFO [LogLoader partition=__consumer_offsets-8, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:39:12,391] INFO [LogLoader partition=__consumer_offsets-29, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:39:12,392] INFO Created log for partition __consumer_offsets-8 in C:\tmp\server-2\kraft-combined-logs\__consumer_offsets-8 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-08-10 11:39:12,393] INFO [Partition __consumer_offsets-8 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2025-08-10 11:39:12,393] INFO [Partition __consumer_offsets-8 broker=2] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:39:12,394] INFO Created log for partition __consumer_offsets-29 in C:\tmp\server-1\kraft-combined-logs\__consumer_offsets-29 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-08-10 11:39:12,395] INFO [Partition __consumer_offsets-29 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2025-08-10 11:39:12,396] INFO [Partition __consumer_offsets-29 broker=1] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:39:12,401] INFO [LogLoader partition=__consumer_offsets-2, dir=C:\tmp\server-3\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:39:12,402] INFO Created log for partition __consumer_offsets-2 in C:\tmp\server-3\kraft-combined-logs\__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-08-10 11:39:12,403] INFO [Partition __consumer_offsets-2 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2025-08-10 11:39:12,403] INFO [Partition __consumer_offsets-2 broker=3] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:39:12,414] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 47 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:12,415] INFO [LogLoader partition=__consumer_offsets-40, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:39:12,415] INFO [LogLoader partition=__consumer_offsets-25, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:39:12,416] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,417] INFO Created log for partition __consumer_offsets-25 in C:\tmp\server-1\kraft-combined-logs\__consumer_offsets-25 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-08-10 11:39:12,420] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 14 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:12,419] INFO Created log for partition __consumer_offsets-40 in C:\tmp\server-2\kraft-combined-logs\__consumer_offsets-40 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-08-10 11:39:12,421] INFO [Partition __consumer_offsets-25 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2025-08-10 11:39:12,422] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,422] INFO [Partition __consumer_offsets-40 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2025-08-10 11:39:12,422] INFO [Partition __consumer_offsets-25 broker=1] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:39:12,423] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 11 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:12,423] INFO [Partition __consumer_offsets-40 broker=2] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:39:12,427] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,429] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 42 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:12,431] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,433] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 22 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:12,435] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,436] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 20 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:12,437] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,437] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 17 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:12,438] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,441] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 30 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:12,442] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,442] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-47 in 22 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,443] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 28 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:12,443] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,444] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 26 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:12,443] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-14 in 20 milliseconds for epoch 0, of which 20 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,444] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,445] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 39 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:12,445] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-11 in 16 milliseconds for epoch 0, of which 16 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,446] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-42 in 14 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,447] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,448] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-22 in 11 milliseconds for epoch 0, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,449] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-20 in 12 milliseconds for epoch 0, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,452] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-17 in 11 milliseconds for epoch 0, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,456] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-30 in 13 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,457] INFO [LogLoader partition=__consumer_offsets-7, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:39:12,455] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 6 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:12,458] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-28 in 14 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,460] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,458] INFO [LogLoader partition=__consumer_offsets-37, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:39:12,462] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-26 in 17 milliseconds for epoch 0, of which 17 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,462] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 3 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:12,464] INFO Created log for partition __consumer_offsets-37 in C:\tmp\server-2\kraft-combined-logs\__consumer_offsets-37 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-08-10 11:39:12,464] INFO Created log for partition __consumer_offsets-7 in C:\tmp\server-1\kraft-combined-logs\__consumer_offsets-7 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-08-10 11:39:12,464] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,465] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-39 in 16 milliseconds for epoch 0, of which 16 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,465] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 35 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:12,465] INFO [Partition __consumer_offsets-7 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2025-08-10 11:39:12,466] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-6 in 4 milliseconds for epoch 0, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,465] INFO [Partition __consumer_offsets-37 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2025-08-10 11:39:12,466] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,467] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 36 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:12,467] INFO [Partition __consumer_offsets-7 broker=1] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:39:12,467] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,467] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-3 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,467] INFO [Partition __consumer_offsets-37 broker=2] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:39:12,467] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 2 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:12,468] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,468] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-35 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,470] INFO [DynamicConfigPublisher broker id=3] Updating topic __consumer_offsets with new configuration : compression.type -> producer,cleanup.policy -> compact,segment.bytes -> 104857600 (kafka.server.metadata.DynamicConfigPublisher)
[2025-08-10 11:39:12,470] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-36 in 3 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,476] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-2 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,506] INFO [LogLoader partition=__consumer_offsets-5, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:39:12,508] INFO Created log for partition __consumer_offsets-5 in C:\tmp\server-1\kraft-combined-logs\__consumer_offsets-5 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-08-10 11:39:12,508] INFO [Partition __consumer_offsets-5 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2025-08-10 11:39:12,508] INFO [Partition __consumer_offsets-5 broker=1] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:39:12,509] INFO [LogLoader partition=__consumer_offsets-4, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:39:12,511] INFO Created log for partition __consumer_offsets-4 in C:\tmp\server-2\kraft-combined-logs\__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-08-10 11:39:12,511] INFO [Partition __consumer_offsets-4 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2025-08-10 11:39:12,512] INFO [Partition __consumer_offsets-4 broker=2] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:39:12,526] INFO [LogLoader partition=__consumer_offsets-38, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:39:12,528] INFO Created log for partition __consumer_offsets-38 in C:\tmp\server-1\kraft-combined-logs\__consumer_offsets-38 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-08-10 11:39:12,529] INFO [Partition __consumer_offsets-38 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2025-08-10 11:39:12,529] INFO [Partition __consumer_offsets-38 broker=1] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:39:12,529] INFO [LogLoader partition=__consumer_offsets-1, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:39:12,531] INFO Created log for partition __consumer_offsets-1 in C:\tmp\server-2\kraft-combined-logs\__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-08-10 11:39:12,531] INFO [Partition __consumer_offsets-1 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2025-08-10 11:39:12,531] INFO [Partition __consumer_offsets-1 broker=2] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:39:12,547] INFO [LogLoader partition=__consumer_offsets-33, dir=C:\tmp\server-1\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:39:12,551] INFO [LogLoader partition=__consumer_offsets-34, dir=C:\tmp\server-2\kraft-combined-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-08-10 11:39:12,552] INFO Created log for partition __consumer_offsets-33 in C:\tmp\server-1\kraft-combined-logs\__consumer_offsets-33 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-08-10 11:39:12,553] INFO [Partition __consumer_offsets-33 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2025-08-10 11:39:12,553] INFO [Partition __consumer_offsets-33 broker=1] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:39:12,553] INFO Created log for partition __consumer_offsets-34 in C:\tmp\server-2\kraft-combined-logs\__consumer_offsets-34 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-08-10 11:39:12,555] INFO [Partition __consumer_offsets-34 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2025-08-10 11:39:12,559] INFO [Partition __consumer_offsets-34 broker=2] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2025-08-10 11:39:12,568] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 16 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:12,570] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 15 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:12,570] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,571] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,572] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 48 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:12,572] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,573] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 45 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:12,573] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 13 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:12,573] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,573] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,574] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 12 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:12,574] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 46 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:12,574] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,574] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,574] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 44 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:12,574] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 43 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:12,574] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,574] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,574] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 9 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:12,574] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 41 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:12,574] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,575] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,575] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 23 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:12,575] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,575] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 10 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:12,575] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,575] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 24 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:12,575] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 21 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:12,575] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,575] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,577] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 19 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:12,577] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,577] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 18 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:12,577] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 49 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:12,577] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,577] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,577] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 32 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:12,577] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 31 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:12,578] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,578] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 27 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:12,578] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,578] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,578] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 0 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:12,579] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 8 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:12,579] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,580] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,580] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 40 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:12,580] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,580] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 29 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:12,580] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 37 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:12,581] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,581] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,581] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 25 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:12,581] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 4 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:12,582] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,582] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,582] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 7 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:12,583] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,583] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 1 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:12,584] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-16 in 12 milliseconds for epoch 0, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,584] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,584] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 5 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:12,585] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 34 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:12,586] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,586] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,585] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 12 milliseconds for epoch 0, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,587] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 38 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:12,588] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,588] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 14 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,589] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 15 milliseconds for epoch 0, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,588] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 33 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:12,590] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,590] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 16 milliseconds for epoch 0, of which 16 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,591] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 16 milliseconds for epoch 0, of which 16 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,591] INFO [DynamicConfigPublisher broker id=2] Updating topic __consumer_offsets with new configuration : compression.type -> producer,cleanup.policy -> compact,segment.bytes -> 104857600 (kafka.server.metadata.DynamicConfigPublisher)
[2025-08-10 11:39:12,592] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-10 in 17 milliseconds for epoch 0, of which 16 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,592] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 15 milliseconds for epoch 0, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,592] INFO [DynamicConfigPublisher broker id=1] Updating topic __consumer_offsets with new configuration : compression.type -> producer,cleanup.policy -> compact,segment.bytes -> 104857600 (kafka.server.metadata.DynamicConfigPublisher)
[2025-08-10 11:39:12,593] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-15 in 17 milliseconds for epoch 0, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,593] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 16 milliseconds for epoch 0, of which 16 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,596] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-31 in 18 milliseconds for epoch 0, of which 17 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,597] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 17 milliseconds for epoch 0, of which 16 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,598] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 17 milliseconds for epoch 0, of which 17 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,600] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-25 in 18 milliseconds for epoch 0, of which 17 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,595] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-13 in 21 milliseconds for epoch 0, of which 21 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,600] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-7 in 16 milliseconds for epoch 0, of which 16 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,601] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-46 in 27 milliseconds for epoch 0, of which 26 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,601] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 14 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,602] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 14 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,602] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-43 in 28 milliseconds for epoch 0, of which 28 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,603] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 13 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,604] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-9 in 29 milliseconds for epoch 0, of which 29 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,605] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-23 in 30 milliseconds for epoch 0, of which 30 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,605] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-24 in 30 milliseconds for epoch 0, of which 30 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,606] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-19 in 29 milliseconds for epoch 0, of which 29 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,606] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-49 in 29 milliseconds for epoch 0, of which 29 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,607] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-32 in 29 milliseconds for epoch 0, of which 29 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,608] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-27 in 28 milliseconds for epoch 0, of which 28 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,608] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-8 in 28 milliseconds for epoch 0, of which 28 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,608] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-40 in 28 milliseconds for epoch 0, of which 28 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,609] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-37 in 28 milliseconds for epoch 0, of which 28 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,610] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-4 in 27 milliseconds for epoch 0, of which 26 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,611] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-1 in 26 milliseconds for epoch 0, of which 26 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,611] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-34 in 24 milliseconds for epoch 0, of which 24 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-08-10 11:39:12,734] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group new-employee-created-event-1 in Empty state. Created a new member id consumer-new-employee-created-event-1-1-8704c3cf-5fe9-4d8a-afee-35e53b6ca0ee and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:12,756] INFO [GroupCoordinator 1]: Preparing to rebalance group new-employee-created-event-1 in state PreparingRebalance with old generation 0 (__consumer_offsets-25) (reason: Adding new member consumer-new-employee-created-event-1-1-8704c3cf-5fe9-4d8a-afee-35e53b6ca0ee with group instance id None; client reason: need to re-join with the given member-id: consumer-new-employee-created-event-1-1-8704c3cf-5fe9-4d8a-afee-35e53b6ca0ee) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:15,546] INFO [GroupCoordinator 3]: Dynamic member with unknown member id joins group new-employee-created-event-2 in Empty state. Created a new member id consumer-new-employee-created-event-2-1-02a341a3-6b92-4d4e-8732-047ada0c829c and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:15,558] INFO [GroupCoordinator 3]: Preparing to rebalance group new-employee-created-event-2 in state PreparingRebalance with old generation 0 (__consumer_offsets-26) (reason: Adding new member consumer-new-employee-created-event-2-1-02a341a3-6b92-4d4e-8732-047ada0c829c with group instance id None; client reason: need to re-join with the given member-id: consumer-new-employee-created-event-2-1-02a341a3-6b92-4d4e-8732-047ada0c829c) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:15,784] INFO [GroupCoordinator 1]: Stabilized group new-employee-created-event-1 generation 1 (__consumer_offsets-25) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:15,811] INFO [GroupCoordinator 1]: Assignment received from leader consumer-new-employee-created-event-1-1-8704c3cf-5fe9-4d8a-afee-35e53b6ca0ee for group new-employee-created-event-1 for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:17,593] INFO [GroupCoordinator 2]: Dynamic member with unknown member id joins group new-employee-created-event-3 in Empty state. Created a new member id consumer-new-employee-created-event-3-1-3e8c83c7-3d43-4ced-9135-c1128784ee3e and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:17,606] INFO [GroupCoordinator 2]: Preparing to rebalance group new-employee-created-event-3 in state PreparingRebalance with old generation 0 (__consumer_offsets-27) (reason: Adding new member consumer-new-employee-created-event-3-1-3e8c83c7-3d43-4ced-9135-c1128784ee3e with group instance id None; client reason: need to re-join with the given member-id: consumer-new-employee-created-event-3-1-3e8c83c7-3d43-4ced-9135-c1128784ee3e) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:18,570] INFO [GroupCoordinator 3]: Stabilized group new-employee-created-event-2 generation 1 (__consumer_offsets-26) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:18,587] INFO [GroupCoordinator 3]: Assignment received from leader consumer-new-employee-created-event-2-1-02a341a3-6b92-4d4e-8732-047ada0c829c for group new-employee-created-event-2 for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:20,615] INFO [GroupCoordinator 2]: Stabilized group new-employee-created-event-3 generation 1 (__consumer_offsets-27) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:39:20,631] INFO [GroupCoordinator 2]: Assignment received from leader consumer-new-employee-created-event-3-1-3e8c83c7-3d43-4ced-9135-c1128784ee3e for group new-employee-created-event-3 for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:48:18,951] INFO [RaftManager id=3] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:48:20,811] INFO [RaftManager id=3] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:48:51,255] INFO [BrokerToControllerChannelManager id=2 name=forwarding] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:49:12,097] INFO [BrokerToControllerChannelManager id=3 name=forwarding] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 11:52:49,866] INFO [GroupCoordinator 3]: Preparing to rebalance group new-employee-created-event-2 in state PreparingRebalance with old generation 1 (__consumer_offsets-26) (reason: Removing member consumer-new-employee-created-event-2-1-02a341a3-6b92-4d4e-8732-047ada0c829c on LeaveGroup; client reason: the consumer unsubscribed from all topics) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:52:49,867] INFO [GroupCoordinator 3]: Group new-employee-created-event-2 with generation 2 is now empty (__consumer_offsets-26) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:52:49,870] INFO [GroupCoordinator 3]: Member MemberMetadata(memberId=consumer-new-employee-created-event-2-1-02a341a3-6b92-4d4e-8732-047ada0c829c, groupInstanceId=None, clientId=consumer-new-employee-created-event-2-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group new-employee-created-event-2 through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:52:49,929] INFO [GroupCoordinator 1]: Preparing to rebalance group new-employee-created-event-1 in state PreparingRebalance with old generation 1 (__consumer_offsets-25) (reason: Removing member consumer-new-employee-created-event-1-1-8704c3cf-5fe9-4d8a-afee-35e53b6ca0ee on LeaveGroup; client reason: the consumer unsubscribed from all topics) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:52:49,932] INFO [GroupCoordinator 1]: Group new-employee-created-event-1 with generation 2 is now empty (__consumer_offsets-25) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:52:49,936] INFO [GroupCoordinator 1]: Member MemberMetadata(memberId=consumer-new-employee-created-event-1-1-8704c3cf-5fe9-4d8a-afee-35e53b6ca0ee, groupInstanceId=None, clientId=consumer-new-employee-created-event-1-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group new-employee-created-event-1 through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:52:50,515] INFO [GroupCoordinator 2]: Preparing to rebalance group new-employee-created-event-3 in state PreparingRebalance with old generation 1 (__consumer_offsets-27) (reason: Removing member consumer-new-employee-created-event-3-1-3e8c83c7-3d43-4ced-9135-c1128784ee3e on LeaveGroup; client reason: the consumer unsubscribed from all topics) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:52:50,516] INFO [GroupCoordinator 2]: Group new-employee-created-event-3 with generation 2 is now empty (__consumer_offsets-27) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:52:50,520] INFO [GroupCoordinator 2]: Member MemberMetadata(memberId=consumer-new-employee-created-event-3-1-3e8c83c7-3d43-4ced-9135-c1128784ee3e, groupInstanceId=None, clientId=consumer-new-employee-created-event-3-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group new-employee-created-event-3 through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:52:51,613] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group new-employee-created-event-1 in Empty state. Created a new member id consumer-new-employee-created-event-1-2-b53e68c1-bc83-4692-90fc-f0eccaf33bf2 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:52:51,617] INFO [GroupCoordinator 1]: Preparing to rebalance group new-employee-created-event-1 in state PreparingRebalance with old generation 2 (__consumer_offsets-25) (reason: Adding new member consumer-new-employee-created-event-1-2-b53e68c1-bc83-4692-90fc-f0eccaf33bf2 with group instance id None; client reason: need to re-join with the given member-id: consumer-new-employee-created-event-1-2-b53e68c1-bc83-4692-90fc-f0eccaf33bf2) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:52:51,671] INFO [GroupCoordinator 3]: Dynamic member with unknown member id joins group new-employee-created-event-2 in Empty state. Created a new member id consumer-new-employee-created-event-2-2-d1d67b01-1ec1-4136-8bf0-4e063a6c9fe4 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:52:51,675] INFO [GroupCoordinator 3]: Preparing to rebalance group new-employee-created-event-2 in state PreparingRebalance with old generation 2 (__consumer_offsets-26) (reason: Adding new member consumer-new-employee-created-event-2-2-d1d67b01-1ec1-4136-8bf0-4e063a6c9fe4 with group instance id None; client reason: need to re-join with the given member-id: consumer-new-employee-created-event-2-2-d1d67b01-1ec1-4136-8bf0-4e063a6c9fe4) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:52:52,306] INFO [GroupCoordinator 2]: Dynamic member with unknown member id joins group new-employee-created-event-3 in Empty state. Created a new member id consumer-new-employee-created-event-3-2-140604c5-4eb1-4fa4-b50f-4b7ea80eefb6 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:52:52,308] INFO [GroupCoordinator 2]: Preparing to rebalance group new-employee-created-event-3 in state PreparingRebalance with old generation 2 (__consumer_offsets-27) (reason: Adding new member consumer-new-employee-created-event-3-2-140604c5-4eb1-4fa4-b50f-4b7ea80eefb6 with group instance id None; client reason: need to re-join with the given member-id: consumer-new-employee-created-event-3-2-140604c5-4eb1-4fa4-b50f-4b7ea80eefb6) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:52:54,620] INFO [GroupCoordinator 1]: Stabilized group new-employee-created-event-1 generation 3 (__consumer_offsets-25) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:52:54,622] INFO [GroupCoordinator 1]: Assignment received from leader consumer-new-employee-created-event-1-2-b53e68c1-bc83-4692-90fc-f0eccaf33bf2 for group new-employee-created-event-1 for generation 3. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:52:54,681] INFO [GroupCoordinator 3]: Stabilized group new-employee-created-event-2 generation 3 (__consumer_offsets-26) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:52:54,683] INFO [GroupCoordinator 3]: Assignment received from leader consumer-new-employee-created-event-2-2-d1d67b01-1ec1-4136-8bf0-4e063a6c9fe4 for group new-employee-created-event-2 for generation 3. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:52:55,327] INFO [GroupCoordinator 2]: Stabilized group new-employee-created-event-3 generation 3 (__consumer_offsets-27) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:52:55,331] INFO [GroupCoordinator 2]: Assignment received from leader consumer-new-employee-created-event-3-2-140604c5-4eb1-4fa4-b50f-4b7ea80eefb6 for group new-employee-created-event-3 for generation 3. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:53:00,843] INFO [GroupCoordinator 2]: Preparing to rebalance group new-employee-created-event-3 in state PreparingRebalance with old generation 3 (__consumer_offsets-27) (reason: Removing member consumer-new-employee-created-event-3-2-140604c5-4eb1-4fa4-b50f-4b7ea80eefb6 on LeaveGroup; client reason: the consumer unsubscribed from all topics) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:53:00,843] INFO [GroupCoordinator 2]: Group new-employee-created-event-3 with generation 4 is now empty (__consumer_offsets-27) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:53:00,844] INFO [GroupCoordinator 2]: Member MemberMetadata(memberId=consumer-new-employee-created-event-3-2-140604c5-4eb1-4fa4-b50f-4b7ea80eefb6, groupInstanceId=None, clientId=consumer-new-employee-created-event-3-2, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group new-employee-created-event-3 through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:53:01,107] INFO [GroupCoordinator 1]: Preparing to rebalance group new-employee-created-event-1 in state PreparingRebalance with old generation 3 (__consumer_offsets-25) (reason: Removing member consumer-new-employee-created-event-1-2-b53e68c1-bc83-4692-90fc-f0eccaf33bf2 on LeaveGroup; client reason: the consumer unsubscribed from all topics) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:53:01,108] INFO [GroupCoordinator 1]: Group new-employee-created-event-1 with generation 4 is now empty (__consumer_offsets-25) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:53:01,109] INFO [GroupCoordinator 1]: Member MemberMetadata(memberId=consumer-new-employee-created-event-1-2-b53e68c1-bc83-4692-90fc-f0eccaf33bf2, groupInstanceId=None, clientId=consumer-new-employee-created-event-1-2, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group new-employee-created-event-1 through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:53:01,199] INFO [GroupCoordinator 3]: Preparing to rebalance group new-employee-created-event-2 in state PreparingRebalance with old generation 3 (__consumer_offsets-26) (reason: Removing member consumer-new-employee-created-event-2-2-d1d67b01-1ec1-4136-8bf0-4e063a6c9fe4 on LeaveGroup; client reason: the consumer unsubscribed from all topics) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:53:01,199] INFO [GroupCoordinator 3]: Group new-employee-created-event-2 with generation 4 is now empty (__consumer_offsets-26) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:53:01,200] INFO [GroupCoordinator 3]: Member MemberMetadata(memberId=consumer-new-employee-created-event-2-2-d1d67b01-1ec1-4136-8bf0-4e063a6c9fe4, groupInstanceId=None, clientId=consumer-new-employee-created-event-2-2, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group new-employee-created-event-2 through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:53:01,787] INFO [GroupCoordinator 2]: Dynamic member with unknown member id joins group new-employee-created-event-3 in Empty state. Created a new member id consumer-new-employee-created-event-3-3-73c8768b-183d-4284-a212-d2e312cb5316 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:53:01,789] INFO [GroupCoordinator 2]: Preparing to rebalance group new-employee-created-event-3 in state PreparingRebalance with old generation 4 (__consumer_offsets-27) (reason: Adding new member consumer-new-employee-created-event-3-3-73c8768b-183d-4284-a212-d2e312cb5316 with group instance id None; client reason: need to re-join with the given member-id: consumer-new-employee-created-event-3-3-73c8768b-183d-4284-a212-d2e312cb5316) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:53:02,173] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group new-employee-created-event-1 in Empty state. Created a new member id consumer-new-employee-created-event-1-3-531c95cc-a2a0-41e1-98e1-f72a3706aa26 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:53:02,174] INFO [GroupCoordinator 1]: Preparing to rebalance group new-employee-created-event-1 in state PreparingRebalance with old generation 4 (__consumer_offsets-25) (reason: Adding new member consumer-new-employee-created-event-1-3-531c95cc-a2a0-41e1-98e1-f72a3706aa26 with group instance id None; client reason: need to re-join with the given member-id: consumer-new-employee-created-event-1-3-531c95cc-a2a0-41e1-98e1-f72a3706aa26) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:53:02,227] INFO [GroupCoordinator 3]: Dynamic member with unknown member id joins group new-employee-created-event-2 in Empty state. Created a new member id consumer-new-employee-created-event-2-3-cc30f885-c01b-41f3-831d-5c376c1b0350 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:53:02,229] INFO [GroupCoordinator 3]: Preparing to rebalance group new-employee-created-event-2 in state PreparingRebalance with old generation 4 (__consumer_offsets-26) (reason: Adding new member consumer-new-employee-created-event-2-3-cc30f885-c01b-41f3-831d-5c376c1b0350 with group instance id None; client reason: need to re-join with the given member-id: consumer-new-employee-created-event-2-3-cc30f885-c01b-41f3-831d-5c376c1b0350) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:53:04,801] INFO [GroupCoordinator 2]: Stabilized group new-employee-created-event-3 generation 5 (__consumer_offsets-27) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:53:04,803] INFO [GroupCoordinator 2]: Assignment received from leader consumer-new-employee-created-event-3-3-73c8768b-183d-4284-a212-d2e312cb5316 for group new-employee-created-event-3 for generation 5. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:53:05,190] INFO [GroupCoordinator 1]: Stabilized group new-employee-created-event-1 generation 5 (__consumer_offsets-25) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:53:05,192] INFO [GroupCoordinator 1]: Assignment received from leader consumer-new-employee-created-event-1-3-531c95cc-a2a0-41e1-98e1-f72a3706aa26 for group new-employee-created-event-1 for generation 5. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:53:05,237] INFO [GroupCoordinator 3]: Stabilized group new-employee-created-event-2 generation 5 (__consumer_offsets-26) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:53:05,240] INFO [GroupCoordinator 3]: Assignment received from leader consumer-new-employee-created-event-2-3-cc30f885-c01b-41f3-831d-5c376c1b0350 for group new-employee-created-event-2 for generation 5. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:56:19,090] INFO [GroupCoordinator 2]: Preparing to rebalance group new-employee-created-event-3 in state PreparingRebalance with old generation 5 (__consumer_offsets-27) (reason: Removing member consumer-new-employee-created-event-3-3-73c8768b-183d-4284-a212-d2e312cb5316 on LeaveGroup; client reason: the consumer unsubscribed from all topics) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:56:19,090] INFO [GroupCoordinator 2]: Group new-employee-created-event-3 with generation 6 is now empty (__consumer_offsets-27) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:56:19,091] INFO [GroupCoordinator 2]: Member MemberMetadata(memberId=consumer-new-employee-created-event-3-3-73c8768b-183d-4284-a212-d2e312cb5316, groupInstanceId=None, clientId=consumer-new-employee-created-event-3-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group new-employee-created-event-3 through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:56:19,275] INFO [GroupCoordinator 1]: Preparing to rebalance group new-employee-created-event-1 in state PreparingRebalance with old generation 5 (__consumer_offsets-25) (reason: Removing member consumer-new-employee-created-event-1-3-531c95cc-a2a0-41e1-98e1-f72a3706aa26 on LeaveGroup; client reason: the consumer unsubscribed from all topics) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:56:19,275] INFO [GroupCoordinator 1]: Group new-employee-created-event-1 with generation 6 is now empty (__consumer_offsets-25) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:56:19,276] INFO [GroupCoordinator 1]: Member MemberMetadata(memberId=consumer-new-employee-created-event-1-3-531c95cc-a2a0-41e1-98e1-f72a3706aa26, groupInstanceId=None, clientId=consumer-new-employee-created-event-1-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group new-employee-created-event-1 through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:56:19,524] INFO [GroupCoordinator 3]: Preparing to rebalance group new-employee-created-event-2 in state PreparingRebalance with old generation 5 (__consumer_offsets-26) (reason: Removing member consumer-new-employee-created-event-2-3-cc30f885-c01b-41f3-831d-5c376c1b0350 on LeaveGroup; client reason: the consumer unsubscribed from all topics) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:56:19,525] INFO [GroupCoordinator 3]: Group new-employee-created-event-2 with generation 6 is now empty (__consumer_offsets-26) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:56:19,526] INFO [GroupCoordinator 3]: Member MemberMetadata(memberId=consumer-new-employee-created-event-2-3-cc30f885-c01b-41f3-831d-5c376c1b0350, groupInstanceId=None, clientId=consumer-new-employee-created-event-2-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group new-employee-created-event-2 through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:56:20,152] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group new-employee-created-event-1 in Empty state. Created a new member id consumer-new-employee-created-event-1-4-e75c9f76-8b6a-498f-824c-5217bd11a03e and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:56:20,154] INFO [GroupCoordinator 1]: Preparing to rebalance group new-employee-created-event-1 in state PreparingRebalance with old generation 6 (__consumer_offsets-25) (reason: Adding new member consumer-new-employee-created-event-1-4-e75c9f76-8b6a-498f-824c-5217bd11a03e with group instance id None; client reason: need to re-join with the given member-id: consumer-new-employee-created-event-1-4-e75c9f76-8b6a-498f-824c-5217bd11a03e) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:56:20,261] INFO [GroupCoordinator 2]: Dynamic member with unknown member id joins group new-employee-created-event-3 in Empty state. Created a new member id consumer-new-employee-created-event-3-4-f71cfe0a-d587-45a2-9281-5ef81d38e9bb and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:56:20,263] INFO [GroupCoordinator 2]: Preparing to rebalance group new-employee-created-event-3 in state PreparingRebalance with old generation 6 (__consumer_offsets-27) (reason: Adding new member consumer-new-employee-created-event-3-4-f71cfe0a-d587-45a2-9281-5ef81d38e9bb with group instance id None; client reason: need to re-join with the given member-id: consumer-new-employee-created-event-3-4-f71cfe0a-d587-45a2-9281-5ef81d38e9bb) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:56:20,661] INFO [GroupCoordinator 3]: Dynamic member with unknown member id joins group new-employee-created-event-2 in Empty state. Created a new member id consumer-new-employee-created-event-2-4-521acfaa-8b26-47fc-a0ed-6fe7c14cf246 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:56:20,664] INFO [GroupCoordinator 3]: Preparing to rebalance group new-employee-created-event-2 in state PreparingRebalance with old generation 6 (__consumer_offsets-26) (reason: Adding new member consumer-new-employee-created-event-2-4-521acfaa-8b26-47fc-a0ed-6fe7c14cf246 with group instance id None; client reason: need to re-join with the given member-id: consumer-new-employee-created-event-2-4-521acfaa-8b26-47fc-a0ed-6fe7c14cf246) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:56:23,162] INFO [GroupCoordinator 1]: Stabilized group new-employee-created-event-1 generation 7 (__consumer_offsets-25) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:56:23,165] INFO [GroupCoordinator 1]: Assignment received from leader consumer-new-employee-created-event-1-4-e75c9f76-8b6a-498f-824c-5217bd11a03e for group new-employee-created-event-1 for generation 7. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:56:23,271] INFO [GroupCoordinator 2]: Stabilized group new-employee-created-event-3 generation 7 (__consumer_offsets-27) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:56:23,273] INFO [GroupCoordinator 2]: Assignment received from leader consumer-new-employee-created-event-3-4-f71cfe0a-d587-45a2-9281-5ef81d38e9bb for group new-employee-created-event-3 for generation 7. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:56:23,671] INFO [GroupCoordinator 3]: Stabilized group new-employee-created-event-2 generation 7 (__consumer_offsets-26) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:56:23,674] INFO [GroupCoordinator 3]: Assignment received from leader consumer-new-employee-created-event-2-4-521acfaa-8b26-47fc-a0ed-6fe7c14cf246 for group new-employee-created-event-2 for generation 7. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:59:55,726] INFO [GroupCoordinator 2]: Preparing to rebalance group new-employee-created-event-3 in state PreparingRebalance with old generation 7 (__consumer_offsets-27) (reason: Removing member consumer-new-employee-created-event-3-4-f71cfe0a-d587-45a2-9281-5ef81d38e9bb on LeaveGroup; client reason: the consumer unsubscribed from all topics) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:59:55,727] INFO [GroupCoordinator 2]: Group new-employee-created-event-3 with generation 8 is now empty (__consumer_offsets-27) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:59:55,728] INFO [GroupCoordinator 2]: Member MemberMetadata(memberId=consumer-new-employee-created-event-3-4-f71cfe0a-d587-45a2-9281-5ef81d38e9bb, groupInstanceId=None, clientId=consumer-new-employee-created-event-3-4, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group new-employee-created-event-3 through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:59:55,741] INFO [GroupCoordinator 1]: Preparing to rebalance group new-employee-created-event-1 in state PreparingRebalance with old generation 7 (__consumer_offsets-25) (reason: Removing member consumer-new-employee-created-event-1-4-e75c9f76-8b6a-498f-824c-5217bd11a03e on LeaveGroup; client reason: the consumer unsubscribed from all topics) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:59:55,741] INFO [GroupCoordinator 1]: Group new-employee-created-event-1 with generation 8 is now empty (__consumer_offsets-25) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:59:55,743] INFO [GroupCoordinator 1]: Member MemberMetadata(memberId=consumer-new-employee-created-event-1-4-e75c9f76-8b6a-498f-824c-5217bd11a03e, groupInstanceId=None, clientId=consumer-new-employee-created-event-1-4, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group new-employee-created-event-1 through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:59:55,899] INFO [GroupCoordinator 3]: Preparing to rebalance group new-employee-created-event-2 in state PreparingRebalance with old generation 7 (__consumer_offsets-26) (reason: Removing member consumer-new-employee-created-event-2-4-521acfaa-8b26-47fc-a0ed-6fe7c14cf246 on LeaveGroup; client reason: the consumer unsubscribed from all topics) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:59:55,899] INFO [GroupCoordinator 3]: Group new-employee-created-event-2 with generation 8 is now empty (__consumer_offsets-26) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:59:55,900] INFO [GroupCoordinator 3]: Member MemberMetadata(memberId=consumer-new-employee-created-event-2-4-521acfaa-8b26-47fc-a0ed-6fe7c14cf246, groupInstanceId=None, clientId=consumer-new-employee-created-event-2-4, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group new-employee-created-event-2 through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:59:56,792] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group new-employee-created-event-1 in Empty state. Created a new member id consumer-new-employee-created-event-1-5-4e5178be-7a2a-4f90-9e17-7f3e2e29e947 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:59:56,795] INFO [GroupCoordinator 1]: Preparing to rebalance group new-employee-created-event-1 in state PreparingRebalance with old generation 8 (__consumer_offsets-25) (reason: Adding new member consumer-new-employee-created-event-1-5-4e5178be-7a2a-4f90-9e17-7f3e2e29e947 with group instance id None; client reason: need to re-join with the given member-id: consumer-new-employee-created-event-1-5-4e5178be-7a2a-4f90-9e17-7f3e2e29e947) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:59:56,945] INFO [GroupCoordinator 2]: Dynamic member with unknown member id joins group new-employee-created-event-3 in Empty state. Created a new member id consumer-new-employee-created-event-3-5-f1edeedc-1567-44e1-9c91-6105e98a5b58 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:59:56,948] INFO [GroupCoordinator 2]: Preparing to rebalance group new-employee-created-event-3 in state PreparingRebalance with old generation 8 (__consumer_offsets-27) (reason: Adding new member consumer-new-employee-created-event-3-5-f1edeedc-1567-44e1-9c91-6105e98a5b58 with group instance id None; client reason: need to re-join with the given member-id: consumer-new-employee-created-event-3-5-f1edeedc-1567-44e1-9c91-6105e98a5b58) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:59:57,457] INFO [GroupCoordinator 3]: Dynamic member with unknown member id joins group new-employee-created-event-2 in Empty state. Created a new member id consumer-new-employee-created-event-2-5-b6396d80-aba5-445d-bd43-21765c43b602 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:59:57,460] INFO [GroupCoordinator 3]: Preparing to rebalance group new-employee-created-event-2 in state PreparingRebalance with old generation 8 (__consumer_offsets-26) (reason: Adding new member consumer-new-employee-created-event-2-5-b6396d80-aba5-445d-bd43-21765c43b602 with group instance id None; client reason: need to re-join with the given member-id: consumer-new-employee-created-event-2-5-b6396d80-aba5-445d-bd43-21765c43b602) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:59:59,800] INFO [GroupCoordinator 1]: Stabilized group new-employee-created-event-1 generation 9 (__consumer_offsets-25) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:59:59,802] INFO [GroupCoordinator 1]: Preparing to rebalance group new-employee-created-event-1 in state PreparingRebalance with old generation 9 (__consumer_offsets-25) (reason: Removing member consumer-new-employee-created-event-1-5-4e5178be-7a2a-4f90-9e17-7f3e2e29e947 on LeaveGroup; client reason: the consumer unsubscribed from all topics) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:59:59,802] INFO [GroupCoordinator 1]: Group new-employee-created-event-1 with generation 10 is now empty (__consumer_offsets-25) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:59:59,803] INFO [GroupCoordinator 1]: Member MemberMetadata(memberId=consumer-new-employee-created-event-1-5-4e5178be-7a2a-4f90-9e17-7f3e2e29e947, groupInstanceId=None, clientId=consumer-new-employee-created-event-1-5, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group new-employee-created-event-1 through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:59:59,955] INFO [GroupCoordinator 2]: Stabilized group new-employee-created-event-3 generation 9 (__consumer_offsets-27) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:59:59,957] INFO [GroupCoordinator 2]: Preparing to rebalance group new-employee-created-event-3 in state PreparingRebalance with old generation 9 (__consumer_offsets-27) (reason: Removing member consumer-new-employee-created-event-3-5-f1edeedc-1567-44e1-9c91-6105e98a5b58 on LeaveGroup; client reason: the consumer unsubscribed from all topics) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:59:59,958] INFO [GroupCoordinator 2]: Group new-employee-created-event-3 with generation 10 is now empty (__consumer_offsets-27) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 11:59:59,959] INFO [GroupCoordinator 2]: Member MemberMetadata(memberId=consumer-new-employee-created-event-3-5-f1edeedc-1567-44e1-9c91-6105e98a5b58, groupInstanceId=None, clientId=consumer-new-employee-created-event-3-5, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group new-employee-created-event-3 through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:00:00,467] INFO [GroupCoordinator 3]: Stabilized group new-employee-created-event-2 generation 9 (__consumer_offsets-26) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:00:00,476] INFO [GroupCoordinator 3]: Preparing to rebalance group new-employee-created-event-2 in state PreparingRebalance with old generation 9 (__consumer_offsets-26) (reason: Removing member consumer-new-employee-created-event-2-5-b6396d80-aba5-445d-bd43-21765c43b602 on LeaveGroup; client reason: the consumer unsubscribed from all topics) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:00:00,476] INFO [GroupCoordinator 3]: Group new-employee-created-event-2 with generation 10 is now empty (__consumer_offsets-26) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:00:00,477] INFO [GroupCoordinator 3]: Member MemberMetadata(memberId=consumer-new-employee-created-event-2-5-b6396d80-aba5-445d-bd43-21765c43b602, groupInstanceId=None, clientId=consumer-new-employee-created-event-2-5, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group new-employee-created-event-2 through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:00:00,563] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group new-employee-created-event-1 in Empty state. Created a new member id consumer-new-employee-created-event-1-6-3f423feb-885d-4b1b-b201-b90809bca376 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:00:00,573] INFO [GroupCoordinator 1]: Preparing to rebalance group new-employee-created-event-1 in state PreparingRebalance with old generation 10 (__consumer_offsets-25) (reason: Adding new member consumer-new-employee-created-event-1-6-3f423feb-885d-4b1b-b201-b90809bca376 with group instance id None; client reason: need to re-join with the given member-id: consumer-new-employee-created-event-1-6-3f423feb-885d-4b1b-b201-b90809bca376) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:00:00,726] INFO [GroupCoordinator 2]: Dynamic member with unknown member id joins group new-employee-created-event-3 in Empty state. Created a new member id consumer-new-employee-created-event-3-6-1c980787-b84a-416e-87f7-3da78f7a4a96 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:00:00,732] INFO [GroupCoordinator 2]: Preparing to rebalance group new-employee-created-event-3 in state PreparingRebalance with old generation 10 (__consumer_offsets-27) (reason: Adding new member consumer-new-employee-created-event-3-6-1c980787-b84a-416e-87f7-3da78f7a4a96 with group instance id None; client reason: need to re-join with the given member-id: consumer-new-employee-created-event-3-6-1c980787-b84a-416e-87f7-3da78f7a4a96) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:00:01,166] INFO [GroupCoordinator 3]: Dynamic member with unknown member id joins group new-employee-created-event-2 in Empty state. Created a new member id consumer-new-employee-created-event-2-6-da9a5c94-cce1-422b-b805-0bb2d27154b9 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:00:01,168] INFO [GroupCoordinator 3]: Preparing to rebalance group new-employee-created-event-2 in state PreparingRebalance with old generation 10 (__consumer_offsets-26) (reason: Adding new member consumer-new-employee-created-event-2-6-da9a5c94-cce1-422b-b805-0bb2d27154b9 with group instance id None; client reason: need to re-join with the given member-id: consumer-new-employee-created-event-2-6-da9a5c94-cce1-422b-b805-0bb2d27154b9) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:00:03,575] INFO [GroupCoordinator 1]: Stabilized group new-employee-created-event-1 generation 11 (__consumer_offsets-25) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:00:03,575] INFO [GroupCoordinator 1]: Assignment received from leader consumer-new-employee-created-event-1-6-3f423feb-885d-4b1b-b201-b90809bca376 for group new-employee-created-event-1 for generation 11. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:00:03,733] INFO [GroupCoordinator 2]: Stabilized group new-employee-created-event-3 generation 11 (__consumer_offsets-27) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:00:03,733] INFO [GroupCoordinator 2]: Assignment received from leader consumer-new-employee-created-event-3-6-1c980787-b84a-416e-87f7-3da78f7a4a96 for group new-employee-created-event-3 for generation 11. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:00:04,178] INFO [GroupCoordinator 3]: Stabilized group new-employee-created-event-2 generation 11 (__consumer_offsets-26) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:00:04,178] INFO [GroupCoordinator 3]: Assignment received from leader consumer-new-employee-created-event-2-6-da9a5c94-cce1-422b-b805-0bb2d27154b9 for group new-employee-created-event-2 for generation 11. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:00:15,634] INFO [GroupCoordinator 1]: Preparing to rebalance group new-employee-created-event-1 in state PreparingRebalance with old generation 11 (__consumer_offsets-25) (reason: Removing member consumer-new-employee-created-event-1-6-3f423feb-885d-4b1b-b201-b90809bca376 on LeaveGroup; client reason: the consumer unsubscribed from all topics) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:00:15,634] INFO [GroupCoordinator 1]: Group new-employee-created-event-1 with generation 12 is now empty (__consumer_offsets-25) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:00:15,635] INFO [GroupCoordinator 1]: Member MemberMetadata(memberId=consumer-new-employee-created-event-1-6-3f423feb-885d-4b1b-b201-b90809bca376, groupInstanceId=None, clientId=consumer-new-employee-created-event-1-6, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group new-employee-created-event-1 through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:00:15,805] INFO [GroupCoordinator 3]: Preparing to rebalance group new-employee-created-event-2 in state PreparingRebalance with old generation 11 (__consumer_offsets-26) (reason: Removing member consumer-new-employee-created-event-2-6-da9a5c94-cce1-422b-b805-0bb2d27154b9 on LeaveGroup; client reason: the consumer unsubscribed from all topics) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:00:15,806] INFO [GroupCoordinator 2]: Preparing to rebalance group new-employee-created-event-3 in state PreparingRebalance with old generation 11 (__consumer_offsets-27) (reason: Removing member consumer-new-employee-created-event-3-6-1c980787-b84a-416e-87f7-3da78f7a4a96 on LeaveGroup; client reason: the consumer unsubscribed from all topics) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:00:15,806] INFO [GroupCoordinator 3]: Group new-employee-created-event-2 with generation 12 is now empty (__consumer_offsets-26) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:00:15,806] INFO [GroupCoordinator 2]: Group new-employee-created-event-3 with generation 12 is now empty (__consumer_offsets-27) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:00:15,807] INFO [GroupCoordinator 2]: Member MemberMetadata(memberId=consumer-new-employee-created-event-3-6-1c980787-b84a-416e-87f7-3da78f7a4a96, groupInstanceId=None, clientId=consumer-new-employee-created-event-3-6, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group new-employee-created-event-3 through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:00:15,807] INFO [GroupCoordinator 3]: Member MemberMetadata(memberId=consumer-new-employee-created-event-2-6-da9a5c94-cce1-422b-b805-0bb2d27154b9, groupInstanceId=None, clientId=consumer-new-employee-created-event-2-6, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group new-employee-created-event-2 through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:00:16,206] INFO [BrokerToControllerChannelManager id=1 name=forwarding] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 12:00:16,440] INFO [BrokerToControllerChannelManager id=2 name=forwarding] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 12:00:16,647] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group new-employee-created-event-1 in Empty state. Created a new member id consumer-new-employee-created-event-1-7-f868b4d4-ea57-44c2-a261-3d73dbf1ea92 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:00:16,649] INFO [GroupCoordinator 1]: Preparing to rebalance group new-employee-created-event-1 in state PreparingRebalance with old generation 12 (__consumer_offsets-25) (reason: Adding new member consumer-new-employee-created-event-1-7-f868b4d4-ea57-44c2-a261-3d73dbf1ea92 with group instance id None; client reason: need to re-join with the given member-id: consumer-new-employee-created-event-1-7-f868b4d4-ea57-44c2-a261-3d73dbf1ea92) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:00:16,763] INFO [GroupCoordinator 3]: Dynamic member with unknown member id joins group new-employee-created-event-2 in Empty state. Created a new member id consumer-new-employee-created-event-2-7-83badf49-49af-4050-a001-f76c4117d306 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:00:16,766] INFO [GroupCoordinator 3]: Preparing to rebalance group new-employee-created-event-2 in state PreparingRebalance with old generation 12 (__consumer_offsets-26) (reason: Adding new member consumer-new-employee-created-event-2-7-83badf49-49af-4050-a001-f76c4117d306 with group instance id None; client reason: need to re-join with the given member-id: consumer-new-employee-created-event-2-7-83badf49-49af-4050-a001-f76c4117d306) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:00:16,830] INFO [GroupCoordinator 2]: Dynamic member with unknown member id joins group new-employee-created-event-3 in Empty state. Created a new member id consumer-new-employee-created-event-3-7-7d65bc79-0b77-4f2b-81d2-f69ae81f08dd and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:00:16,832] INFO [GroupCoordinator 2]: Preparing to rebalance group new-employee-created-event-3 in state PreparingRebalance with old generation 12 (__consumer_offsets-27) (reason: Adding new member consumer-new-employee-created-event-3-7-7d65bc79-0b77-4f2b-81d2-f69ae81f08dd with group instance id None; client reason: need to re-join with the given member-id: consumer-new-employee-created-event-3-7-7d65bc79-0b77-4f2b-81d2-f69ae81f08dd) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:00:19,653] INFO [GroupCoordinator 1]: Stabilized group new-employee-created-event-1 generation 13 (__consumer_offsets-25) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:00:19,656] INFO [GroupCoordinator 1]: Assignment received from leader consumer-new-employee-created-event-1-7-f868b4d4-ea57-44c2-a261-3d73dbf1ea92 for group new-employee-created-event-1 for generation 13. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:00:19,777] INFO [GroupCoordinator 3]: Stabilized group new-employee-created-event-2 generation 13 (__consumer_offsets-26) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:00:19,779] INFO [GroupCoordinator 3]: Assignment received from leader consumer-new-employee-created-event-2-7-83badf49-49af-4050-a001-f76c4117d306 for group new-employee-created-event-2 for generation 13. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:00:19,838] INFO [GroupCoordinator 2]: Stabilized group new-employee-created-event-3 generation 13 (__consumer_offsets-27) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:00:19,840] INFO [GroupCoordinator 2]: Assignment received from leader consumer-new-employee-created-event-3-7-7d65bc79-0b77-4f2b-81d2-f69ae81f08dd for group new-employee-created-event-3 for generation 13. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:06,884] INFO [GroupCoordinator 1]: Preparing to rebalance group new-employee-created-event-1 in state PreparingRebalance with old generation 13 (__consumer_offsets-25) (reason: Removing member consumer-new-employee-created-event-1-7-f868b4d4-ea57-44c2-a261-3d73dbf1ea92 on LeaveGroup; client reason: the consumer unsubscribed from all topics) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:06,885] INFO [GroupCoordinator 1]: Group new-employee-created-event-1 with generation 14 is now empty (__consumer_offsets-25) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:06,886] INFO [GroupCoordinator 1]: Member MemberMetadata(memberId=consumer-new-employee-created-event-1-7-f868b4d4-ea57-44c2-a261-3d73dbf1ea92, groupInstanceId=None, clientId=consumer-new-employee-created-event-1-7, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group new-employee-created-event-1 through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:06,980] INFO [GroupCoordinator 3]: Preparing to rebalance group new-employee-created-event-2 in state PreparingRebalance with old generation 13 (__consumer_offsets-26) (reason: Removing member consumer-new-employee-created-event-2-7-83badf49-49af-4050-a001-f76c4117d306 on LeaveGroup; client reason: the consumer unsubscribed from all topics) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:06,980] INFO [GroupCoordinator 3]: Group new-employee-created-event-2 with generation 14 is now empty (__consumer_offsets-26) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:06,981] INFO [GroupCoordinator 3]: Member MemberMetadata(memberId=consumer-new-employee-created-event-2-7-83badf49-49af-4050-a001-f76c4117d306, groupInstanceId=None, clientId=consumer-new-employee-created-event-2-7, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group new-employee-created-event-2 through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:07,058] INFO [GroupCoordinator 2]: Preparing to rebalance group new-employee-created-event-3 in state PreparingRebalance with old generation 13 (__consumer_offsets-27) (reason: Removing member consumer-new-employee-created-event-3-7-7d65bc79-0b77-4f2b-81d2-f69ae81f08dd on LeaveGroup; client reason: the consumer unsubscribed from all topics) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:07,058] INFO [GroupCoordinator 2]: Group new-employee-created-event-3 with generation 14 is now empty (__consumer_offsets-27) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:07,060] INFO [GroupCoordinator 2]: Member MemberMetadata(memberId=consumer-new-employee-created-event-3-7-7d65bc79-0b77-4f2b-81d2-f69ae81f08dd, groupInstanceId=None, clientId=consumer-new-employee-created-event-3-7, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group new-employee-created-event-3 through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:07,819] INFO [GroupCoordinator 3]: Dynamic member with unknown member id joins group new-employee-created-event-2 in Empty state. Created a new member id consumer-new-employee-created-event-2-8-c7434559-1a63-4cb3-b653-7419ce08dd99 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:07,821] INFO [GroupCoordinator 3]: Preparing to rebalance group new-employee-created-event-2 in state PreparingRebalance with old generation 14 (__consumer_offsets-26) (reason: Adding new member consumer-new-employee-created-event-2-8-c7434559-1a63-4cb3-b653-7419ce08dd99 with group instance id None; client reason: need to re-join with the given member-id: consumer-new-employee-created-event-2-8-c7434559-1a63-4cb3-b653-7419ce08dd99) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:08,227] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group new-employee-created-event-1 in Empty state. Created a new member id consumer-new-employee-created-event-1-8-483bfae1-d350-4044-9eb8-45900657f1d1 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:08,229] INFO [GroupCoordinator 1]: Preparing to rebalance group new-employee-created-event-1 in state PreparingRebalance with old generation 14 (__consumer_offsets-25) (reason: Adding new member consumer-new-employee-created-event-1-8-483bfae1-d350-4044-9eb8-45900657f1d1 with group instance id None; client reason: need to re-join with the given member-id: consumer-new-employee-created-event-1-8-483bfae1-d350-4044-9eb8-45900657f1d1) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:08,358] INFO [GroupCoordinator 2]: Dynamic member with unknown member id joins group new-employee-created-event-3 in Empty state. Created a new member id consumer-new-employee-created-event-3-8-5b3a633d-8277-47fd-9345-64a701ac8e32 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:08,360] INFO [GroupCoordinator 2]: Preparing to rebalance group new-employee-created-event-3 in state PreparingRebalance with old generation 14 (__consumer_offsets-27) (reason: Adding new member consumer-new-employee-created-event-3-8-5b3a633d-8277-47fd-9345-64a701ac8e32 with group instance id None; client reason: need to re-join with the given member-id: consumer-new-employee-created-event-3-8-5b3a633d-8277-47fd-9345-64a701ac8e32) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:10,828] INFO [GroupCoordinator 3]: Stabilized group new-employee-created-event-2 generation 15 (__consumer_offsets-26) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:10,831] INFO [GroupCoordinator 3]: Assignment received from leader consumer-new-employee-created-event-2-8-c7434559-1a63-4cb3-b653-7419ce08dd99 for group new-employee-created-event-2 for generation 15. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:11,231] INFO [GroupCoordinator 1]: Stabilized group new-employee-created-event-1 generation 15 (__consumer_offsets-25) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:11,233] INFO [GroupCoordinator 1]: Assignment received from leader consumer-new-employee-created-event-1-8-483bfae1-d350-4044-9eb8-45900657f1d1 for group new-employee-created-event-1 for generation 15. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:11,370] INFO [GroupCoordinator 2]: Stabilized group new-employee-created-event-3 generation 15 (__consumer_offsets-27) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:11,374] INFO [GroupCoordinator 2]: Assignment received from leader consumer-new-employee-created-event-3-8-5b3a633d-8277-47fd-9345-64a701ac8e32 for group new-employee-created-event-3 for generation 15. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:15,737] INFO [GroupCoordinator 1]: Preparing to rebalance group new-employee-created-event-1 in state PreparingRebalance with old generation 15 (__consumer_offsets-25) (reason: Removing member consumer-new-employee-created-event-1-8-483bfae1-d350-4044-9eb8-45900657f1d1 on LeaveGroup; client reason: the consumer unsubscribed from all topics) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:15,737] INFO [GroupCoordinator 1]: Group new-employee-created-event-1 with generation 16 is now empty (__consumer_offsets-25) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:15,738] INFO [GroupCoordinator 1]: Member MemberMetadata(memberId=consumer-new-employee-created-event-1-8-483bfae1-d350-4044-9eb8-45900657f1d1, groupInstanceId=None, clientId=consumer-new-employee-created-event-1-8, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group new-employee-created-event-1 through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:15,877] INFO [GroupCoordinator 2]: Preparing to rebalance group new-employee-created-event-3 in state PreparingRebalance with old generation 15 (__consumer_offsets-27) (reason: Removing member consumer-new-employee-created-event-3-8-5b3a633d-8277-47fd-9345-64a701ac8e32 on LeaveGroup; client reason: the consumer unsubscribed from all topics) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:15,878] INFO [GroupCoordinator 2]: Group new-employee-created-event-3 with generation 16 is now empty (__consumer_offsets-27) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:15,879] INFO [GroupCoordinator 2]: Member MemberMetadata(memberId=consumer-new-employee-created-event-3-8-5b3a633d-8277-47fd-9345-64a701ac8e32, groupInstanceId=None, clientId=consumer-new-employee-created-event-3-8, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group new-employee-created-event-3 through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:16,342] INFO [GroupCoordinator 3]: Preparing to rebalance group new-employee-created-event-2 in state PreparingRebalance with old generation 15 (__consumer_offsets-26) (reason: Removing member consumer-new-employee-created-event-2-8-c7434559-1a63-4cb3-b653-7419ce08dd99 on LeaveGroup; client reason: the consumer unsubscribed from all topics) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:16,342] INFO [GroupCoordinator 3]: Group new-employee-created-event-2 with generation 16 is now empty (__consumer_offsets-26) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:16,343] INFO [GroupCoordinator 3]: Member MemberMetadata(memberId=consumer-new-employee-created-event-2-8-c7434559-1a63-4cb3-b653-7419ce08dd99, groupInstanceId=None, clientId=consumer-new-employee-created-event-2-8, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group new-employee-created-event-2 through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:16,605] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group new-employee-created-event-1 in Empty state. Created a new member id consumer-new-employee-created-event-1-9-490869d5-9eab-48d8-86cb-398b59c2cd0e and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:16,608] INFO [GroupCoordinator 1]: Preparing to rebalance group new-employee-created-event-1 in state PreparingRebalance with old generation 16 (__consumer_offsets-25) (reason: Adding new member consumer-new-employee-created-event-1-9-490869d5-9eab-48d8-86cb-398b59c2cd0e with group instance id None; client reason: need to re-join with the given member-id: consumer-new-employee-created-event-1-9-490869d5-9eab-48d8-86cb-398b59c2cd0e) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:16,826] INFO [GroupCoordinator 2]: Dynamic member with unknown member id joins group new-employee-created-event-3 in Empty state. Created a new member id consumer-new-employee-created-event-3-9-c5534db9-799f-44cf-ab05-561d66fbf0d7 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:16,829] INFO [GroupCoordinator 2]: Preparing to rebalance group new-employee-created-event-3 in state PreparingRebalance with old generation 16 (__consumer_offsets-27) (reason: Adding new member consumer-new-employee-created-event-3-9-c5534db9-799f-44cf-ab05-561d66fbf0d7 with group instance id None; client reason: need to re-join with the given member-id: consumer-new-employee-created-event-3-9-c5534db9-799f-44cf-ab05-561d66fbf0d7) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:17,210] INFO [GroupCoordinator 3]: Dynamic member with unknown member id joins group new-employee-created-event-2 in Empty state. Created a new member id consumer-new-employee-created-event-2-9-5abf767f-224c-49cb-9061-a0741386a46c and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:17,211] INFO [GroupCoordinator 3]: Preparing to rebalance group new-employee-created-event-2 in state PreparingRebalance with old generation 16 (__consumer_offsets-26) (reason: Adding new member consumer-new-employee-created-event-2-9-5abf767f-224c-49cb-9061-a0741386a46c with group instance id None; client reason: need to re-join with the given member-id: consumer-new-employee-created-event-2-9-5abf767f-224c-49cb-9061-a0741386a46c) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:19,623] INFO [GroupCoordinator 1]: Stabilized group new-employee-created-event-1 generation 17 (__consumer_offsets-25) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:19,626] INFO [GroupCoordinator 1]: Assignment received from leader consumer-new-employee-created-event-1-9-490869d5-9eab-48d8-86cb-398b59c2cd0e for group new-employee-created-event-1 for generation 17. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:19,838] INFO [GroupCoordinator 2]: Stabilized group new-employee-created-event-3 generation 17 (__consumer_offsets-27) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:19,840] INFO [GroupCoordinator 2]: Assignment received from leader consumer-new-employee-created-event-3-9-c5534db9-799f-44cf-ab05-561d66fbf0d7 for group new-employee-created-event-3 for generation 17. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:20,212] INFO [GroupCoordinator 3]: Stabilized group new-employee-created-event-2 generation 17 (__consumer_offsets-26) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:20,214] INFO [GroupCoordinator 3]: Assignment received from leader consumer-new-employee-created-event-2-9-5abf767f-224c-49cb-9061-a0741386a46c for group new-employee-created-event-2 for generation 17. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:43,090] INFO [GroupCoordinator 2]: Preparing to rebalance group new-employee-created-event-3 in state PreparingRebalance with old generation 17 (__consumer_offsets-27) (reason: Removing member consumer-new-employee-created-event-3-9-c5534db9-799f-44cf-ab05-561d66fbf0d7 on LeaveGroup; client reason: the consumer unsubscribed from all topics) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:43,090] INFO [GroupCoordinator 2]: Group new-employee-created-event-3 with generation 18 is now empty (__consumer_offsets-27) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:43,091] INFO [GroupCoordinator 2]: Member MemberMetadata(memberId=consumer-new-employee-created-event-3-9-c5534db9-799f-44cf-ab05-561d66fbf0d7, groupInstanceId=None, clientId=consumer-new-employee-created-event-3-9, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group new-employee-created-event-3 through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:43,106] INFO [GroupCoordinator 3]: Preparing to rebalance group new-employee-created-event-2 in state PreparingRebalance with old generation 17 (__consumer_offsets-26) (reason: Removing member consumer-new-employee-created-event-2-9-5abf767f-224c-49cb-9061-a0741386a46c on LeaveGroup; client reason: the consumer unsubscribed from all topics) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:43,106] INFO [GroupCoordinator 3]: Group new-employee-created-event-2 with generation 18 is now empty (__consumer_offsets-26) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:43,107] INFO [GroupCoordinator 3]: Member MemberMetadata(memberId=consumer-new-employee-created-event-2-9-5abf767f-224c-49cb-9061-a0741386a46c, groupInstanceId=None, clientId=consumer-new-employee-created-event-2-9, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group new-employee-created-event-2 through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:43,389] INFO [GroupCoordinator 1]: Preparing to rebalance group new-employee-created-event-1 in state PreparingRebalance with old generation 17 (__consumer_offsets-25) (reason: Removing member consumer-new-employee-created-event-1-9-490869d5-9eab-48d8-86cb-398b59c2cd0e on LeaveGroup; client reason: the consumer unsubscribed from all topics) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:43,389] INFO [GroupCoordinator 1]: Group new-employee-created-event-1 with generation 18 is now empty (__consumer_offsets-25) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:43,390] INFO [GroupCoordinator 1]: Member MemberMetadata(memberId=consumer-new-employee-created-event-1-9-490869d5-9eab-48d8-86cb-398b59c2cd0e, groupInstanceId=None, clientId=consumer-new-employee-created-event-1-9, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group new-employee-created-event-1 through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:43,951] INFO [GroupCoordinator 2]: Dynamic member with unknown member id joins group new-employee-created-event-3 in Empty state. Created a new member id consumer-new-employee-created-event-3-10-53069daf-a93f-4cf7-beba-dcc624c2fb5c and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:43,953] INFO [GroupCoordinator 2]: Preparing to rebalance group new-employee-created-event-3 in state PreparingRebalance with old generation 18 (__consumer_offsets-27) (reason: Adding new member consumer-new-employee-created-event-3-10-53069daf-a93f-4cf7-beba-dcc624c2fb5c with group instance id None; client reason: need to re-join with the given member-id: consumer-new-employee-created-event-3-10-53069daf-a93f-4cf7-beba-dcc624c2fb5c) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:44,318] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group new-employee-created-event-1 in Empty state. Created a new member id consumer-new-employee-created-event-1-10-96bc12d5-6230-4fe7-83fb-e1a04dfc0e07 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:44,320] INFO [GroupCoordinator 1]: Preparing to rebalance group new-employee-created-event-1 in state PreparingRebalance with old generation 18 (__consumer_offsets-25) (reason: Adding new member consumer-new-employee-created-event-1-10-96bc12d5-6230-4fe7-83fb-e1a04dfc0e07 with group instance id None; client reason: need to re-join with the given member-id: consumer-new-employee-created-event-1-10-96bc12d5-6230-4fe7-83fb-e1a04dfc0e07) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:44,375] INFO [GroupCoordinator 3]: Dynamic member with unknown member id joins group new-employee-created-event-2 in Empty state. Created a new member id consumer-new-employee-created-event-2-10-b568ddc8-57f2-48a3-b9c9-0d5b40cb208a and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:44,378] INFO [GroupCoordinator 3]: Preparing to rebalance group new-employee-created-event-2 in state PreparingRebalance with old generation 18 (__consumer_offsets-26) (reason: Adding new member consumer-new-employee-created-event-2-10-b568ddc8-57f2-48a3-b9c9-0d5b40cb208a with group instance id None; client reason: need to re-join with the given member-id: consumer-new-employee-created-event-2-10-b568ddc8-57f2-48a3-b9c9-0d5b40cb208a) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:46,958] INFO [GroupCoordinator 2]: Stabilized group new-employee-created-event-3 generation 19 (__consumer_offsets-27) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:46,960] INFO [GroupCoordinator 2]: Assignment received from leader consumer-new-employee-created-event-3-10-53069daf-a93f-4cf7-beba-dcc624c2fb5c for group new-employee-created-event-3 for generation 19. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:47,331] INFO [GroupCoordinator 1]: Stabilized group new-employee-created-event-1 generation 19 (__consumer_offsets-25) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:47,333] INFO [GroupCoordinator 1]: Assignment received from leader consumer-new-employee-created-event-1-10-96bc12d5-6230-4fe7-83fb-e1a04dfc0e07 for group new-employee-created-event-1 for generation 19. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:47,393] INFO [GroupCoordinator 3]: Stabilized group new-employee-created-event-2 generation 19 (__consumer_offsets-26) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:01:47,395] INFO [GroupCoordinator 3]: Assignment received from leader consumer-new-employee-created-event-2-10-b568ddc8-57f2-48a3-b9c9-0d5b40cb208a for group new-employee-created-event-2 for generation 19. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:06:12,886] INFO [GroupCoordinator 3]: Preparing to rebalance group new-employee-created-event-2 in state PreparingRebalance with old generation 19 (__consumer_offsets-26) (reason: Removing member consumer-new-employee-created-event-2-10-b568ddc8-57f2-48a3-b9c9-0d5b40cb208a on LeaveGroup; client reason: the consumer unsubscribed from all topics) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:06:12,886] INFO [GroupCoordinator 3]: Group new-employee-created-event-2 with generation 20 is now empty (__consumer_offsets-26) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:06:12,887] INFO [GroupCoordinator 3]: Member MemberMetadata(memberId=consumer-new-employee-created-event-2-10-b568ddc8-57f2-48a3-b9c9-0d5b40cb208a, groupInstanceId=None, clientId=consumer-new-employee-created-event-2-10, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group new-employee-created-event-2 through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:06:12,962] INFO [GroupCoordinator 2]: Preparing to rebalance group new-employee-created-event-3 in state PreparingRebalance with old generation 19 (__consumer_offsets-27) (reason: Removing member consumer-new-employee-created-event-3-10-53069daf-a93f-4cf7-beba-dcc624c2fb5c on LeaveGroup; client reason: the consumer unsubscribed from all topics) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:06:12,963] INFO [GroupCoordinator 2]: Group new-employee-created-event-3 with generation 20 is now empty (__consumer_offsets-27) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:06:12,964] INFO [GroupCoordinator 2]: Member MemberMetadata(memberId=consumer-new-employee-created-event-3-10-53069daf-a93f-4cf7-beba-dcc624c2fb5c, groupInstanceId=None, clientId=consumer-new-employee-created-event-3-10, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group new-employee-created-event-3 through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:06:13,369] INFO [GroupCoordinator 1]: Preparing to rebalance group new-employee-created-event-1 in state PreparingRebalance with old generation 19 (__consumer_offsets-25) (reason: Removing member consumer-new-employee-created-event-1-10-96bc12d5-6230-4fe7-83fb-e1a04dfc0e07 on LeaveGroup; client reason: the consumer unsubscribed from all topics) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:06:13,369] INFO [GroupCoordinator 1]: Group new-employee-created-event-1 with generation 20 is now empty (__consumer_offsets-25) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:06:13,370] INFO [GroupCoordinator 1]: Member MemberMetadata(memberId=consumer-new-employee-created-event-1-10-96bc12d5-6230-4fe7-83fb-e1a04dfc0e07, groupInstanceId=None, clientId=consumer-new-employee-created-event-1-10, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group new-employee-created-event-1 through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:06:13,820] INFO [GroupCoordinator 3]: Dynamic member with unknown member id joins group new-employee-created-event-2 in Empty state. Created a new member id consumer-new-employee-created-event-2-11-59153442-bfcd-4031-8eaa-198ab19eeda1 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:06:13,823] INFO [GroupCoordinator 3]: Preparing to rebalance group new-employee-created-event-2 in state PreparingRebalance with old generation 20 (__consumer_offsets-26) (reason: Adding new member consumer-new-employee-created-event-2-11-59153442-bfcd-4031-8eaa-198ab19eeda1 with group instance id None; client reason: need to re-join with the given member-id: consumer-new-employee-created-event-2-11-59153442-bfcd-4031-8eaa-198ab19eeda1) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:06:13,842] INFO [GroupCoordinator 2]: Dynamic member with unknown member id joins group new-employee-created-event-3 in Empty state. Created a new member id consumer-new-employee-created-event-3-11-bc485437-10c8-40df-9a34-064da73ca751 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:06:13,843] INFO [GroupCoordinator 2]: Preparing to rebalance group new-employee-created-event-3 in state PreparingRebalance with old generation 20 (__consumer_offsets-27) (reason: Adding new member consumer-new-employee-created-event-3-11-bc485437-10c8-40df-9a34-064da73ca751 with group instance id None; client reason: need to re-join with the given member-id: consumer-new-employee-created-event-3-11-bc485437-10c8-40df-9a34-064da73ca751) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:06:14,275] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group new-employee-created-event-1 in Empty state. Created a new member id consumer-new-employee-created-event-1-11-fb2894d3-563b-46f7-b463-ffe2543250ef and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:06:14,278] INFO [GroupCoordinator 1]: Preparing to rebalance group new-employee-created-event-1 in state PreparingRebalance with old generation 20 (__consumer_offsets-25) (reason: Adding new member consumer-new-employee-created-event-1-11-fb2894d3-563b-46f7-b463-ffe2543250ef with group instance id None; client reason: need to re-join with the given member-id: consumer-new-employee-created-event-1-11-fb2894d3-563b-46f7-b463-ffe2543250ef) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:06:16,832] INFO [GroupCoordinator 3]: Stabilized group new-employee-created-event-2 generation 21 (__consumer_offsets-26) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:06:16,841] INFO [GroupCoordinator 3]: Assignment received from leader consumer-new-employee-created-event-2-11-59153442-bfcd-4031-8eaa-198ab19eeda1 for group new-employee-created-event-2 for generation 21. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:06:16,848] INFO [GroupCoordinator 2]: Stabilized group new-employee-created-event-3 generation 21 (__consumer_offsets-27) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:06:16,850] INFO [GroupCoordinator 2]: Assignment received from leader consumer-new-employee-created-event-3-11-bc485437-10c8-40df-9a34-064da73ca751 for group new-employee-created-event-3 for generation 21. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:06:17,281] INFO [GroupCoordinator 1]: Stabilized group new-employee-created-event-1 generation 21 (__consumer_offsets-25) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:06:17,283] INFO [GroupCoordinator 1]: Assignment received from leader consumer-new-employee-created-event-1-11-fb2894d3-563b-46f7-b463-ffe2543250ef for group new-employee-created-event-1 for generation 21. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:06:44,104] INFO [GroupCoordinator 1]: Preparing to rebalance group new-employee-created-event-1 in state PreparingRebalance with old generation 21 (__consumer_offsets-25) (reason: Removing member consumer-new-employee-created-event-1-11-fb2894d3-563b-46f7-b463-ffe2543250ef on LeaveGroup; client reason: the consumer unsubscribed from all topics) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:06:44,105] INFO [GroupCoordinator 1]: Group new-employee-created-event-1 with generation 22 is now empty (__consumer_offsets-25) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:06:44,105] INFO [GroupCoordinator 1]: Member MemberMetadata(memberId=consumer-new-employee-created-event-1-11-fb2894d3-563b-46f7-b463-ffe2543250ef, groupInstanceId=None, clientId=consumer-new-employee-created-event-1-11, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group new-employee-created-event-1 through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:06:47,199] INFO [GroupCoordinator 3]: Preparing to rebalance group new-employee-created-event-2 in state PreparingRebalance with old generation 21 (__consumer_offsets-26) (reason: Removing member consumer-new-employee-created-event-2-11-59153442-bfcd-4031-8eaa-198ab19eeda1 on LeaveGroup; client reason: the consumer unsubscribed from all topics) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:06:47,199] INFO [GroupCoordinator 3]: Group new-employee-created-event-2 with generation 22 is now empty (__consumer_offsets-26) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:06:47,200] INFO [GroupCoordinator 3]: Member MemberMetadata(memberId=consumer-new-employee-created-event-2-11-59153442-bfcd-4031-8eaa-198ab19eeda1, groupInstanceId=None, clientId=consumer-new-employee-created-event-2-11, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group new-employee-created-event-2 through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:06:51,760] INFO [GroupCoordinator 2]: Preparing to rebalance group new-employee-created-event-3 in state PreparingRebalance with old generation 21 (__consumer_offsets-27) (reason: Removing member consumer-new-employee-created-event-3-11-bc485437-10c8-40df-9a34-064da73ca751 on LeaveGroup; client reason: the consumer unsubscribed from all topics) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:06:51,760] INFO [GroupCoordinator 2]: Group new-employee-created-event-3 with generation 22 is now empty (__consumer_offsets-27) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:06:51,762] INFO [GroupCoordinator 2]: Member MemberMetadata(memberId=consumer-new-employee-created-event-3-11-bc485437-10c8-40df-9a34-064da73ca751, groupInstanceId=None, clientId=consumer-new-employee-created-event-3-11, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group new-employee-created-event-3 through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 12:38:19,429] INFO [SnapshotGenerator id=2] Creating new KRaft snapshot file snapshot 00000000000000007149-0000000001 because we have waited at least 60 minute(s). (org.apache.kafka.image.publisher.SnapshotGenerator)
[2025-08-10 12:38:19,429] INFO [SnapshotGenerator id=3] Creating new KRaft snapshot file snapshot 00000000000000007150-0000000001 because we have waited at least 60 minute(s). (org.apache.kafka.image.publisher.SnapshotGenerator)
[2025-08-10 12:38:19,512] INFO [SnapshotEmitter id=3] Successfully wrote snapshot 00000000000000007150-0000000001 (org.apache.kafka.image.publisher.SnapshotEmitter)
[2025-08-10 12:38:19,526] INFO [SnapshotEmitter id=2] Successfully wrote snapshot 00000000000000007149-0000000001 (org.apache.kafka.image.publisher.SnapshotEmitter)
[2025-08-10 12:38:20,972] INFO [SnapshotGenerator id=1] Creating new KRaft snapshot file snapshot 00000000000000007152-0000000001 because we have waited at least 60 minute(s). (org.apache.kafka.image.publisher.SnapshotGenerator)
[2025-08-10 12:38:21,067] INFO [SnapshotEmitter id=1] Successfully wrote snapshot 00000000000000007152-0000000001 (org.apache.kafka.image.publisher.SnapshotEmitter)
[2025-08-10 13:01:26,180] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group new-employee-created-event-1 in Empty state. Created a new member id consumer-new-employee-created-event-1-1-eba4fdca-e393-4a02-ad5d-397ba5a1ee01 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 13:01:26,224] INFO [GroupCoordinator 1]: Preparing to rebalance group new-employee-created-event-1 in state PreparingRebalance with old generation 22 (__consumer_offsets-25) (reason: Adding new member consumer-new-employee-created-event-1-1-eba4fdca-e393-4a02-ad5d-397ba5a1ee01 with group instance id None; client reason: need to re-join with the given member-id: consumer-new-employee-created-event-1-1-eba4fdca-e393-4a02-ad5d-397ba5a1ee01) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 13:01:29,255] INFO [GroupCoordinator 1]: Stabilized group new-employee-created-event-1 generation 23 (__consumer_offsets-25) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 13:01:29,279] INFO [GroupCoordinator 1]: Assignment received from leader consumer-new-employee-created-event-1-1-eba4fdca-e393-4a02-ad5d-397ba5a1ee01 for group new-employee-created-event-1 for generation 23. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 13:02:33,841] INFO [GroupCoordinator 3]: Dynamic member with unknown member id joins group new-employee-created-event-2 in Empty state. Created a new member id consumer-new-employee-created-event-2-1-260ca5da-35b9-4711-b80f-918e4204ad93 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 13:02:33,883] INFO [GroupCoordinator 3]: Preparing to rebalance group new-employee-created-event-2 in state PreparingRebalance with old generation 22 (__consumer_offsets-26) (reason: Adding new member consumer-new-employee-created-event-2-1-260ca5da-35b9-4711-b80f-918e4204ad93 with group instance id None; client reason: need to re-join with the given member-id: consumer-new-employee-created-event-2-1-260ca5da-35b9-4711-b80f-918e4204ad93) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 13:02:36,927] INFO [GroupCoordinator 3]: Stabilized group new-employee-created-event-2 generation 23 (__consumer_offsets-26) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 13:02:36,947] INFO [GroupCoordinator 3]: Assignment received from leader consumer-new-employee-created-event-2-1-260ca5da-35b9-4711-b80f-918e4204ad93 for group new-employee-created-event-2 for generation 23. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 13:04:17,119] INFO [GroupCoordinator 3]: Preparing to rebalance group new-employee-created-event-2 in state PreparingRebalance with old generation 23 (__consumer_offsets-26) (reason: Removing member consumer-new-employee-created-event-2-1-260ca5da-35b9-4711-b80f-918e4204ad93 on LeaveGroup; client reason: the consumer unsubscribed from all topics) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 13:04:17,120] INFO [GroupCoordinator 3]: Group new-employee-created-event-2 with generation 24 is now empty (__consumer_offsets-26) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 13:04:17,125] INFO [GroupCoordinator 3]: Member MemberMetadata(memberId=consumer-new-employee-created-event-2-1-260ca5da-35b9-4711-b80f-918e4204ad93, groupInstanceId=None, clientId=consumer-new-employee-created-event-2-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group new-employee-created-event-2 through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 13:07:26,655] INFO [GroupCoordinator 1]: Preparing to rebalance group new-employee-created-event-1 in state PreparingRebalance with old generation 23 (__consumer_offsets-25) (reason: Removing member consumer-new-employee-created-event-1-1-eba4fdca-e393-4a02-ad5d-397ba5a1ee01 on LeaveGroup; client reason: the consumer unsubscribed from all topics) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 13:07:26,657] INFO [GroupCoordinator 1]: Group new-employee-created-event-1 with generation 24 is now empty (__consumer_offsets-25) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 13:07:26,665] INFO [GroupCoordinator 1]: Member MemberMetadata(memberId=consumer-new-employee-created-event-1-1-eba4fdca-e393-4a02-ad5d-397ba5a1ee01, groupInstanceId=None, clientId=consumer-new-employee-created-event-1-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group new-employee-created-event-1 through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 13:07:27,573] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group new-employee-created-event-1 in Empty state. Created a new member id consumer-new-employee-created-event-1-2-380eda20-47e0-4cc7-adb7-16afc2930d0d and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 13:07:27,576] INFO [GroupCoordinator 1]: Preparing to rebalance group new-employee-created-event-1 in state PreparingRebalance with old generation 24 (__consumer_offsets-25) (reason: Adding new member consumer-new-employee-created-event-1-2-380eda20-47e0-4cc7-adb7-16afc2930d0d with group instance id None; client reason: need to re-join with the given member-id: consumer-new-employee-created-event-1-2-380eda20-47e0-4cc7-adb7-16afc2930d0d) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 13:07:30,593] INFO [GroupCoordinator 1]: Stabilized group new-employee-created-event-1 generation 25 (__consumer_offsets-25) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 13:07:30,596] INFO [GroupCoordinator 1]: Assignment received from leader consumer-new-employee-created-event-1-2-380eda20-47e0-4cc7-adb7-16afc2930d0d for group new-employee-created-event-1 for generation 25. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 13:09:42,476] INFO [GroupCoordinator 1]: Preparing to rebalance group new-employee-created-event-1 in state PreparingRebalance with old generation 25 (__consumer_offsets-25) (reason: Removing member consumer-new-employee-created-event-1-2-380eda20-47e0-4cc7-adb7-16afc2930d0d on LeaveGroup; client reason: the consumer unsubscribed from all topics) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 13:09:42,486] INFO [GroupCoordinator 1]: Group new-employee-created-event-1 with generation 26 is now empty (__consumer_offsets-25) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 13:09:42,487] INFO [GroupCoordinator 1]: Member MemberMetadata(memberId=consumer-new-employee-created-event-1-2-380eda20-47e0-4cc7-adb7-16afc2930d0d, groupInstanceId=None, clientId=consumer-new-employee-created-event-1-2, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group new-employee-created-event-1 through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 13:09:43,300] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group new-employee-created-event-1 in Empty state. Created a new member id consumer-new-employee-created-event-1-3-45fddb02-bd3a-4be7-90b1-51b3268fc865 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 13:09:43,302] INFO [GroupCoordinator 1]: Preparing to rebalance group new-employee-created-event-1 in state PreparingRebalance with old generation 26 (__consumer_offsets-25) (reason: Adding new member consumer-new-employee-created-event-1-3-45fddb02-bd3a-4be7-90b1-51b3268fc865 with group instance id None; client reason: need to re-join with the given member-id: consumer-new-employee-created-event-1-3-45fddb02-bd3a-4be7-90b1-51b3268fc865) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 13:09:46,314] INFO [GroupCoordinator 1]: Stabilized group new-employee-created-event-1 generation 27 (__consumer_offsets-25) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 13:09:46,317] INFO [GroupCoordinator 1]: Assignment received from leader consumer-new-employee-created-event-1-3-45fddb02-bd3a-4be7-90b1-51b3268fc865 for group new-employee-created-event-1 for generation 27. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 13:10:45,953] INFO [GroupCoordinator 1]: Preparing to rebalance group new-employee-created-event-1 in state PreparingRebalance with old generation 27 (__consumer_offsets-25) (reason: Removing member consumer-new-employee-created-event-1-3-45fddb02-bd3a-4be7-90b1-51b3268fc865 on LeaveGroup; client reason: the consumer unsubscribed from all topics) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 13:10:45,954] INFO [GroupCoordinator 1]: Group new-employee-created-event-1 with generation 28 is now empty (__consumer_offsets-25) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 13:10:45,956] INFO [GroupCoordinator 1]: Member MemberMetadata(memberId=consumer-new-employee-created-event-1-3-45fddb02-bd3a-4be7-90b1-51b3268fc865, groupInstanceId=None, clientId=consumer-new-employee-created-event-1-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group new-employee-created-event-1 through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 13:10:49,225] INFO [GroupCoordinator 3]: Dynamic member with unknown member id joins group new-employee-created-event-2 in Empty state. Created a new member id consumer-new-employee-created-event-2-1-d75bd0ec-2162-4fce-b65b-71b455a73d8b and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 13:10:49,231] INFO [GroupCoordinator 3]: Preparing to rebalance group new-employee-created-event-2 in state PreparingRebalance with old generation 24 (__consumer_offsets-26) (reason: Adding new member consumer-new-employee-created-event-2-1-d75bd0ec-2162-4fce-b65b-71b455a73d8b with group instance id None; client reason: need to re-join with the given member-id: consumer-new-employee-created-event-2-1-d75bd0ec-2162-4fce-b65b-71b455a73d8b) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 13:10:52,087] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group new-employee-created-event-1 in Empty state. Created a new member id consumer-new-employee-created-event-1-1-5f75e284-2716-40e9-a1f1-0e6eac88bb88 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 13:10:52,091] INFO [GroupCoordinator 1]: Preparing to rebalance group new-employee-created-event-1 in state PreparingRebalance with old generation 28 (__consumer_offsets-25) (reason: Adding new member consumer-new-employee-created-event-1-1-5f75e284-2716-40e9-a1f1-0e6eac88bb88 with group instance id None; client reason: need to re-join with the given member-id: consumer-new-employee-created-event-1-1-5f75e284-2716-40e9-a1f1-0e6eac88bb88) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 13:10:52,243] INFO [GroupCoordinator 3]: Stabilized group new-employee-created-event-2 generation 25 (__consumer_offsets-26) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 13:10:52,257] INFO [GroupCoordinator 3]: Assignment received from leader consumer-new-employee-created-event-2-1-d75bd0ec-2162-4fce-b65b-71b455a73d8b for group new-employee-created-event-2 for generation 25. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 13:10:55,097] INFO [GroupCoordinator 1]: Stabilized group new-employee-created-event-1 generation 29 (__consumer_offsets-25) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 13:10:55,099] INFO [GroupCoordinator 1]: Preparing to rebalance group new-employee-created-event-1 in state PreparingRebalance with old generation 29 (__consumer_offsets-25) (reason: Removing member consumer-new-employee-created-event-1-1-5f75e284-2716-40e9-a1f1-0e6eac88bb88 on LeaveGroup; client reason: the consumer unsubscribed from all topics) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 13:10:55,100] INFO [GroupCoordinator 1]: Group new-employee-created-event-1 with generation 30 is now empty (__consumer_offsets-25) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 13:10:55,101] INFO [GroupCoordinator 1]: Member MemberMetadata(memberId=consumer-new-employee-created-event-1-1-5f75e284-2716-40e9-a1f1-0e6eac88bb88, groupInstanceId=None, clientId=consumer-new-employee-created-event-1-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group new-employee-created-event-1 through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 13:10:58,250] INFO [GroupCoordinator 3]: Preparing to rebalance group new-employee-created-event-2 in state PreparingRebalance with old generation 25 (__consumer_offsets-26) (reason: Removing member consumer-new-employee-created-event-2-1-d75bd0ec-2162-4fce-b65b-71b455a73d8b on LeaveGroup; client reason: the consumer unsubscribed from all topics) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 13:10:58,251] INFO [GroupCoordinator 3]: Group new-employee-created-event-2 with generation 26 is now empty (__consumer_offsets-26) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 13:10:58,255] INFO [GroupCoordinator 3]: Member MemberMetadata(memberId=consumer-new-employee-created-event-2-1-d75bd0ec-2162-4fce-b65b-71b455a73d8b, groupInstanceId=None, clientId=consumer-new-employee-created-event-2-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group new-employee-created-event-2 through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 13:26:56,877] INFO [BrokerToControllerChannelManager id=3 name=forwarding] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-08-10 13:28:55,235] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group new-employee-created-event-1 in Empty state. Created a new member id consumer-new-employee-created-event-1-1-2c44311d-83eb-4da2-91a1-358e97de6c66 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 13:28:55,249] INFO [GroupCoordinator 1]: Preparing to rebalance group new-employee-created-event-1 in state PreparingRebalance with old generation 30 (__consumer_offsets-25) (reason: Adding new member consumer-new-employee-created-event-1-1-2c44311d-83eb-4da2-91a1-358e97de6c66 with group instance id None; client reason: need to re-join with the given member-id: consumer-new-employee-created-event-1-1-2c44311d-83eb-4da2-91a1-358e97de6c66) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 13:28:58,059] INFO [GroupCoordinator 3]: Dynamic member with unknown member id joins group new-employee-created-event-2 in Empty state. Created a new member id consumer-new-employee-created-event-2-1-2065c66f-53bf-463b-b568-3ca3737794e6 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 13:28:58,079] INFO [GroupCoordinator 3]: Preparing to rebalance group new-employee-created-event-2 in state PreparingRebalance with old generation 26 (__consumer_offsets-26) (reason: Adding new member consumer-new-employee-created-event-2-1-2065c66f-53bf-463b-b568-3ca3737794e6 with group instance id None; client reason: need to re-join with the given member-id: consumer-new-employee-created-event-2-1-2065c66f-53bf-463b-b568-3ca3737794e6) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 13:28:58,261] INFO [GroupCoordinator 1]: Stabilized group new-employee-created-event-1 generation 31 (__consumer_offsets-25) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 13:28:58,279] INFO [GroupCoordinator 1]: Assignment received from leader consumer-new-employee-created-event-1-1-2c44311d-83eb-4da2-91a1-358e97de6c66 for group new-employee-created-event-1 for generation 31. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 13:29:00,350] INFO [GroupCoordinator 2]: Dynamic member with unknown member id joins group new-employee-created-event-3 in Empty state. Created a new member id consumer-new-employee-created-event-3-1-6c56d415-c4ce-460d-bc03-b077a06a01e8 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 13:29:00,392] INFO [GroupCoordinator 2]: Preparing to rebalance group new-employee-created-event-3 in state PreparingRebalance with old generation 22 (__consumer_offsets-27) (reason: Adding new member consumer-new-employee-created-event-3-1-6c56d415-c4ce-460d-bc03-b077a06a01e8 with group instance id None; client reason: need to re-join with the given member-id: consumer-new-employee-created-event-3-1-6c56d415-c4ce-460d-bc03-b077a06a01e8) (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 13:29:01,095] INFO [GroupCoordinator 3]: Stabilized group new-employee-created-event-2 generation 27 (__consumer_offsets-26) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 13:29:01,106] INFO [GroupCoordinator 3]: Assignment received from leader consumer-new-employee-created-event-2-1-2065c66f-53bf-463b-b568-3ca3737794e6 for group new-employee-created-event-2 for generation 27. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 13:29:03,421] INFO [GroupCoordinator 2]: Stabilized group new-employee-created-event-3 generation 23 (__consumer_offsets-27) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 13:29:03,439] INFO [GroupCoordinator 2]: Assignment received from leader consumer-new-employee-created-event-3-1-6c56d415-c4ce-460d-bc03-b077a06a01e8 for group new-employee-created-event-3 for generation 23. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-08-10 13:38:19,451] INFO [SnapshotGenerator id=3] Creating new KRaft snapshot file snapshot 00000000000000014240-0000000001 because we have waited at least 60 minute(s). (org.apache.kafka.image.publisher.SnapshotGenerator)
[2025-08-10 13:38:19,451] INFO [SnapshotGenerator id=2] Creating new KRaft snapshot file snapshot 00000000000000014239-0000000001 because we have waited at least 60 minute(s). (org.apache.kafka.image.publisher.SnapshotGenerator)
[2025-08-10 13:38:19,501] INFO [SnapshotEmitter id=3] Successfully wrote snapshot 00000000000000014240-0000000001 (org.apache.kafka.image.publisher.SnapshotEmitter)
[2025-08-10 13:38:19,515] INFO [SnapshotEmitter id=2] Successfully wrote snapshot 00000000000000014239-0000000001 (org.apache.kafka.image.publisher.SnapshotEmitter)
[2025-08-10 13:38:20,966] INFO [SnapshotGenerator id=1] Creating new KRaft snapshot file snapshot 00000000000000014242-0000000001 because we have waited at least 60 minute(s). (org.apache.kafka.image.publisher.SnapshotGenerator)
[2025-08-10 13:38:21,014] INFO [SnapshotEmitter id=1] Successfully wrote snapshot 00000000000000014242-0000000001 (org.apache.kafka.image.publisher.SnapshotEmitter)
